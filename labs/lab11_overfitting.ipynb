{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6B: Backtest Overfitting (CSCV, PBO, PSR/DSR)\n",
        "\n",
        "## Before You Code: The Big Picture\n",
        "\n",
        "The #1 problem in quantitative finance: **your backtest looks great, but\n",
        "it fails in live trading**. Why? **Overfitting**—you optimized\n",
        "parameters on the same data you tested on. Your “alpha” is actually\n",
        "selection bias.\n",
        "\n",
        "> **The Backtest Overfitting Problem**\n",
        ">\n",
        "> **The Scenario:** You test 200 trading strategies on 20 years of data.\n",
        "> One strategy has a Sharpe ratio of 2.5—amazing! You deploy it with\n",
        "> real money. It loses money immediately. What happened?\n",
        ">\n",
        "> **The Problem:** - With 200 tries, **one will look good by pure luck**\n",
        "> (multiple testing) - In-sample optimization + in-sample testing =\n",
        "> guaranteed overfitting - Traditional cross-validation doesn’t detect\n",
        "> this (data leakage across folds)\n",
        ">\n",
        "> **The Solution (Bailey & López de Prado):** 1. **CSCV (Combinatorially\n",
        "> Symmetric Cross-Validation)**: Proper walk-forward splits 2. **PBO\n",
        "> (Probability of Backtest Overfitting)**: Quantifies selection bias 3.\n",
        "> **PSR (Probabilistic Sharpe Ratio)**: Tests if Sharpe \\> 0 with\n",
        "> statistical significance 4. **DSR (Deflated Sharpe Ratio)**: Adjusts\n",
        "> for multiple testing\n",
        ">\n",
        "> **The Evidence:** Harvey, Liu & Zhu (2016, RFS): Most published factor\n",
        "> strategies fail out-of-sample due to p-hacking and multiple testing.\n",
        "> PBO/PSR help detect this **before** losing real money.\n",
        "\n",
        "### What You’ll Build Today\n",
        "\n",
        "By the end of this lab, you will have:\n",
        "\n",
        "-   ✅ Understanding of why standard backtesting fails\n",
        "-   ✅ CSCV implementation for honest validation\n",
        "-   ✅ PBO calculation showing selection bias\n",
        "-   ✅ PSR/DSR metrics for performance significance\n",
        "-   ✅ Critical perspective on published trading strategies\n",
        "\n",
        "**Time estimate:** 90-120 minutes (this is advanced material—take your\n",
        "time)\n",
        "\n",
        "> **Why This Matters for Coursework 2**\n",
        ">\n",
        "> Your factor replication **must** use walk-forward validation and\n",
        "> report PBO/PSR. Otherwise, your Sharpe ratio is meaningless—it’s just\n",
        "> in-sample optimization parading as out-of-sample performance. This lab\n",
        "> shows you how to do it right.\n",
        "\n",
        "# Objectives\n",
        "\n",
        "-   Diagnose backtest overfitting with combinatorially symmetric\n",
        "    cross‑validation (CSCV)  \n",
        "-   Estimate Probability of Backtest Overfitting (PBO)  \n",
        "-   Quantify performance significance via Probabilistic Sharpe Ratio\n",
        "    (PSR); discuss Deflated Sharpe Ratio (DSR)\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> This lab follows Bailey & López de Prado’s approach to selection bias:\n",
        "> CSCV → PBO and PSR/DSR. We implement lightweight utilities and show\n",
        "> how to compare against `mlfinlab` if available.\n",
        "\n",
        "# Setup\n",
        "\n",
        "# Part A — A garden of strategies on pure noise\n",
        "\n",
        "We simulate `N=200` strategies with no true edge. In a finite sample,\n",
        "one will “win” in‑sample by chance.\n",
        "\n",
        "Observation: Even with zero true edge, the best in‑sample Sharpe can\n",
        "look compelling.\n",
        "\n",
        "# Part B — CSCV and Probability of Backtest Overfitting (PBO)\n",
        "\n",
        "We split the time axis into contiguous folds and repeatedly pick the\n",
        "in‑sample “champion”, then measure its out‑of‑sample rank. PBO is the\n",
        "fraction of splits where the champion underperforms out‑of‑sample\n",
        "(negative logit rank).\n",
        "\n",
        "Interpretation: A high PBO indicates that selecting the in‑sample\n",
        "“winner” is likely to disappoint out‑of‑sample.\n",
        "\n",
        "# Part C — PSR and discussion of DSR\n",
        "\n",
        "We compute the Probabilistic Sharpe Ratio (PSR) of the champion against\n",
        "a 0 benchmark. DSR additionally deflates for selection bias by using a\n",
        "higher benchmark Sharpe (selection threshold). If `mlfinlab` is\n",
        "installed, we compare against its DSR.\n",
        "\n",
        "Optional: compare with `mlfinlab`’s DSR (if available). Note DSR uses an\n",
        "elevated benchmark Sharpe that accounts for the number of trials and\n",
        "their correlation (see paper for details).\n",
        "\n",
        "## Optional — Empirical Selection Benchmark (SR\\*)\n",
        "\n",
        "An intuitive (but approximate) benchmark SR\\* is the selection threshold\n",
        "you would have used to promote a strategy, e.g., the 95th percentile of\n",
        "candidate SRs or the top‑k cutoff used in model selection. This inflates\n",
        "the benchmark to reflect the search.\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> Guidance: PSR answers “what is the probability that the true SR \\>\n",
        "> benchmark SR*?”. DSR raises SR* to deflate for selection bias (many\n",
        "> trials and correlation among them). When reporting results, disclose\n",
        "> the number of trials and use CSCV/PBO to evidence robustness.\n",
        "\n",
        "# Extension — Replace noise with weak‑edge signals\n",
        "\n",
        "Modify the simulation so a small subset of strategies has a slight\n",
        "positive mean. Re‑run CSCV/PBO and PSR to see whether evidence\n",
        "accumulates honestly.\n",
        "\n",
        "# Deliverables\n",
        "\n",
        "-   Report the observed PBO and interpret its meaning\n",
        "-   Report PSR for the selected strategy; if available, compare with DSR\n",
        "-   Describe how your result changes when a few strategies have a\n",
        "    genuine (small) edge\n",
        "\n",
        "## How to Report (Template)\n",
        "\n",
        "-   Trials: We evaluated N strategies/hyper‑parameters (comment on\n",
        "    similarity/correlation if relevant).  \n",
        "-   Selection: In‑sample selection metric = \\[Sharpe/alpha/etc.\\] with\n",
        "    CSCV splits (k=10).  \n",
        "-   Robustness: PBO = X.XX across S splits (show logit rank\n",
        "    histogram).  \n",
        "-   Significance: PSR = X.XX vs SR\\*=0 (skew=…, kurt=…, n=…)\n",
        "    -   Optional: DSR = X.XX (assumptions: trials=N, rho=…, length=n).  \n",
        "-   Data: period, universe, costs/slippage, vintages/release timing.  \n",
        "-   Decision: \\[Promote/Park\\], rationale and next steps (e.g., live\n",
        "    paper trading).\n",
        "\n",
        "# References\n",
        "\n",
        "-   Bailey et al. (2015) — Probability of Backtest Overfitting (PBO) and\n",
        "    CSCV  \n",
        "-   Bailey and Prado (2014) — Deflated Sharpe Ratio (DSR)  \n",
        "-   López de Prado, M. — Deflated Sharpe Ratio (DSR), SSRN  \n",
        "-   White (2000) — Reality Check for data snooping  \n",
        "-   Hansen (2005) — Superior Predictive Ability (SPA) test\n",
        "\n",
        "Bailey, David H., Jonathan M. Borwein, Marcos López de Prado, and Qiji\n",
        "Jim Zhu. 2015. “The Probability of Backtest Overfitting.” *Journal of\n",
        "Computational Finance*. <https://doi.org/10.2139/ssrn.2326253>.\n",
        "\n",
        "Bailey, David H., and Marcos López de Prado. 2014. “The Deflated Sharpe\n",
        "Ratio: Correcting for Selection Bias, Backtest Overfitting and\n",
        "Non-Normality.” *Journal of Portfolio Management* 40 (5): 94–107.\n",
        "<https://doi.org/10.2139/ssrn.2460551>."
      ],
      "id": "7e931953-2b48-4b15-87e7-96bc154c02c5"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "fin510",
      "display_name": "FIN510 Python",
      "language": "python",
      "path": "/Users/quinference/Library/Jupyter/kernels/fin510"
    }
  }
}