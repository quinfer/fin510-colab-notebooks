{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 10: Factor Replication ‚Äî Exploratory Analysis\n",
        "\n",
        "<figure>\n",
        "<a\n",
        "href=\"https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab10_factor_replication.ipynb\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "<figcaption>Open in Colab</figcaption>\n",
        "</figure>\n",
        "\n",
        "## Objective\n",
        "\n",
        "This lab develops understanding of factor replication principles through\n",
        "**exploratory exercises**. You‚Äôll investigate concepts that underpin\n",
        "rigorous factor analysis‚ÄîHAC standard errors, alpha interpretation,\n",
        "robustness thinking‚Äîwithout producing submission-ready outputs.\n",
        "\n",
        "**Important**: This is not a template for Coursework 2. The scaffold\n",
        "notebook ([open in\n",
        "Colab](https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/coursework2_scaffold.ipynb))\n",
        "provides that. This lab teaches you **how to think** about factor\n",
        "replication so you can interpret scaffold outputs intelligently and\n",
        "write critical analysis.\n",
        "\n",
        "**Time estimate**: 60-90 minutes\n",
        "\n",
        "## Learning Goals\n",
        "\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "-   Explain why HAC standard errors matter in time-series regression\n",
        "-   Interpret alpha tests and distinguish statistical vs.¬†economic\n",
        "    significance\n",
        "-   Evaluate robustness by comparing results across subsamples\n",
        "-   Identify limitations in factor research (selection bias, transaction\n",
        "    costs)\n",
        "-   Ask critical questions about factor replicability\n",
        "\n",
        "## Setup"
      ],
      "id": "2eadc4c3-8e52-4c07-9d63-9947a5eb2679"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from statsmodels.stats.sandwich_covariance import cov_hac\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "np.random.seed(42)  # Reproducibility\n",
        "\n",
        "print(\"‚úì Libraries loaded successfully\")"
      ],
      "id": "6280ca5f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Understanding Autocorrelation and HAC Standard Errors\n",
        "\n",
        "### Exercise 1.1: Visualising Autocorrelation\n",
        "\n",
        "Financial returns often exhibit serial correlation. Let‚Äôs explore what\n",
        "this means and why it matters for statistical inference."
      ],
      "id": "0a9af4e3-8b5b-40ad-b6f9-61da4f89d075"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate two return series: one independent, one autocorrelated\n",
        "n = 240  # 20 years monthly\n",
        "\n",
        "# Series 1: Independent returns (no autocorrelation)\n",
        "returns_iid = np.random.normal(0.008, 0.04, n)\n",
        "\n",
        "# Series 2: Autocorrelated returns (AR(1) with coefficient 0.4)\n",
        "returns_ar = np.zeros(n)\n",
        "returns_ar[0] = np.random.normal(0.008, 0.04)\n",
        "for i in range(1, n):\n",
        "    returns_ar[i] = 0.008 + 0.4 * (returns_ar[i-1] - 0.008) + np.random.normal(0, 0.04)\n",
        "\n",
        "# Convert to pandas Series with date index\n",
        "dates = pd.date_range('2004-01-01', periods=n, freq='MS')\n",
        "returns_iid = pd.Series(returns_iid, index=dates, name='IID Returns')\n",
        "returns_ar = pd.Series(returns_ar, index=dates, name='AR(1) Returns')\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "# Time series plots\n",
        "ax1.plot(returns_iid.index, returns_iid.values, label='Independent Returns', alpha=0.7, linewidth=1)\n",
        "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
        "ax1.set_ylabel('Monthly Return')\n",
        "ax1.set_title('Independent Returns (No Autocorrelation)', fontsize=12)\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "ax2.plot(returns_ar.index, returns_ar.values, label='Autocorrelated Returns', alpha=0.7, linewidth=1, color='red')\n",
        "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
        "ax2.set_xlabel('Date')\n",
        "ax2.set_ylabel('Monthly Return')\n",
        "ax2.set_title('Autocorrelated Returns (AR(1) coefficient = 0.4)', fontsize=12)\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate autocorrelation\n",
        "print(\"=== Autocorrelation at Lag 1 ===\")\n",
        "print(f\"Independent returns: {returns_iid.autocorr(1):.4f}\")\n",
        "print(f\"Autocorrelated returns: {returns_ar.autocorr(1):.4f}\")"
      ],
      "id": "e53d9de6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  What visual differences do you notice between the two series?\n",
        "2.  How does autocorrelation affect the ‚Äúsmoothness‚Äù of the return\n",
        "    series?\n",
        "3.  If returns are autocorrelated, are observations truly independent?\n",
        "\n",
        "### Exercise 1.2: Impact of Autocorrelation on Standard Errors\n",
        "\n",
        "Now let‚Äôs see how autocorrelation affects statistical inference. We‚Äôll\n",
        "regress both series on a constant (testing if mean return is\n",
        "significantly different from zero)."
      ],
      "id": "d81a4e3c-7ac7-4975-8daf-66786be95190"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_mean_return(returns, name):\n",
        "    \"\"\"\n",
        "    Test if mean return is significantly different from zero.\n",
        "    Compare OLS vs HAC standard errors.\n",
        "    \"\"\"\n",
        "    # Regression on constant only (testing mean)\n",
        "    X = np.ones(len(returns))\n",
        "    model = OLS(returns.values, X).fit()\n",
        "    \n",
        "    # HAC standard errors (Newey-West with 6 lags)\n",
        "    cov_hac_matrix = cov_hac(model, nlags=6)\n",
        "    se_hac = np.sqrt(cov_hac_matrix[0, 0])\n",
        "    t_hac = model.params[0] / se_hac\n",
        "    \n",
        "    # Results\n",
        "    results = pd.DataFrame({\n",
        "        'Estimate': [model.params[0] * 100],  # Convert to %\n",
        "        'OLS SE': [model.bse[0] * 100],\n",
        "        'HAC SE': [se_hac * 100],\n",
        "        'OLS t-stat': [model.tvalues[0]],\n",
        "        'HAC t-stat': [t_hac],\n",
        "        'SE Ratio (HAC/OLS)': [se_hac / model.bse[0]]\n",
        "    }, index=[name])\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test both series\n",
        "results_iid = test_mean_return(returns_iid, 'Independent')\n",
        "results_ar = test_mean_return(returns_ar, 'Autocorrelated')\n",
        "\n",
        "print(\"=== Mean Return Tests: OLS vs HAC ===\\n\")\n",
        "print(pd.concat([results_iid, results_ar]).round(4))"
      ],
      "id": "7a4278ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  For independent returns, how do OLS and HAC standard errors compare?\n",
        "    Why?\n",
        "2.  For autocorrelated returns, is HAC standard error larger or smaller\n",
        "    than OLS? Why?\n",
        "3.  Does the conclusion about statistical significance change when using\n",
        "    HAC vs OLS?\n",
        "4.  What would happen if we used OLS for autocorrelated data without\n",
        "    realising it?\n",
        "\n",
        "**Key insight**: Autocorrelation violates OLS independence assumption,\n",
        "causing standard errors to be understated. HAC corrects this by\n",
        "adjusting for serial dependence. Using OLS on financial time-series data\n",
        "leads to false positives (claiming significance when results are\n",
        "actually noise).\n",
        "\n",
        "## Part 2: Alpha Tests and Economic Interpretation\n",
        "\n",
        "### Exercise 2.1: Simulating Factor Returns\n",
        "\n",
        "Let‚Äôs create a simulated factor and test for alpha using CAPM\n",
        "regression."
      ],
      "id": "ff1caa01-893c-4975-a49c-d8ae89cb9bf0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate market and factor returns\n",
        "n = 240  # 20 years monthly\n",
        "\n",
        "# Market returns\n",
        "market = np.random.normal(0.008, 0.04, n)\n",
        "\n",
        "# Factor returns with:\n",
        "# - Positive alpha (0.003 = 0.3% monthly = 3.6% annualised)\n",
        "# - Beta = 0.2 (some market exposure)\n",
        "# - Autocorrelation (realistic for factors)\n",
        "factor = np.zeros(n)\n",
        "factor[0] = 0.003 + 0.2 * market[0] + np.random.normal(0, 0.03)\n",
        "for i in range(1, n):\n",
        "    factor[i] = 0.003 + 0.2 * market[i] + 0.3 * factor[i-1] + np.random.normal(0, 0.03)\n",
        "\n",
        "# Convert to pandas\n",
        "dates = pd.date_range('2004-01-01', periods=n, freq='MS')\n",
        "market = pd.Series(market, index=dates, name='Market')\n",
        "factor = pd.Series(factor, index=dates, name='Factor')\n",
        "\n",
        "# Summary statistics\n",
        "summary = pd.DataFrame({\n",
        "    'Mean (% monthly)': [market.mean() * 100, factor.mean() * 100],\n",
        "    'Std Dev (%)': [market.std() * 100, factor.std() * 100],\n",
        "    'Sharpe Ratio': [(market.mean() / market.std()) * np.sqrt(12), \n",
        "                     (factor.mean() / factor.std()) * np.sqrt(12)]\n",
        "}, index=['Market', 'Factor'])\n",
        "\n",
        "print(\"=== Summary Statistics ===\\n\")\n",
        "print(summary.round(3))"
      ],
      "id": "7ef35356"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  Which has higher mean return: market or factor?\n",
        "2.  Which has higher volatility (risk)?\n",
        "3.  Which has better risk-adjusted return (Sharpe ratio)?\n",
        "4.  Can you tell from summary stats alone whether factor has significant\n",
        "    alpha?\n",
        "\n",
        "### Exercise 2.2: CAPM Alpha Regression\n",
        "\n",
        "Now test for alpha by regressing factor on market."
      ],
      "id": "6467ca21-fc38-4cc5-ac22-b6ecb123fc91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CAPM regression\n",
        "X = sm.add_constant(market.values)\n",
        "model = OLS(factor.values, X).fit()\n",
        "\n",
        "# HAC standard errors\n",
        "cov_hac_matrix = cov_hac(model, nlags=6)\n",
        "se_hac = np.sqrt(np.diag(cov_hac_matrix))\n",
        "t_hac = model.params / se_hac\n",
        "\n",
        "# Results table\n",
        "alpha_results = pd.DataFrame({\n",
        "    'Coefficient': model.params,\n",
        "    'OLS SE': model.bse,\n",
        "    'HAC SE': se_hac,\n",
        "    'HAC t-stat': t_hac,\n",
        "    'OLS p-value': model.pvalues\n",
        "}, index=['Alpha', 'Beta'])\n",
        "\n",
        "# Add R-squared\n",
        "alpha_results.loc['R-squared', 'Coefficient'] = model.rsquared\n",
        "\n",
        "print(\"=== CAPM Alpha Test ===\")\n",
        "print(f\"Regression: Factor = Alpha + Beta √ó Market + error\\n\")\n",
        "print(alpha_results.round(4))\n",
        "\n",
        "# Interpretation\n",
        "alpha_monthly = model.params[0]\n",
        "alpha_annual = alpha_monthly * 12\n",
        "t_stat = t_hac[0]\n",
        "\n",
        "print(f\"\\nüìä INTERPRETATION:\")\n",
        "print(f\"   Alpha = {alpha_monthly*100:.3f}% monthly ({alpha_annual*100:.2f}% annualised)\")\n",
        "print(f\"   Beta = {model.params[1]:.3f} (market exposure)\")\n",
        "print(f\"   t-statistic = {t_stat:.2f}\")\n",
        "\n",
        "if abs(t_stat) > 1.96:\n",
        "    print(f\"   ‚úì Alpha is statistically significant at 5% level (|t| > 1.96)\")\n",
        "    print(f\"     Factor earns excess return beyond market exposure\")\n",
        "else:\n",
        "    print(f\"   ‚úó Alpha is NOT statistically significant (|t| < 1.96)\")\n",
        "    print(f\"     Cannot reject null hypothesis of zero alpha\")\n",
        "\n",
        "print(f\"\\n   R¬≤ = {model.rsquared:.3f} ({model.rsquared*100:.1f}% of factor variance explained by market)\")"
      ],
      "id": "1ab8be12"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  What is the estimated alpha? Is it positive or negative?\n",
        "2.  Is alpha statistically significant (using HAC t-statistic)?\n",
        "3.  What does beta tell you about factor‚Äôs market exposure?\n",
        "4.  What does R¬≤ tell you about how much factor is driven by market?\n",
        "5.  Even if alpha is statistically significant, is it economically\n",
        "    meaningful? (Consider transaction costs of ~0.2-0.5% monthly for\n",
        "    real portfolios)\n",
        "\n",
        "**Key insight**: Alpha measures excess return not explained by market.\n",
        "Positive and significant alpha suggests factor generates returns beyond\n",
        "market exposure. But statistical significance doesn‚Äôt guarantee economic\n",
        "exploitability‚Äîmust consider transaction costs, implementation\n",
        "constraints, and risk.\n",
        "\n",
        "## Part 3: Robustness Thinking\n",
        "\n",
        "### Exercise 3.1: Sample Split\n",
        "\n",
        "A single significant result could be luck. Robustness checks test if\n",
        "results hold under alternative specifications. Let‚Äôs start with sample\n",
        "split."
      ],
      "id": "051bd93f-797b-47c5-ba01-1bd4799efe2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data at midpoint\n",
        "midpoint = len(factor) // 2\n",
        "dates_split = factor.index[midpoint]\n",
        "\n",
        "# First half\n",
        "market_1 = market.iloc[:midpoint]\n",
        "factor_1 = factor.iloc[:midpoint]\n",
        "\n",
        "# Second half\n",
        "market_2 = market.iloc[midpoint:]\n",
        "factor_2 = factor.iloc[midpoint:]\n",
        "\n",
        "def run_alpha_test(factor_ret, market_ret, period_name):\n",
        "    \"\"\"Run CAPM alpha test with HAC standard errors.\"\"\"\n",
        "    X = sm.add_constant(market_ret.values)\n",
        "    model = OLS(factor_ret.values, X).fit()\n",
        "    \n",
        "    # HAC standard errors\n",
        "    cov_hac_matrix = cov_hac(model, nlags=6)\n",
        "    se_hac = np.sqrt(np.diag(cov_hac_matrix))\n",
        "    t_hac = model.params / se_hac\n",
        "    \n",
        "    results = {\n",
        "        'Period': period_name,\n",
        "        'Alpha (% monthly)': model.params[0] * 100,\n",
        "        'HAC SE': se_hac[0] * 100,\n",
        "        't-statistic': t_hac[0],\n",
        "        'Significant?': 'Yes' if abs(t_hac[0]) > 1.96 else 'No',\n",
        "        'Beta': model.params[1],\n",
        "        'R¬≤': model.rsquared,\n",
        "        'Observations': len(factor_ret)\n",
        "    }\n",
        "    return results\n",
        "\n",
        "# Run tests\n",
        "results_1 = run_alpha_test(factor_1, market_1, \n",
        "                           f\"{factor.index[0].year}-{factor.index[midpoint-1].year}\")\n",
        "results_2 = run_alpha_test(factor_2, market_2, \n",
        "                           f\"{factor.index[midpoint].year}-{factor.index[-1].year}\")\n",
        "\n",
        "# Combine\n",
        "robustness = pd.DataFrame([results_1, results_2]).set_index('Period')\n",
        "\n",
        "print(\"=== Robustness Check: Sample Split ===\\n\")\n",
        "print(robustness.round(3))"
      ],
      "id": "1cbeda87"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  Is alpha significant in both periods?\n",
        "2.  Is alpha magnitude similar across periods, or does it change?\n",
        "3.  If alpha was significant in first period but not second, what might\n",
        "    that suggest?\n",
        "4.  If alpha is positive in one period but negative in another, is the\n",
        "    factor robust?\n",
        "5.  What conclusions would you draw about factor stability from this\n",
        "    test?\n",
        "\n",
        "**Key insight**: Robust factors show consistent performance across\n",
        "subsamples. If results hold only in one period, the factor might be\n",
        "sample-specific or driven by a unique market regime. Instability doesn‚Äôt\n",
        "definitively prove factor is spurious, but it raises questions about\n",
        "reliability and generalisability.\n",
        "\n",
        "### Exercise 3.2: Rolling Window Analysis\n",
        "\n",
        "Instead of just two periods, let‚Äôs look at how alpha evolves over time\n",
        "using rolling windows."
      ],
      "id": "77825821-a76d-4b3f-acbe-6ef277b8ded2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate rolling alpha (3-year window)\n",
        "window = 36  # months\n",
        "\n",
        "rolling_alpha = []\n",
        "rolling_dates = []\n",
        "\n",
        "for i in range(window, len(factor)):\n",
        "    factor_window = factor.iloc[i-window:i]\n",
        "    market_window = market.iloc[i-window:i]\n",
        "    \n",
        "    # CAPM regression\n",
        "    X = sm.add_constant(market_window.values)\n",
        "    model = OLS(factor_window.values, X).fit()\n",
        "    \n",
        "    rolling_alpha.append(model.params[0] * 12 * 100)  # Annualised %\n",
        "    rolling_dates.append(factor.index[i])\n",
        "\n",
        "rolling_alpha = pd.Series(rolling_alpha, index=rolling_dates)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(rolling_alpha.index, rolling_alpha.values, linewidth=2, label='Rolling Alpha (3-year window)')\n",
        "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5, label='Zero Alpha')\n",
        "plt.fill_between(rolling_alpha.index, 0, rolling_alpha.values, \n",
        "                 where=(rolling_alpha >= 0), alpha=0.3, label='Positive Alpha')\n",
        "plt.fill_between(rolling_alpha.index, 0, rolling_alpha.values, \n",
        "                 where=(rolling_alpha < 0), alpha=0.3, color='red', label='Negative Alpha')\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Annualised Alpha (%)', fontsize=12)\n",
        "plt.title('Factor Alpha Over Time (Rolling 3-Year Windows)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Rolling alpha statistics:\")\n",
        "print(f\"  Mean: {rolling_alpha.mean():.2f}%\")\n",
        "print(f\"  Std Dev: {rolling_alpha.std():.2f}%\")\n",
        "print(f\"  Min: {rolling_alpha.min():.2f}% ({rolling_alpha.idxmin().year})\")\n",
        "print(f\"  Max: {rolling_alpha.max():.2f}% ({rolling_alpha.idxmax().year})\")\n",
        "print(f\"  % periods with positive alpha: {(rolling_alpha > 0).mean()*100:.1f}%\")"
      ],
      "id": "207c66bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  How stable is alpha over time? Does it stay consistently\n",
        "    positive/negative?\n",
        "2.  Are there periods where alpha turns negative?\n",
        "3.  What might explain variation in rolling alpha? (Market regimes?\n",
        "    Structural changes? Arbitrage?)\n",
        "4.  If you observed this pattern in real data, would you conclude the\n",
        "    factor is reliably exploitable?\n",
        "\n",
        "**Key insight**: Rolling analysis reveals time-variation in factor\n",
        "performance. Factors can work in some periods and fail in others. Stable\n",
        "alpha is more convincing than alpha that fluctuates wildly or reverses\n",
        "sign. Instability might reflect changing market conditions, arbitrage\n",
        "eroding profits, or sample-specific luck.\n",
        "\n",
        "## Part 4: Critical Thinking About Factor Research\n",
        "\n",
        "### Exercise 4.1: Transaction Cost Reality Check\n",
        "\n",
        "Academic papers often report gross returns (before trading costs). But\n",
        "real investors face costs. Let‚Äôs explore how costs affect\n",
        "exploitability."
      ],
      "id": "2b385697-3895-43c0-abd5-6f8fa53e7406"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume our factor requires monthly rebalancing\n",
        "# Transaction costs depend on liquidity, portfolio size, and execution strategy\n",
        "# Realistic range: 0.1% - 0.5% per month (includes bid-ask spreads, commissions, market impact)\n",
        "\n",
        "cost_scenarios = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "# Recompute CAPM alpha here to avoid relying on earlier cells\n",
        "X_tc = sm.add_constant(market.values)\n",
        "model_tc = OLS(factor.values, X_tc).fit()\n",
        "alpha_tc = model_tc.params[0]\n",
        "\n",
        "# Calculate net alpha under different cost assumptions\n",
        "results_costs = []\n",
        "for cost in cost_scenarios:\n",
        "    gross_alpha = alpha_tc * 12 * 100  # Annualised %\n",
        "    net_alpha = gross_alpha - (cost * 12)  # Subtract annual cost\n",
        "    \n",
        "    results_costs.append({\n",
        "        'Monthly Cost (%)': cost,\n",
        "        'Annual Cost (%)': cost * 12,\n",
        "        'Gross Alpha (%)': gross_alpha,\n",
        "        'Net Alpha (%)': net_alpha,\n",
        "        'Exploitable?': 'Yes' if net_alpha > 1.0 else 'Marginal' if net_alpha > 0 else 'No'\n",
        "    })\n",
        "\n",
        "costs_df = pd.DataFrame(results_costs)\n",
        "print(\"=== Transaction Cost Impact on Alpha ===\\n\")\n",
        "print(costs_df.round(2))\n",
        "\n",
        "# Visualise\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(costs_df['Monthly Cost (%)'], costs_df['Net Alpha (%)'], \n",
        "         marker='o', linewidth=2, markersize=8)\n",
        "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5, label='Break-even')\n",
        "plt.axhline(y=1, color='orange', linestyle='--', alpha=0.5, label='Minimum meaningful alpha')\n",
        "plt.xlabel('Monthly Transaction Cost (%)', fontsize=12)\n",
        "plt.ylabel('Net Annualised Alpha (%)', fontsize=12)\n",
        "plt.title('How Transaction Costs Erode Factor Alpha', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "718633bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  At what transaction cost level does net alpha turn negative?\n",
        "2.  Even if net alpha is positive, is it large enough to justify\n",
        "    implementation?\n",
        "3.  How do transaction costs affect the ‚Äúbreak-even‚Äù account size for\n",
        "    implementing a factor?\n",
        "4.  Why might high-turnover factors (like momentum) be harder to exploit\n",
        "    than low-turnover factors (like value)?\n",
        "5.  If you read a paper reporting 8% gross alpha, what questions would\n",
        "    you ask about exploitability?\n",
        "\n",
        "**Key insight**: Gross alpha overstates exploitability. Always consider\n",
        "transaction costs, especially for high-turnover strategies. Even\n",
        "statistically significant alpha can be economically meaningless after\n",
        "costs. This is a major reason many published factors fail in real-world\n",
        "implementation.\n",
        "\n",
        "### Exercise 4.2: Selection Bias Simulation\n",
        "\n",
        "Let‚Äôs simulate the multiple testing problem that creates false\n",
        "discoveries in factor research."
      ],
      "id": "cbc60194-255d-4d0e-afc9-6d8f04a55f58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate many researchers each testing a potential \"factor\"\n",
        "# None of these factors have true alpha (all are pure noise)\n",
        "# But some will appear significant just by luck (5% false positive rate)\n",
        "\n",
        "num_researchers = 100\n",
        "num_obs = 240\n",
        "significance_level = 0.05\n",
        "\n",
        "# Storage for results\n",
        "p_values = []\n",
        "significant_factors = []\n",
        "\n",
        "for i in range(num_researchers):\n",
        "    # Generate random \"factor\" and market with zero true alpha (mean 0)\n",
        "    random_factor = np.random.normal(0.0, 0.04, num_obs)\n",
        "    market_sim = np.random.normal(0.0, 0.04, num_obs)\n",
        "    \n",
        "    # Test for alpha\n",
        "    X = sm.add_constant(market_sim)\n",
        "    model = OLS(random_factor, X).fit()\n",
        "    \n",
        "    p_values.append(model.pvalues[0])\n",
        "    \n",
        "    # \"Publish\" if significant\n",
        "    if model.pvalues[0] < significance_level:\n",
        "        significant_factors.append({\n",
        "            'Factor': i+1,\n",
        "            'Alpha (% monthly)': model.params[0] * 100,\n",
        "            't-statistic': model.tvalues[0],\n",
        "            'p-value': model.pvalues[0]\n",
        "        })\n",
        "\n",
        "# How many false positives?\n",
        "num_significant = len(significant_factors)\n",
        "expected_false = num_researchers * significance_level\n",
        "\n",
        "print(f\"=== Selection Bias Simulation ===\")\n",
        "print(f\"Number of 'factors' tested: {num_researchers}\")\n",
        "print(f\"True alpha for all factors: 0% (pure noise)\")\n",
        "print(f\"Significance level: {significance_level*100}%\")\n",
        "print(f\"\\nRESULTS:\")\n",
        "print(f\"  Number appearing 'significant': {num_significant}\")\n",
        "print(f\"  Expected false positives: {expected_false:.1f}\")\n",
        "print(f\"  All significant findings are FALSE POSITIVES (Type I errors)\")\n",
        "\n",
        "if significant_factors:\n",
        "    print(f\"\\n'Published' Factors:\")\n",
        "    print(pd.DataFrame(significant_factors).round(3))\n",
        "\n",
        "print(f\"\\nIMPLICATION:\")\n",
        "print(f\"  If only 'significant' factors get published, the literature\")\n",
        "print(f\"  overrepresents spurious findings by construction.\")\n",
        "print(f\"  This is the source of the replication crisis.\")\n",
        "\n",
        "# Distribution of p-values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(p_values, bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=0.05, color='red', linestyle='--', linewidth=2, label='Significance threshold')\n",
        "plt.xlabel('p-value', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Distribution of p-values for Null Factors (True Alpha = 0)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "c7cc47c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Discussion questions:**\n",
        "\n",
        "1.  How many ‚Äúsignificant‚Äù results appeared even though true alpha is\n",
        "    zero?\n",
        "2.  Is this close to the expected 5% false positive rate?\n",
        "3.  If journals only publish significant results, what fraction of\n",
        "    published factors are false positives?\n",
        "4.  How does this simulation relate to the ~300 published equity factors\n",
        "    in real finance literature?\n",
        "5.  What practices could reduce false discovery rate? (Pre-registration?\n",
        "    Higher significance thresholds? Out-of-sample testing?)\n",
        "\n",
        "**Key insight**: Multiple testing creates false discoveries even under\n",
        "rigorous statistical practices. With hundreds of factors tested, many\n",
        "spurious findings get published whilst null results remain in file\n",
        "drawers. This selection bias inflates published returns and explains why\n",
        "many factors fail replication. Jensen et al.¬†(2024) document this\n",
        "systematically.\n",
        "\n",
        "## Part 5: Connecting to Coursework 2\n",
        "\n",
        "### What You‚Äôve Learned vs.¬†What You‚Äôll Apply\n",
        "\n",
        "**Today‚Äôs lab explored concepts:**\n",
        "\n",
        "-   HAC standard errors correct for autocorrelation (prevents false\n",
        "    positives)\n",
        "-   Alpha tests isolate excess returns beyond market exposure\n",
        "-   Robustness checks (sample split, rolling windows) test stability\n",
        "-   Transaction costs reduce net alpha (affects exploitability)\n",
        "-   Selection bias creates false discoveries (replication crisis)\n",
        "\n",
        "**For Coursework 2, you‚Äôll:**\n",
        "\n",
        "1.  Use scaffold notebook to run these analyses on real JKP factor data\n",
        "2.  Interpret outputs using understanding developed today\n",
        "3.  Write critical analysis discussing significance, robustness,\n",
        "    limitations\n",
        "4.  Engage with Jensen et al.¬†(2024) on selection bias and replication\n",
        "5.  Provide investment recommendations considering costs and risks\n",
        "\n",
        "### Critical Analysis Questions to Ask\n",
        "\n",
        "When interpreting your Coursework 2 results, ask:\n",
        "\n",
        "**Statistical questions:**\n",
        "\n",
        "-   Is alpha statistically significant using HAC standard errors?\n",
        "-   How does significance change if you use higher threshold (t \\> 3)?\n",
        "-   Are results robust to sample split? If not, why?\n",
        "\n",
        "**Economic questions:**\n",
        "\n",
        "-   What is alpha magnitude after transaction costs?\n",
        "-   Is net alpha large enough to justify implementation?\n",
        "-   How does your result compare to original published paper?\n",
        "\n",
        "**Methodological questions:**\n",
        "\n",
        "-   Could selection bias explain why original paper found stronger\n",
        "    results?\n",
        "-   Has factor performance declined post-publication (arbitrage\n",
        "    erosion)?\n",
        "-   What limitations affect your replication (data, sample period,\n",
        "    methodology)?\n",
        "\n",
        "**Investment questions:**\n",
        "\n",
        "-   Would you recommend implementing this factor in a real portfolio?\n",
        "-   What risks and constraints would practitioners face?\n",
        "-   What further robustness tests would you want before making\n",
        "    investment decision?\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1.  **Read Jensen et al.¬†(2024)**: ‚ÄúIs There a Replication Crisis in\n",
        "    Finance?‚Äù ‚Äî Essential for understanding replication methodology and\n",
        "    selection bias\n",
        "2.  **Run scaffold notebook**: See what actual outputs look like with\n",
        "    real JKP data\n",
        "3.  **Choose factor**: Value (HML) or Momentum (MOM) are\n",
        "    well-documented; Quality (RMW) or Size (SMB) also work\n",
        "4.  **Draft interpretation**: Practice writing paragraphs interpreting\n",
        "    alpha, robustness, limitations\n",
        "5.  **Office hours**: Ask conceptual questions about interpretation (not\n",
        "    code debugging)\n",
        "\n",
        "## Summary\n",
        "\n",
        "Today‚Äôs lab developed principles for factor replication:\n",
        "\n",
        "-   **HAC standard errors** are essential for honest inference in\n",
        "    time-series data\n",
        "-   **Alpha tests** reveal excess returns, but significance ‚â†\n",
        "    exploitability\n",
        "-   **Robustness checks** separate real patterns from sample-specific\n",
        "    noise\n",
        "-   **Transaction costs** can eliminate seemingly significant alpha\n",
        "-   **Selection bias** inflates published results, explaining\n",
        "    replication failures\n",
        "\n",
        "**These principles enable critical analysis**‚Äîthe 35% component of\n",
        "Coursework 2. Scaffold provides outputs; understanding provides\n",
        "interpretation. Focus your effort on thinking deeply about what results\n",
        "mean, not on perfecting code.\n",
        "\n",
        "**Week 11 preview**: Market prediction using factors. Same\n",
        "principle-focused approach‚Äîunderstanding concepts, not copying\n",
        "templates."
      ],
      "id": "6d63cbff-0e00-43f8-9b79-509620a1647b"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "fin510",
      "display_name": "FIN510 Python",
      "language": "python",
      "path": "/Users/quinference/Library/Jupyter/kernels/fin510"
    }
  }
}