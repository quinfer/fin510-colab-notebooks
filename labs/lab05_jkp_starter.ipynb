{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5: JKP Factor Starter\n",
        "\n",
        "<figure>\n",
        "<a\n",
        "href=\"https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab05_jkp_starter.ipynb\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "<figcaption>Open in Colab</figcaption>\n",
        "</figure>\n",
        "\n",
        "## Before You Code: The Big Picture\n",
        "\n",
        "The **Jensen, Kelly, and Pedersen (JKP) factor dataset** contains\n",
        "returns for hundreds of documented investment factors from academic\n",
        "research. This is the gold standard for factor replication studies—and\n",
        "it’s what you’ll use for Coursework 2.\n",
        "\n",
        "> **What Are Factors?**\n",
        ">\n",
        "> **Factors** are characteristics that explain cross-sectional stock\n",
        "> returns: - **Momentum (MOM)**: Past winners outperform past losers -\n",
        "> **Value (HML)**: Cheap stocks outperform expensive stocks (High Minus\n",
        "> Low book-to-market) - **Size (SMB)**: Small stocks outperform large\n",
        "> stocks (Small Minus Big) - **Quality, Profitability, Investment**:\n",
        "> Other documented anomalies\n",
        ">\n",
        "> **Why They Matter:** - If factors work, you can build systematic\n",
        "> strategies around them - If factors are spurious (data mining), they\n",
        "> won’t persist out-of-sample - Factor replication tests whether\n",
        "> published findings are real or lucky\n",
        ">\n",
        "> **Your Task in Coursework 2:** Pick a factor, replicate it using JKP\n",
        "> data, evaluate performance with rigorous backtesting, and critically\n",
        "> assess whether it’s exploitable.\n",
        "\n",
        "### What You’ll Learn Today\n",
        "\n",
        "This is a **quick starter lab** to familiarize you with:\n",
        "\n",
        "-   ✅ Loading JKP factor data (monthly returns)\n",
        "-   ✅ Computing CAPM alpha (does factor beat the market?)\n",
        "-   ✅ Basic prediction setup (OLS vs Ridge for next-month market\n",
        "    return)\n",
        "-   ✅ Understanding what you’ll extend for Coursework 2\n",
        "\n",
        "**Time estimate:** 20-30 minutes (this is intentionally brief—real work\n",
        "happens in your coursework)\n",
        "\n",
        "> **Coursework 2 Preview**\n",
        ">\n",
        "> This lab shows the **minimal skeleton**. For Coursework 2, you’ll: -\n",
        "> Use full JKP dataset (not just this sample) - Implement walk-forward\n",
        "> validation (not simple train/test split) - Add HAC standard errors\n",
        "> (Newey-West) for proper inference - Calculate out-of-sample R², Sharpe\n",
        "> ratios, CER gains - Write critical analysis of replication results\n",
        "\n",
        "## Objective\n",
        "\n",
        "-   Load a small JKP factor slice (CSV) and compute rolling alpha vs\n",
        "    market.  \n",
        "-   Run a tiny prediction baseline (OLS vs ridge) for next‑month `MKT`.\n",
        "-   Understand the scaffolding you’ll extend for Coursework 2.\n",
        "\n",
        "## 1) Load data (JKP CSV or course sample)\n",
        "\n",
        "``` python\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Option A: point to your downloaded JKP CSV\n",
        "# jkp = pd.read_csv('/content/JKP_region_monthly.csv')\n",
        "\n",
        "# Option B: use course sample (small demo)\n",
        "sample_url = 'https://raw.githubusercontent.com/quinfer/fin510-colab-notebooks/main/resources/jkp-sample.csv'\n",
        "jkp = pd.read_csv(sample_url)\n",
        "\n",
        "# Expect columns: date, MKT, SMB, HML, MOM (monthly)\n",
        "jkp['date'] = pd.to_datetime(jkp['date'])\n",
        "jkp = jkp.set_index('date').sort_index()\n",
        "jkp.head()\n",
        "```\n",
        "\n",
        "## 2) Rolling alpha vs market (HAC optional in project)\n",
        "\n",
        "``` python\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "ls_ret = jkp['MOM'].dropna()  # example: long-short momentum\n",
        "mkt    = jkp['MKT'].reindex(ls_ret.index)\n",
        "\n",
        "# Simple CAPM alpha (no HAC here to keep the lab minimal)\n",
        "capm = sm.OLS(ls_ret, sm.add_constant(mkt)).fit()\n",
        "alpha = capm.params['const']\n",
        "alpha_t = capm.tvalues['const']\n",
        "alpha, alpha_t\n",
        "```\n",
        "\n",
        "## 3) Tiny prediction baseline (OLS vs ridge)\n",
        "\n",
        "``` python\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Predict next-month MKT using lagged features\n",
        "X = pd.concat({\n",
        "    'mkt_l1': jkp['MKT'].shift(1),\n",
        "    'mom_l1': jkp['MOM'].shift(1),\n",
        "}, axis=1).dropna()\n",
        "y = jkp['MKT'].reindex(X.index)\n",
        "\n",
        "split = int(len(X)*0.7)\n",
        "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
        "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
        "\n",
        "ols = LinearRegression().fit(X_train, y_train)\n",
        "ridge = Ridge(alpha=5.0).fit(X_train, y_train)\n",
        "\n",
        "ols_rmse  = mean_squared_error(y_test, ols.predict(X_test), squared=False)\n",
        "rid_rmse  = mean_squared_error(y_test, ridge.predict(X_test), squared=False)\n",
        "{'ols_rmse': ols_rmse, 'ridge_rmse': rid_rmse}\n",
        "```\n",
        "\n",
        "## 4) Notes\n",
        "\n",
        "-   For the assessment: extend the windowing to a walk‑forward scheme\n",
        "    and add evaluation (`R²_oos`, CER gain, etc.).  \n",
        "-   Replace the sample with your JKP CSV; document your exact\n",
        "    filters/version/date.  \n",
        "-   Use HAC standard errors for regression inference in the project."
      ],
      "id": "e903cd23-3d6e-45b3-aaa5-f1ab8491423b"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}