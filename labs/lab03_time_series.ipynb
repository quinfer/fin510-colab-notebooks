{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3: Time Series Foundations\n",
        "\n",
        "Stationarity, ARIMA, and Forecasting with Bloomberg Data\n",
        "\n",
        "Financial Data Science\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "1.  Test time series for stationarity using visual and statistical\n",
        "    methods\n",
        "2.  Interpret ACF and PACF plots to identify AR/MA patterns\n",
        "3.  Fit ARIMA models to financial data\n",
        "4.  Perform walk-forward validation for time series forecasts\n",
        "5.  Compare forecast accuracy across different models\n",
        "\n",
        "## Setup"
      ],
      "id": "9cb77313-567f-451a-988e-d63d3ef8d78d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Time series tools\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, acf, pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Validation\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Settings\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# Data root (config/data_root.yml or repo data/)\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "try:\n",
        "    with open(Path(\"config/data_root.yml\")) as f:\n",
        "        cfg = yaml.safe_load(f)\n",
        "    data_root = Path(cfg.get(\"data_root\", \"data\")).expanduser().resolve()\n",
        "except Exception:\n",
        "    data_root = Path(\"data\")"
      ],
      "id": "setup"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Stationarity Diagnostics\n",
        "\n",
        "### 1.1 Load Bloomberg Database"
      ],
      "id": "3b09f323-a842-42fb-a9b3-f3103836bd68"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resolve path: local (repo root / labs / labs/notebooks) or Colab (raw URL)\n",
        "from pathlib import Path\n",
        "COLAB_DB_URL = \"https://raw.githubusercontent.com/quinfer/fin510-colab-notebooks/main/resources/bloomberg_database.parquet\"\n",
        "_candidates = [\n",
        "    data_root / \"bloomberg_database/bloomberg_database.parquet\",\n",
        "    Path(\"data/bloomberg_database/bloomberg_database.parquet\"),   # project root\n",
        "    Path(\"../data/bloomberg_database/bloomberg_database.parquet\"), # labs/\n",
        "    Path(\"../../data/bloomberg_database/bloomberg_database.parquet\"), # labs/notebooks/\n",
        "]\n",
        "_data_path = next((p for p in _candidates if p.exists()), None)\n",
        "if _data_path is not None:\n",
        "    df = pd.read_parquet(_data_path)\n",
        "else:\n",
        "    # Fallback: Colab or any env where DB is fetched from public repo\n",
        "    df = pd.read_parquet(COLAB_DB_URL)\n",
        "\n",
        "# Preview\n",
        "print(df.head())\n",
        "print(f\"\\nAssets available: {df['ticker'].unique()}\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")"
      ],
      "id": "load-data"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Visual Inspection: Prices vs Returns\n",
        "\n",
        "**Task:** Compare SPY prices and returns to diagnose stationarity."
      ],
      "id": "fe1af543-0f31-46fe-a0be-f56f71af66a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract SPY data\n",
        "spy = df[df['ticker'] == 'SPY'].set_index('date').sort_index()\n",
        "\n",
        "# Calculate returns (already in data, but let's recalculate for clarity)\n",
        "spy['return'] = spy['PX_LAST'].pct_change()\n",
        "\n",
        "# Plot prices and returns\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
        "\n",
        "# Prices\n",
        "axes[0].plot(spy.index, spy['PX_LAST'], linewidth=1, color='steelblue')\n",
        "axes[0].set_ylabel('Price ($)')\n",
        "axes[0].set_title('SPY Prices: Clear Trend (Non-Stationary?)')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Returns\n",
        "axes[1].plot(spy.index, spy['return'], linewidth=0.5, color='coral', alpha=0.7)\n",
        "axes[1].axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
        "axes[1].set_ylabel('Daily Return')\n",
        "axes[1].set_xlabel('Date')\n",
        "axes[1].set_title('SPY Returns: Fluctuates Around Zero (Stationary?)')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "spy-visual"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 1.1**\n",
        ">\n",
        "> Based on visual inspection alone: - Do SPY prices appear stationary?\n",
        "> Why or why not? - Do SPY returns appear stationary? Why or why not?\n",
        "\n",
        "### 1.3 ACF Diagnostic\n",
        "\n",
        "The Autocorrelation Function (ACF) provides evidence for stationarity: -\n",
        "**Stationary**: ACF drops quickly to zero - **Non-stationary**: ACF\n",
        "decays slowly"
      ],
      "id": "a758fd20-8696-4120-a370-8c5ff2afcf4c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ACF of prices\n",
        "plot_acf(spy['PX_LAST'].dropna(), ax=axes[0], lags=40, title='ACF: SPY Prices')\n",
        "axes[0].set_ylabel('Autocorrelation')\n",
        "\n",
        "# ACF of returns\n",
        "plot_acf(spy['return'].dropna(), ax=axes[1], lags=40, title='ACF: SPY Returns')\n",
        "axes[1].set_ylabel('Autocorrelation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "spy-acf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 1.2**\n",
        ">\n",
        "> -   Which ACF plot shows slow decay?\n",
        "> -   Which ACF plot shows rapid decay to zero?\n",
        "> -   What does this tell you about stationarity?\n",
        "\n",
        "### 1.4 Augmented Dickey-Fuller Test\n",
        "\n",
        "The ADF test formalises the stationarity check: - **Null hypothesis**:\n",
        "Series has a unit root (non-stationary) - **Alternative**: Series is\n",
        "stationary - **Decision**: If p-value \\< 0.05, reject null → series is\n",
        "stationary"
      ],
      "id": "ece276f0-8d89-477e-9e49-ab7ff7da54d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adf_test(series, name):\n",
        "    \"\"\"Perform ADF test and print results\"\"\"\n",
        "    result = adfuller(series.dropna())\n",
        "    print(f\"\\nADF Test: {name}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"ADF Statistic: {result[0]:.4f}\")\n",
        "    print(f\"p-value: {result[1]:.4f}\")\n",
        "    print(f\"Critical Values:\")\n",
        "    for key, value in result[4].items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    \n",
        "    if result[1] < 0.05:\n",
        "        print(f\"✓ Conclusion: {name} is STATIONARY (reject null at 5%)\")\n",
        "    else:\n",
        "        print(f\"✗ Conclusion: {name} is NON-STATIONARY (fail to reject null)\")\n",
        "    return result\n",
        "\n",
        "# Test prices\n",
        "adf_prices = adf_test(spy['PX_LAST'], \"SPY Prices\")\n",
        "\n",
        "# Test returns\n",
        "adf_returns = adf_test(spy['return'], \"SPY Returns\")"
      ],
      "id": "spy-adf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 1.3**\n",
        ">\n",
        "> -   Do the ADF test results confirm your visual intuition?\n",
        "> -   Why is the p-value for returns much smaller than for prices?\n",
        "\n",
        "### 1.5 Exercise: Test VIX for Stationarity\n",
        "\n",
        "**Your task:** Apply the same diagnostics to the VIX index."
      ],
      "id": "5aa60f5b-cb3d-4d83-9ef4-1e458cea7018"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract VIX data\n",
        "vix = df[df['ticker'] == 'VIX'].set_index('date').sort_index()\n",
        "\n",
        "# YOUR CODE HERE:\n",
        "# 1. Plot VIX over time\n",
        "# 2. Plot ACF\n",
        "# 3. Run ADF test\n",
        "# 4. Interpret results: Is VIX stationary?\n",
        "\n",
        "# Solution (uncomment to run):\n",
        "# fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
        "# \n",
        "# # Time plot\n",
        "# axes[0].plot(vix.index, vix['PX_LAST'], linewidth=0.8, color='coral')\n",
        "# axes[0].axhline(vix['PX_LAST'].mean(), color='steelblue', linestyle='--', \n",
        "#                 label=f'Mean: {vix[\"PX_LAST\"].mean():.1f}')\n",
        "# axes[0].set_ylabel('VIX Level')\n",
        "# axes[0].set_title('VIX: Mean-Reverting but Clustered')\n",
        "# axes[0].legend()\n",
        "# axes[0].grid(alpha=0.3)\n",
        "# \n",
        "# # ACF\n",
        "# plot_acf(vix['PX_LAST'].dropna(), ax=axes[1], lags=40, title='ACF: VIX')\n",
        "# axes[1].set_xlabel('Lag')\n",
        "# \n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "# \n",
        "# # ADF test\n",
        "# adf_test(vix['PX_LAST'], \"VIX\")"
      ],
      "id": "vix-exercise"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Hint**\n",
        ">\n",
        "> VIX is bounded (can’t go negative, rarely exceeds 80) and\n",
        "> mean-reverting, but it shows persistence. The ADF test result may be\n",
        "> borderline.\n",
        "\n",
        "## Part 2: ACF and PACF Interpretation\n",
        "\n",
        "### 2.1 Volatility Clustering Preview\n",
        "\n",
        "Remember from the slides: returns are unpredictable, but **volatility**\n",
        "is predictable."
      ],
      "id": "24aae467-0e3f-4785-8cb5-16e3bce95dcb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spy['return_sq'] = spy['return'] ** 2\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ACF of returns\n",
        "plot_acf(spy['return'].dropna(), ax=axes[0], lags=40, title='ACF: Returns (No Pattern)')\n",
        "axes[0].set_ylabel('Autocorrelation')\n",
        "\n",
        "# ACF of squared returns\n",
        "plot_acf(spy['return_sq'].dropna(), ax=axes[1], lags=40, \n",
        "         title='ACF: Squared Returns (Strong Persistence)')\n",
        "axes[1].set_ylabel('Autocorrelation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "volatility-clustering"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 2.1**\n",
        ">\n",
        "> -   Why do returns show no autocorrelation?\n",
        "> -   Why do **squared** returns show strong autocorrelation?\n",
        "> -   What does this tell you about market efficiency vs volatility?\n",
        "\n",
        "### 2.2 PACF: Identifying AR vs MA\n",
        "\n",
        "The **Partial ACF** isolates direct lag effects.\n",
        "\n",
        "**Interpretation rules:**\n",
        "\n",
        "| Process   | ACF Pattern          | PACF Pattern         |\n",
        "|-----------|----------------------|----------------------|\n",
        "| AR(p)     | Exponential decay    | Cuts off after lag p |\n",
        "| MA(q)     | Cuts off after lag q | Exponential decay    |\n",
        "| ARMA(p,q) | Both decay           | Both decay           |"
      ],
      "id": "fffcdaa1-4e3a-4820-851b-29fd293918da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ACF\n",
        "plot_acf(vix['PX_LAST'].dropna(), ax=axes[0], lags=20, title='ACF: VIX')\n",
        "\n",
        "# PACF\n",
        "plot_pacf(vix['PX_LAST'].dropna(), ax=axes[1], lags=20, title='PACF: VIX')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "vix-acf-pacf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 2.2**\n",
        ">\n",
        "> Looking at the VIX ACF and PACF: - Does the PACF cut off sharply after\n",
        "> lag 1? - Does the ACF decay gradually? - What does this pattern\n",
        "> suggest? (Hint: AR process)\n",
        "\n",
        "## Part 3: Fitting ARIMA Models\n",
        "\n",
        "The standard workflow is the **Box–Jenkins approach**: (1) identify\n",
        "order using ACF/PACF, (2) estimate the model, (3) diagnose residuals\n",
        "(check for white noise). If residuals show autocorrelation, consider\n",
        "more lags or a different specification (Brooks, 2019, Ch 5).\n",
        "\n",
        "### 3.1 AR(1) Model for VIX\n",
        "\n",
        "Let’s fit an AR(1) model: $VIX_t = c + \\phi_1 VIX_{t-1} + \\varepsilon_t$"
      ],
      "id": "00335bc4-4198-4b97-b6ec-0b4ea21395c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit AR(1) = ARIMA(1,0,0)\n",
        "model_ar1 = ARIMA(vix['PX_LAST'].dropna(), order=(1, 0, 0))\n",
        "results_ar1 = model_ar1.fit()\n",
        "\n",
        "# Print summary\n",
        "print(results_ar1.summary())\n",
        "\n",
        "# Plot fitted values\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "ax.plot(vix.index, vix['PX_LAST'], label='Observed', \n",
        "        linewidth=0.8, alpha=0.7, color='coral')\n",
        "ax.plot(vix.index, results_ar1.fittedvalues, \n",
        "        label='AR(1) Fitted', linewidth=1.5, color='steelblue')\n",
        "ax.set_ylabel('VIX Level')\n",
        "ax.set_title('VIX: AR(1) Model Fit')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "ar1-fit"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 3.1**\n",
        ">\n",
        "> -   Is the AR coefficient ($\\phi_1$) significantly different from\n",
        ">     zero?\n",
        "> -   What is the value of $\\phi_1$? How persistent is VIX?\n",
        "> -   Does the fitted line track the observed VIX reasonably well?\n",
        "\n",
        "### 3.2 Model Diagnostics: Residuals\n",
        "\n",
        "Good models should have **white noise residuals** (uncorrelated, mean\n",
        "zero). The **Ljung–Box test** jointly tests whether the first $m$\n",
        "autocorrelations of the residuals are zero: $H_0$:\n",
        "$\\rho_1 = \\cdots = \\rho_m = 0$. If the p-value is **greater than 0.05**,\n",
        "we fail to reject $H_0$ and treat residuals as white noise; if p-value\n",
        "**less than 0.05**, we reject and should consider more lags or a\n",
        "different model (Tsay, 2010, Ch 2)."
      ],
      "id": "4564825f-4d39-4120-b0a9-9961d56798db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get residuals\n",
        "residuals = results_ar1.resid\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Time plot\n",
        "axes[0, 0].plot(residuals, linewidth=0.5, color='gray')\n",
        "axes[0, 0].axhline(0, color='red', linestyle='--', linewidth=0.5)\n",
        "axes[0, 0].set_title('Residuals Over Time')\n",
        "axes[0, 0].set_xlabel('Time')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Histogram\n",
        "axes[0, 1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_title('Residual Distribution')\n",
        "axes[0, 1].set_xlabel('Residual')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# ACF\n",
        "plot_acf(residuals, ax=axes[1, 0], lags=20, title='ACF: Residuals')\n",
        "\n",
        "# Q-Q plot\n",
        "sm.qqplot(residuals, line='45', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Q-Q Plot: Residuals vs Normal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Ljung-Box test for residual autocorrelation\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "lb_test = acorr_ljungbox(residuals, lags=10, return_df=True)\n",
        "print(\"\\nLjung-Box Test (H0: residuals are white noise):\")\n",
        "print(lb_test[['lb_stat', 'lb_pvalue']].head())"
      ],
      "id": "ar1-diagnostics"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 3.2**\n",
        ">\n",
        "> -   Do residuals look randomly scattered around zero?\n",
        "> -   Is there remaining autocorrelation in the ACF plot?\n",
        "> -   Are residuals approximately normally distributed?\n",
        "\n",
        "### 3.3 Exercise: Fit ARIMA to SPY Prices\n",
        "\n",
        "**Your task:** SPY prices are non-stationary. Fit an ARIMA(1,1,0) model\n",
        "(random walk with drift)."
      ],
      "id": "07170182-43d2-4a76-9a78-f0366db64ef5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE:\n",
        "# 1. Fit ARIMA(1,1,0) to SPY prices\n",
        "# 2. Print summary\n",
        "# 3. Plot fitted values\n",
        "# 4. Check residuals\n",
        "\n",
        "# Solution (uncomment to run):\n",
        "# model_spy = ARIMA(spy['PX_LAST'].dropna(), order=(1, 1, 0))\n",
        "# results_spy = model_spy.fit()\n",
        "# print(results_spy.summary())\n",
        "# \n",
        "# fig, ax = plt.subplots(figsize=(12, 5))\n",
        "# ax.plot(spy.index, spy['PX_LAST'], label='Observed', alpha=0.7)\n",
        "# ax.plot(spy.index, results_spy.fittedvalues, label='ARIMA(1,1,0) Fitted')\n",
        "# ax.legend()\n",
        "# plt.show()"
      ],
      "id": "spy-arima-exercise"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Hint**\n",
        ">\n",
        "> ARIMA(1,1,0) = first difference + AR(1) = random walk with\n",
        "> mean-reversion tendency.\n",
        "\n",
        "## Part 4: Forecasting and Validation\n",
        "\n",
        "### 4.1 Simple Baselines\n",
        "\n",
        "Before fitting complex models, establish **naive** and **mean**\n",
        "baselines."
      ],
      "id": "90f59b42-667d-4c32-bb64-7095a330ea37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use last 100 days for demonstration\n",
        "vix_recent = vix['PX_LAST'].iloc[-100:].dropna()\n",
        "\n",
        "# Split: 80% train, 20% test\n",
        "train_size = int(0.8 * len(vix_recent))\n",
        "vix_train = vix_recent.iloc[:train_size]\n",
        "vix_test = vix_recent.iloc[train_size:]\n",
        "\n",
        "# Naive forecast: last observed value\n",
        "naive_pred = np.full_like(vix_test, vix_train.iloc[-1])\n",
        "\n",
        "# Mean forecast: historical average\n",
        "mean_pred = np.full_like(vix_test, vix_train.mean())\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "ax.plot(vix_train.index, vix_train, label='Training', color='steelblue')\n",
        "ax.plot(vix_test.index, vix_test, label='Test (Actual)', \n",
        "        color='black', linewidth=2)\n",
        "ax.plot(vix_test.index, naive_pred, label='Naive Forecast', \n",
        "        linestyle='--', color='coral')\n",
        "ax.plot(vix_test.index, mean_pred, label='Mean Forecast', \n",
        "        linestyle='--', color='green')\n",
        "ax.set_ylabel('VIX Level')\n",
        "ax.set_title('VIX: Baseline Forecasts')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "naive_mae = mean_absolute_error(vix_test, naive_pred)\n",
        "mean_mae = mean_absolute_error(vix_test, mean_pred)\n",
        "\n",
        "print(f\"Naive MAE: {naive_mae:.4f}\")\n",
        "print(f\"Mean MAE: {mean_mae:.4f}\")\n",
        "print(f\"\\nBest baseline: {'Naive' if naive_mae < mean_mae else 'Mean'}\")"
      ],
      "id": "baselines"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 4.1**\n",
        ">\n",
        "> -   Which baseline performs better?\n",
        "> -   Why might the mean forecast work well for VIX?\n",
        "\n",
        "### 4.2 AR(1) vs Baselines\n",
        "\n",
        "Does AR(1) beat naive?"
      ],
      "id": "f2bea149-ad7e-462d-b33d-85447ca0a9c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit AR(1) on training data\n",
        "model_train = ARIMA(vix_train, order=(1, 0, 0))\n",
        "results_train = model_train.fit()\n",
        "\n",
        "# Forecast\n",
        "forecast = results_train.forecast(steps=len(vix_test))\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "ax.plot(vix_train.index, vix_train, label='Training', color='steelblue')\n",
        "ax.plot(vix_test.index, vix_test, label='Test (Actual)', \n",
        "        color='black', linewidth=2)\n",
        "ax.plot(vix_test.index, naive_pred, label='Naive', \n",
        "        linestyle='--', color='coral', alpha=0.7)\n",
        "ax.plot(vix_test.index, forecast.values, label='AR(1) Forecast', \n",
        "        linestyle='--', color='purple', linewidth=2)\n",
        "ax.set_ylabel('VIX Level')\n",
        "ax.set_title('VIX: AR(1) vs Naive Forecast')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "ar1_mae = mean_absolute_error(vix_test, forecast)\n",
        "\n",
        "print(f\"\\nForecast Accuracy (MAE):\")\n",
        "print(f\"  Naive:  {naive_mae:.4f}\")\n",
        "print(f\"  Mean:   {mean_mae:.4f}\")\n",
        "print(f\"  AR(1):  {ar1_mae:.4f}\")\n",
        "print(f\"\\nBest model: AR(1)\" if ar1_mae < min(naive_mae, mean_mae) else \"Best model: Baseline\")"
      ],
      "id": "ar1-forecast"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 4.2**\n",
        ">\n",
        "> -   Does AR(1) beat the baselines?\n",
        "> -   If yes, by how much?\n",
        "> -   Is the improvement economically meaningful?\n",
        "\n",
        "### 4.3 Walk-Forward Validation\n",
        "\n",
        "Single train/test split is risky. Use **time series cross-validation**."
      ],
      "id": "21388c9b-f677-442f-a87c-04f4f74b81c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use full VIX series\n",
        "vix_full = vix['PX_LAST'].dropna()\n",
        "\n",
        "# Walk-forward with 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5, test_size=50)\n",
        "\n",
        "naive_errors = []\n",
        "ar1_errors = []\n",
        "\n",
        "for train_idx, test_idx in tscv.split(vix_full):\n",
        "    # Split\n",
        "    train = vix_full.iloc[train_idx]\n",
        "    test = vix_full.iloc[test_idx]\n",
        "    \n",
        "    # Naive forecast\n",
        "    naive_pred = np.full_like(test, train.iloc[-1])\n",
        "    naive_errors.append(mean_absolute_error(test, naive_pred))\n",
        "    \n",
        "    # AR(1) forecast\n",
        "    model = ARIMA(train, order=(1, 0, 0))\n",
        "    results = model.fit()\n",
        "    ar1_pred = results.forecast(steps=len(test))\n",
        "    ar1_errors.append(mean_absolute_error(test, ar1_pred))\n",
        "\n",
        "# Results\n",
        "print(\"Walk-Forward Cross-Validation (5 splits):\")\n",
        "print(f\"  Naive MAE (average): {np.mean(naive_errors):.4f} ± {np.std(naive_errors):.4f}\")\n",
        "print(f\"  AR(1) MAE (average): {np.mean(ar1_errors):.4f} ± {np.std(ar1_errors):.4f}\")\n",
        "print(f\"\\nWinner: {'AR(1)' if np.mean(ar1_errors) < np.mean(naive_errors) else 'Naive'}\")\n",
        "\n",
        "# Plot errors across splits\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "x = np.arange(1, 6)\n",
        "ax.plot(x, naive_errors, 'o-', label='Naive', linewidth=2, markersize=8)\n",
        "ax.plot(x, ar1_errors, 's-', label='AR(1)', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Split')\n",
        "ax.set_ylabel('MAE')\n",
        "ax.set_title('Forecast Error Across Walk-Forward Splits')\n",
        "ax.set_xticks(x)\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "walk-forward"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Question 4.3**\n",
        ">\n",
        "> -   Is AR(1) consistently better than naive across all splits?\n",
        "> -   What does the variability across splits tell you?\n",
        "\n",
        "### 4.4 The ARIMA Reality Check: Returns vs Levels\n",
        "\n",
        "The previous exercises used VIX *levels*, which are mean-reverting\n",
        "(AR(1) has signal). But what about **returns**? This is the crucial test\n",
        "of whether ARIMA adds value for the problem most practitioners care\n",
        "about."
      ],
      "id": "18daf1b9-17cf-4fcc-853c-2fb16f2494ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPY returns (not prices, not VIX)\n",
        "spy_returns = spy['return'].dropna()\n",
        "\n",
        "# Walk-forward CV for returns\n",
        "tscv = TimeSeriesSplit(n_splits=5, test_size=50)\n",
        "\n",
        "naive_ret_errors = []\n",
        "ar1_ret_errors = []\n",
        "zero_ret_errors = []  # Predicting zero (simplest naive for returns)\n",
        "\n",
        "for train_idx, test_idx in tscv.split(spy_returns):\n",
        "    train = spy_returns.iloc[train_idx]\n",
        "    test = spy_returns.iloc[test_idx]\n",
        "    \n",
        "    # Naive: predict last return\n",
        "    naive_pred = np.full_like(test, train.iloc[-1])\n",
        "    naive_ret_errors.append(mean_absolute_error(test, naive_pred))\n",
        "    \n",
        "    # Zero forecast (returns fluctuate around zero)\n",
        "    zero_pred = np.zeros_like(test)\n",
        "    zero_ret_errors.append(mean_absolute_error(test, zero_pred))\n",
        "    \n",
        "    # AR(1) for returns\n",
        "    try:\n",
        "        model = ARIMA(train, order=(1, 0, 0))\n",
        "        results = model.fit()\n",
        "        ar1_pred = results.forecast(steps=len(test))\n",
        "        ar1_ret_errors.append(mean_absolute_error(test, ar1_pred))\n",
        "    except:\n",
        "        ar1_ret_errors.append(np.nan)\n",
        "\n",
        "# Results\n",
        "print(\"=== THE ARIMA REALITY CHECK ===\")\n",
        "print(\"\\nPredicting SPY Daily RETURNS (not VIX levels):\")\n",
        "print(f\"  Zero forecast MAE: {np.mean(zero_ret_errors):.6f}\")\n",
        "print(f\"  Naive forecast MAE: {np.mean(naive_ret_errors):.6f}\")\n",
        "print(f\"  AR(1) forecast MAE: {np.nanmean(ar1_ret_errors):.6f}\")\n",
        "\n",
        "# Compare to zero\n",
        "ar1_improvement = (np.mean(zero_ret_errors) - np.nanmean(ar1_ret_errors)) / np.mean(zero_ret_errors) * 100\n",
        "print(f\"\\nAR(1) improvement over zero: {ar1_improvement:.2f}%\")\n",
        "\n",
        "if ar1_improvement < 1:\n",
        "    print(\"\\n⚠️ KEY INSIGHT: AR(1) barely beats predicting zero!\")\n",
        "    print(\"   For returns, the mean equation is almost trivial.\")\n",
        "    print(\"   This is why we focus on VOLATILITY modelling (Week 4).\")"
      ],
      "id": "arima-reality-check"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **The Three Prediction Problems**\n",
        ">\n",
        "> This exercise demonstrates a fundamental insight:\n",
        ">\n",
        "> | What You Predict             | Signal?              | Does ARIMA Help?        |\n",
        "> |------------------------------|----------------------|-------------------------|\n",
        "> | VIX levels (mean-reverting)  | Yes (~25% R²)        | ✓ AR(1) beats naive     |\n",
        "> | SPY returns                  | Almost none (~1% R²) | ✗ Barely beats zero     |\n",
        "> | Volatility (squared returns) | Yes                  | ✓ GARCH family (Week 4) |\n",
        ">\n",
        "> **The lesson:** Don’t waste time fitting complex ARIMA models to\n",
        "> returns. The signal is in the *variance* (volatility), not the *mean*\n",
        "> (returns). This is why GARCH matters.\n",
        "\n",
        "> **Question 4.4**\n",
        ">\n",
        "> 1.  How much did AR(1) improve over simply predicting zero?\n",
        "> 2.  Is this improvement economically meaningful after transaction\n",
        ">     costs?\n",
        "> 3.  Why does AR(1) work for VIX levels but not SPY returns?\n",
        "\n",
        "## Part 5: Challenge Exercises\n",
        "\n",
        "### 5.1 Exercise: BTCUSD (Highly Non-Stationary)\n",
        "\n",
        "Bitcoin is highly volatile and non-stationary. Test different ARIMA\n",
        "specifications."
      ],
      "id": "e2d36089-9a54-40e7-a8ee-2f83e4efe3f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract BTCUSD\n",
        "btc = df[df['ticker'] == 'BTCUSD'].set_index('date').sort_index()\n",
        "\n",
        "# YOUR TASK:\n",
        "# 1. Test stationarity of BTC prices and returns\n",
        "# 2. Fit ARIMA(0,1,0) (random walk) to prices\n",
        "# 3. Compare to naive forecast\n",
        "# 4. Does ARIMA add value?"
      ],
      "id": "btc-challenge"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Exercise: Treasury Yield (Mean-Reverting?)\n",
        "\n",
        "The 10-year Treasury yield may be mean-reverting or trending depending\n",
        "on the period."
      ],
      "id": "4fb8cd51-d495-474c-876b-89a956863a84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract USGG10YR\n",
        "treasury = df[df['ticker'] == 'USGG10YR'].set_index('date').sort_index()\n",
        "\n",
        "# YOUR TASK:\n",
        "# 1. Visual and statistical stationarity tests\n",
        "# 2. Fit AR(1) or ARIMA(1,1,0) depending on stationarity\n",
        "# 3. Forecast and evaluate"
      ],
      "id": "treasury-challenge"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this lab, you learned to:\n",
        "\n",
        "1.  [x] Diagnose stationarity using visual and ADF tests\n",
        "2.  [x] Interpret ACF/PACF to identify AR vs MA patterns\n",
        "3.  [x] Fit and diagnose ARIMA models\n",
        "4.  [x] Perform walk-forward validation\n",
        "5.  [x] Compare forecasts to naive baselines\n",
        "\n",
        "**Key takeaways:** - Prices are non-stationary; returns are (mostly)\n",
        "stationary - VIX is mean-reverting but persistent → AR(1) fits well -\n",
        "Always compare to naive forecast — if you can’t beat it, use it -\n",
        "Walk-forward validation prevents overfitting\n",
        "\n",
        "## References\n",
        "\n",
        "-   Tsay, R. S. (2010). *Analysis of Financial Time Series*, 3rd\n",
        "    ed. Wiley. Chapter 2 (Linear Time Series), Chapter 3 (Conditional\n",
        "    Heteroscedastic Models).\n",
        "-   Brooks, C. (2019). *Introductory Econometrics for Finance*, 4th\n",
        "    ed. Cambridge University Press. Chapter 5 (Univariate time series\n",
        "    modelling and forecasting).\n",
        "-   Hyndman, R. J., & Athanasopoulos, G. (2021). *Forecasting:\n",
        "    Principles and Practice*, 3rd ed."
      ],
      "id": "7f55afb4-dabd-44ca-853a-f579c19fcf2d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "fin510",
      "display_name": "FIN510 Python",
      "language": "python",
      "path": "/Users/quinference/Library/Jupyter/kernels/fin510"
    }
  }
}