{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 7: Digital Asset Data Analysis\n",
        "\n",
        "Market structure, volatility, and efficiency testing\n",
        "\n",
        "> **Expected time**\n",
        ">\n",
        "> -   Core lab: â‰ˆ 75 minutes\n",
        "> -   Optional extensions: +30â€“60 minutes\n",
        "\n",
        "<figure>\n",
        "<a\n",
        "href=\"https://colab.research.google.com/github/quinfer/financial-data-science/blob/main/labs/notebooks/lab07_crypto.ipynb\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "<figcaption>Open in Colab</figcaption>\n",
        "</figure>\n",
        "\n",
        "## Before You Code: The Big Picture\n",
        "\n",
        "Cryptocurrencies promise **financial inclusion, decentralization, and\n",
        "censorship resistance**. But do they deliver? Letâ€™s test the claims\n",
        "empirically using market microstructure analysis.\n",
        "\n",
        "> **The Crypto Promise vs.Â Reality**\n",
        ">\n",
        "> **The Promise:**\n",
        ">\n",
        "> 1.  **Inclusion**: Banking for the 1.7 billion unbanked (World Bank)\n",
        "> 2.  **Efficiency**: Near-zero transaction costs, instant settlement\n",
        "> 3.  **Decentralization**: No intermediaries, no gatekeepers\n",
        "> 4.  **Transparency**: All transactions on public blockchain\n",
        ">\n",
        "> **The Reality (Empirical Evidence):**\n",
        ">\n",
        "> -   **Volatility**: Bitcoin std dev ~80% annualized (vs.Â S&P 500 ~15%)\n",
        "> -   **Correlation**: Bitcoin-S&P correlation increased from ~0 (2015)\n",
        ">     to ~0.5 (2022)â€”no longer diversifying\n",
        "> -   **Efficiency**: Autocorrelation tests show predictability\n",
        ">     (inefficient markets)\n",
        "> -   **Inclusion**: 95% of crypto holders are speculators, not unbanked\n",
        ">     users (Makarov & Schoar 2022, JF)\n",
        "> -   **Costs**: During congestion, Ethereum gas fees reached \\$50+ per\n",
        ">     transaction\n",
        ">\n",
        "> **The Academic Debate:**\n",
        ">\n",
        "> -   **Academic skeptics** (no financial stake): [Paul\n",
        ">     Krugman](https://en.wikipedia.org/wiki/Paul_Krugman) (Nobel\n",
        ">     Prize-winning economist, argues crypto lacks intrinsic value and\n",
        ">     serves primarily for illegal transactions) and [Nouriel\n",
        ">     Roubini](https://en.wikipedia.org/wiki/Nouriel_Roubini) (NYU\n",
        ">     economist who predicted 2008 crisis, calls crypto â€œthe mother of\n",
        ">     all scamsâ€) view cryptocurrency as a speculative bubble with no\n",
        ">     fundamental value, poor unit of account properties, and dominated\n",
        ">     by fraud. Their critique comes from outside the crypto ecosystem\n",
        ">     with no personal financial interest.\n",
        ">\n",
        "> -   **Industry advocates** (significant skin in the game): [Andreas M.\n",
        ">     Antonopoulos](https://aantonop.com/) (author of *Mastering\n",
        ">     Bitcoin*, emphasizes censorship resistance and financial\n",
        ">     sovereignty) and [Vitalik Buterin](https://vitalik.eth.limo/)\n",
        ">     (Ethereum co-founder, argues for programmable money and\n",
        ">     decentralized applications beyond payments) counter that crypto is\n",
        ">     early-stage infrastructureâ€”like the internet in 1995â€”requiring\n",
        ">     time for legitimate use cases to mature beyond speculation. Both\n",
        ">     have deep financial and reputational stakes in cryptoâ€™s success.\n",
        ">\n",
        "> -   **Evidence-based approach** (This lab): Understanding incentives\n",
        ">     matters. Academic critics risk nothing by being wrong; industry\n",
        ">     advocates benefit financially from adoption. Rather than choosing\n",
        ">     sides, we test empirical claims with dataâ€”volatility patterns,\n",
        ">     correlation dynamics, market efficiency, and actual usage\n",
        ">     statistics.\n",
        "\n",
        "### What Youâ€™ll Build Today\n",
        "\n",
        "By the end of this lab, you will have:\n",
        "\n",
        "-   âœ… Real-time crypto data from public APIs (CoinGecko)\n",
        "-   âœ… Volatility analysis comparing crypto to traditional assets\n",
        "-   âœ… Return distribution analysis (fat tails, skewness)\n",
        "-   âœ… Market efficiency tests (autocorrelation, mean reversion)\n",
        "-   âœ… Critical perspective on cryptoâ€™s actual use cases\n",
        "\n",
        "> **Why This Matters**\n",
        ">\n",
        "> Crypto is either the future of finance or a trillion-dollar\n",
        "> speculative bubble. Your job as a data scientist: **test the claims\n",
        "> empirically**, not ideologically. This lab shows you how.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "-   Access cryptocurrency market data using public APIs\n",
        "-   Calculate and compare volatility across crypto and traditional\n",
        "    assets\n",
        "-   Analyze return distributions and identify tail risk\n",
        "-   Measure correlation patterns (within-crypto and cross-asset)\n",
        "-   Test market efficiency using autocorrelation and arbitrage analysis\n",
        "-   Visualize price dynamics and microstructure features\n",
        "-   Evaluate crypto financial inclusion claims empirically\n",
        "\n",
        "## Setup and Dependencies"
      ],
      "id": "0dd2b1f0-8190-4c52-b91e-1130d2cb444e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For reading data files\n",
        "try:\n",
        "    import requests  # For downloading from GitHub\n",
        "except ImportError:\n",
        "    print(\"Installing requests...\")\n",
        "    !pip install -q requests\n",
        "    import requests\n",
        "\n",
        "# Note: openpyxl only needed if reading Bloomberg Excel directly\n",
        "# We're using CSV from GitHub, so not required for students\n",
        "\n",
        "# For statistical tests\n",
        "try:\n",
        "    import statsmodels.api as sm\n",
        "    from statsmodels.tsa.stattools import adfuller, acf\n",
        "except ImportError:\n",
        "    print(\"Installing statsmodels...\")\n",
        "    !pip install -q statsmodels\n",
        "\n",
        "# Visualization settings\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "print(\"âœ“ Setup complete - ready for crypto market analysis\")"
      ],
      "id": "6ff70632"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Accessing Cryptocurrency Market Data\n",
        "\n",
        "### Understanding Crypto Data Sources\n",
        "\n",
        "Unlike traditional finance where Bloomberg terminals and licensed data\n",
        "vendors dominate, cryptocurrency data comes from public APIs provided by\n",
        "exchanges and aggregators. This democratizes accessâ€”you can get the same\n",
        "data professionals useâ€”but also creates challenges around data quality,\n",
        "fragmentation, and standardization.\n",
        "\n",
        "**Key data sources:**\n",
        "\n",
        "-   **Aggregators**: CoinGecko, CoinMarketCap (volume-weighted prices\n",
        "    across exchanges)\n",
        "-   **Exchanges**: Coinbase Pro, Binance, Kraken (order books, trade\n",
        "    data, official prices)\n",
        "-   **Blockchain explorers**: On-chain data (transaction volumes,\n",
        "    addresses, mining)\n",
        "-   **Derivatives**: CME, Deribit (futures, options implied volatility)\n",
        "\n",
        "Weâ€™ll use **real data from Bloomberg Terminal**, downloaded via the\n",
        "Excel add-in. This provides institutional-quality pricing with proper\n",
        "corporate actions handling and validated sources.\n",
        "\n",
        "> **Bloomberg Terminal Data**\n",
        ">\n",
        "> This lab uses data downloaded from Bloomberg Terminal (XBTUSD Curncy,\n",
        "> ETHUSD Curncy, etc.). Bloomberg provides the most reliable crypto\n",
        "> pricing for institutional use. If you donâ€™t have Terminal access,\n",
        "> alternatives include Yahoo Finance (free but less reliable) or\n",
        "> CoinGecko Pro (paid API).\n",
        "\n",
        "### Loading Bloomberg Data from GitHub"
      ],
      "id": "7d55f59c-05d2-45ac-b423-1ce9e3b178ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_bloomberg_crypto(github_url='https://quinfer.github.io/financial-data-science/data/chapter07/crypto_bloomberg.csv'):\n",
        "    \"\"\"\n",
        "    Load cryptocurrency data from Bloomberg Terminal (CSV format).\n",
        "    \n",
        "    This function loads data from GitHub Pages by default (works in Colab).\n",
        "    Falls back to local file if GitHub Pages is unavailable.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    github_url : str\n",
        "        URL to Bloomberg crypto CSV on GitHub Pages\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Bitcoin price data with date index\n",
        "    \"\"\"\n",
        "    # Try GitHub Pages first (default for Colab/remote students)\n",
        "    try:\n",
        "        print(\"ðŸ“¥ Loading Bloomberg data from GitHub Pages...\")\n",
        "        df = pd.read_csv(github_url, parse_dates=['date'])\n",
        "        df = df.set_index('date')\n",
        "        print(f\"âœ… Loaded Bloomberg data: {len(df)} rows\")\n",
        "        print(f\"   Source: GitHub Pages (quinfer.github.io/financial-data-science)\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Could not load from GitHub Pages: {e}\")\n",
        "        pass\n",
        "    \n",
        "    # Fallback to local file (if running on campus with repo)\n",
        "    try:\n",
        "        local_path = 'data/chapter07/crypto_bloomberg.csv'\n",
        "        df = pd.read_csv(local_path, parse_dates=['date'])\n",
        "        df = df.set_index('date')\n",
        "        print(f\"âœ… Loaded local Bloomberg data: {len(df)} rows\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"âš ï¸  Local file not found\")\n",
        "        return None\n",
        "\n",
        "# Load Bitcoin data from Bloomberg Terminal\n",
        "print(\"Loading cryptocurrency data from Bloomberg Terminal...\")\n",
        "btc_bloomberg = load_bloomberg_crypto()\n",
        "\n",
        "if btc_bloomberg is not None:\n",
        "    # Use real Bloomberg data\n",
        "    btc_data = btc_bloomberg[['price']].copy()\n",
        "    btc_data['volume'] = btc_bloomberg['volume'] if 'volume' in btc_bloomberg else None\n",
        "    \n",
        "    print(f\"âœ… Bitcoin (Bloomberg): {len(btc_data)} days of data\")\n",
        "    print(f\"  Date range: {btc_data.index.min().date()} to {btc_data.index.max().date()}\")\n",
        "    print(f\"  Price range: ${btc_data['price'].min():,.0f} - ${btc_data['price'].max():,.0f}\")\n",
        "    \n",
        "    # Use last 2 years for analysis (to match typical lab scope)\n",
        "    cutoff_date = btc_data.index.max() - pd.Timedelta(days=730)\n",
        "    btc_data = btc_data[btc_data.index >= cutoff_date]\n",
        "    print(f\"  Using last 2 years: {len(btc_data)} days\")\n",
        "    \n",
        "    # Create synthetic ETH and BNB for comparison (scaled from BTC)\n",
        "    # Real multi-asset Bloomberg data would require separate Terminal queries\n",
        "    eth_data = btc_data.copy()\n",
        "    eth_data['price'] = btc_data['price'] * 0.05  # Roughly ETH/BTC ratio\n",
        "    bnb_data = btc_data.copy()\n",
        "    bnb_data['price'] = btc_data['price'] * 0.01  # Roughly BNB/BTC ratio\n",
        "else:\n",
        "    # Fallback to synthetic data if Bloomberg not available\n",
        "    print(\"âš ï¸  Bloomberg data not available, using synthetic data...\")\n",
        "    dates = pd.date_range(end=pd.Timestamp.now(), periods=730, freq='D')\n",
        "    btc_data = pd.DataFrame({\n",
        "        'price': 30000 + np.cumsum(np.random.randn(730) * 500),\n",
        "        'volume': np.random.rand(730) * 1e9\n",
        "    }, index=dates)\n",
        "    eth_data = btc_data.copy()\n",
        "    eth_data['price'] = btc_data['price'] * 0.05\n",
        "    bnb_data = btc_data.copy()\n",
        "    bnb_data['price'] = btc_data['price'] * 0.01\n",
        "\n",
        "if btc_data is not None:\n",
        "    print(f\"âœ“ Retrieved {len(btc_data)} days of Bitcoin data\")\n",
        "    print(f\"  Price range: ${btc_data['price'].min():,.0f} - ${btc_data['price'].max():,.0f}\")\n",
        "    print(\"\\nSample data:\")\n",
        "    print(btc_data.head())"
      ],
      "id": "5664f65d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Price Trends"
      ],
      "id": "95fa6ca4-1e19-405e-8e56-8d0313f9b01f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive price visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Bitcoin price\n",
        "axes[0, 0].plot(btc_data.index, btc_data['price'], color='orange', linewidth=2)\n",
        "axes[0, 0].set_title('Bitcoin Price (USD)', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Price ($)')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "axes[0, 0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
        "\n",
        "# Ethereum price\n",
        "axes[0, 1].plot(eth_data.index, eth_data['price'], color='blue', linewidth=2)\n",
        "axes[0, 1].set_title('Ethereum Price (USD)', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('Price ($)')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Trading volumes\n",
        "axes[1, 0].plot(btc_data.index, btc_data['volume'], color='green', alpha=0.7, linewidth=1.5)\n",
        "axes[1, 0].set_title('Bitcoin Trading Volume', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Volume ($)')\n",
        "axes[1, 0].set_xlabel('Date')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "axes[1, 0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e9:.1f}B'))\n",
        "\n",
        "# Price comparison (normalized to 100)\n",
        "btc_norm = 100 * btc_data['price'] / btc_data['price'].iloc[0]\n",
        "eth_norm = 100 * eth_data['price'] / eth_data['price'].iloc[0]\n",
        "bnb_norm = 100 * bnb_data['price'] / bnb_data['price'].iloc[0]\n",
        "\n",
        "axes[1, 1].plot(btc_norm.index, btc_norm, label='Bitcoin', color='orange', linewidth=2)\n",
        "axes[1, 1].plot(eth_norm.index, eth_norm, label='Ethereum', color='blue', linewidth=2)\n",
        "axes[1, 1].plot(bnb_norm.index, bnb_norm, label='BNB', color='gold', linewidth=2)\n",
        "axes[1, 1].set_title('Comparative Performance (Base = 100)', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Index Value')\n",
        "axes[1, 1].set_xlabel('Date')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY STATISTICS (2-year period)\")\n",
        "print(\"=\"*60)\n",
        "for name, data in [('Bitcoin', btc_data), ('Ethereum', eth_data), ('BNB', bnb_data)]:\n",
        "    total_return = (data['price'].iloc[-1] / data['price'].iloc[0] - 1) * 100\n",
        "    max_price = data['price'].max()\n",
        "    min_price = data['price'].min()\n",
        "    drawdown = ((data['price'] / data['price'].cummax()) - 1).min() * 100\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Total Return: {total_return:+.1f}%\")\n",
        "    print(f\"  Price Range: ${min_price:,.0f} - ${max_price:,.0f}\")\n",
        "    print(f\"  Max Drawdown: {drawdown:.1f}%\")"
      ],
      "id": "9d0b984c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions (Exercise 1)\n",
        "\n",
        "Write 200-250 words addressing:\n",
        "\n",
        "1.  **Data Quality**: What challenges might arise from using free\n",
        "    aggregator APIs versus licensed data feeds? How might wash trading\n",
        "    on some exchanges affect aggregate data quality?\n",
        "\n",
        "2.  **Price Fragmentation**: CoinGecko aggregates prices across\n",
        "    exchanges. Why might Bitcoin trade at different prices\n",
        "    simultaneously on different venues? What arbitrage mechanisms should\n",
        "    eliminate these spreads?\n",
        "\n",
        "3.  **Volume Interpretation**: How should we interpret trading volume\n",
        "    data knowing that significant portion might be wash trading? What\n",
        "    alternative metrics could measure genuine market activity?\n",
        "\n",
        "## Exercise 2: Volatility and Risk Analysis\n",
        "\n",
        "### Calculating Returns and Volatility"
      ],
      "id": "fa58c0d2-3b2c-4fc6-8c37-afec45bfb40b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate log returns\n",
        "btc_data['returns'] = np.log(btc_data['price'] / btc_data['price'].shift(1))\n",
        "eth_data['returns'] = np.log(eth_data['price'] / eth_data['price'].shift(1))\n",
        "bnb_data['returns'] = np.log(bnb_data['price'] / bnb_data['price'].shift(1))\n",
        "\n",
        "# Remove NaN values\n",
        "btc_returns = btc_data['returns'].dropna()\n",
        "eth_returns = eth_data['returns'].dropna()\n",
        "bnb_returns = bnb_data['returns'].dropna()\n",
        "\n",
        "# Calculate volatility metrics\n",
        "def calculate_volatility_metrics(returns, name):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive volatility statistics for cryptocurrency returns.\n",
        "    \n",
        "    Computes key risk metrics used by portfolio managers: realized volatility,\n",
        "    tail risk measures (VaR), and distribution shape (skewness, kurtosis).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    returns : pd.Series\n",
        "        Daily returns (log or simple returns)\n",
        "    name : str\n",
        "        Asset name for display in output\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary with keys:\n",
        "        - 'daily_vol' : float, daily standard deviation\n",
        "        - 'annual_vol' : float, annualized standard deviation (daily * sqrt(365))\n",
        "        - 'rolling_vol' : pd.Series, 30-day rolling volatility\n",
        "        - 'skew' : float, skewness (negative = left tail)\n",
        "        - 'kurt' : float, excess kurtosis (> 0 = fat tails)\n",
        "        - 'var_95' : float, 5th percentile return (1-day VaR at 95%)\n",
        "        - 'var_99' : float, 1st percentile return (1-day VaR at 99%)\n",
        "        \n",
        "    Notes\n",
        "    -----\n",
        "    - Annualization assumes 365 trading days (crypto markets trade 24/7)\n",
        "    - Traditional equity markets use 252 trading days\n",
        "    - VaR is historical (empirical percentiles), not parametric (Gaussian assumption)\n",
        "    - Fat tails (kurtosis > 3) mean VaR underestimates extreme losses\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> btc_returns = btc_data['price'].pct_change()\n",
        "    >>> metrics = calculate_volatility_metrics(btc_returns, 'Bitcoin')\n",
        "    >>> metrics['annual_vol']\n",
        "    0.65  # 65% annualized volatility (vs. S&P 500 ~15%)\n",
        "    \"\"\"\n",
        "    daily_vol = returns.std()\n",
        "    annual_vol = daily_vol * np.sqrt(365)\n",
        "    \n",
        "    # Rolling volatility (30-day window)\n",
        "    rolling_vol = returns.rolling(30).std() * np.sqrt(365)\n",
        "    \n",
        "    # Skewness and kurtosis\n",
        "    skew = stats.skew(returns.dropna())\n",
        "    kurt = stats.kurtosis(returns.dropna())\n",
        "    \n",
        "    # Value at Risk (95% and 99%)\n",
        "    var_95 = np.percentile(returns.dropna(), 5)\n",
        "    var_99 = np.percentile(returns.dropna(), 1)\n",
        "    \n",
        "    print(f\"\\n{name} Volatility Metrics:\")\n",
        "    print(f\"  Daily Volatility: {daily_vol*100:.2f}%\")\n",
        "    print(f\"  Annualized Volatility: {annual_vol*100:.1f}%\")\n",
        "    print(f\"  Skewness: {skew:.3f} {'(negative tail)' if skew < 0 else '(positive tail)'}\")\n",
        "    print(f\"  Kurtosis: {kurt:.3f} {'(fat tails)' if kurt > 3 else '(thin tails)'}\")\n",
        "    print(f\"  VaR (95%): {var_95*100:.2f}% (1-day)\")\n",
        "    print(f\"  VaR (99%): {var_99*100:.2f}% (1-day)\")\n",
        "    \n",
        "    return {\n",
        "        'daily_vol': daily_vol,\n",
        "        'annual_vol': annual_vol,\n",
        "        'rolling_vol': rolling_vol,\n",
        "        'skew': skew,\n",
        "        'kurt': kurt,\n",
        "        'var_95': var_95,\n",
        "        'var_99': var_99\n",
        "    }\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VOLATILITY ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "btc_vol = calculate_volatility_metrics(btc_returns, \"Bitcoin\")\n",
        "eth_vol = calculate_volatility_metrics(eth_returns, \"Ethereum\")\n",
        "bnb_vol = calculate_volatility_metrics(bnb_returns, \"BNB\")\n",
        "\n",
        "# Compare to traditional assets (typical values for reference)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"COMPARISON TO TRADITIONAL ASSETS (typical values):\")\n",
        "print(\"-\"*70)\n",
        "print(\"S&P 500:      Annual Vol ~15-20%, Skew ~-0.5, Kurtosis ~5-8\")\n",
        "print(\"Gold:         Annual Vol ~15-18%, Skew ~0.2, Kurtosis ~3-5\")\n",
        "print(\"Treasury Bonds: Annual Vol ~5-8%, Skew ~0.0, Kurtosis ~3-4\")\n",
        "print(\"\\nCryptocurrency volatility is 3-5x higher than traditional assets!\")"
      ],
      "id": "66989f2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Return Distributions"
      ],
      "id": "22952b1a-f3eb-40c9-a291-e4bc54434efc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Bitcoin return distribution\n",
        "axes[0, 0].hist(btc_returns * 100, bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
        "axes[0, 0].axvline(btc_returns.mean() * 100, color='red', linestyle='--', linewidth=2, label=f'Mean: {btc_returns.mean()*100:.2f}%')\n",
        "axes[0, 0].set_title('Bitcoin Daily Returns Distribution', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Daily Return (%)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# QQ plot for normality test\n",
        "stats.probplot(btc_returns.dropna(), dist=\"norm\", plot=axes[0, 1])\n",
        "axes[0, 1].set_title('Q-Q Plot: Bitcoin Returns vs Normal Distribution', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Rolling volatility\n",
        "axes[1, 0].plot(btc_vol['rolling_vol'].index, btc_vol['rolling_vol'] * 100, \n",
        "                color='purple', linewidth=2, label='BTC Rolling Vol (30d)')\n",
        "axes[1, 0].plot(eth_vol['rolling_vol'].index, eth_vol['rolling_vol'] * 100, \n",
        "                color='blue', linewidth=2, alpha=0.7, label='ETH Rolling Vol (30d)')\n",
        "axes[1, 0].set_title('Rolling Volatility (30-day window)', fontsize=13, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Annualized Volatility (%)')\n",
        "axes[1, 0].set_xlabel('Date')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Volatility comparison bar chart\n",
        "vol_comparison = pd.DataFrame({\n",
        "    'Bitcoin': [btc_vol['annual_vol'] * 100],\n",
        "    'Ethereum': [eth_vol['annual_vol'] * 100],\n",
        "    'BNB': [bnb_vol['annual_vol'] * 100],\n",
        "    'S&P 500': [17.5],  # Typical value\n",
        "    'Gold': [16.5]  # Typical value\n",
        "})\n",
        "\n",
        "vol_comparison.T.plot(kind='bar', ax=axes[1, 1], legend=False, color=['orange', 'blue', 'gold', 'green', 'brown'])\n",
        "axes[1, 1].set_title('Annualized Volatility Comparison', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Volatility (%)')\n",
        "axes[1, 1].set_xlabel('Asset')\n",
        "axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45, ha='right')\n",
        "axes[1, 1].axhline(y=20, color='red', linestyle='--', alpha=0.5, label='20% threshold')\n",
        "axes[1, 1].grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical tests for normality\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NORMALITY TESTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for name, returns in [('Bitcoin', btc_returns), ('Ethereum', eth_returns)]:\n",
        "    # Jarque-Bera test\n",
        "    jb_stat, jb_pval = stats.jarque_bera(returns.dropna())\n",
        "    \n",
        "    # Shapiro-Wilk test (sample if too large)\n",
        "    sample_returns = returns.dropna().sample(min(5000, len(returns)))\n",
        "    sw_stat, sw_pval = stats.shapiro(sample_returns)\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Jarque-Bera test: statistic={jb_stat:.2f}, p-value={jb_pval:.4f}\")\n",
        "    print(f\"    {'Reject normality' if jb_pval < 0.05 else 'Cannot reject normality'} (Î±=0.05)\")\n",
        "    print(f\"  Shapiro-Wilk test: statistic={sw_stat:.4f}, p-value={sw_pval:.4f}\")\n",
        "    print(f\"    {'Reject normality' if sw_pval < 0.05 else 'Cannot reject normality'} (Î±=0.05)\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Returns exhibit fat tails and deviate significantly from normal distribution!\")"
      ],
      "id": "5313ace5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation Analysis"
      ],
      "id": "a16edd93-f48d-4c4f-9574-8ad69a2a7b33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine returns into single DataFrame\n",
        "returns_df = pd.DataFrame({\n",
        "    'BTC': btc_returns,\n",
        "    'ETH': eth_returns,\n",
        "    'BNB': bnb_returns\n",
        "}).dropna()\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = returns_df.corr()\n",
        "\n",
        "# Visualize correlations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=axes[0])\n",
        "axes[0].set_title('Cryptocurrency Correlation Matrix', fontsize=13, fontweight='bold')\n",
        "\n",
        "# Scatter plot: BTC vs ETH\n",
        "axes[1].scatter(returns_df['BTC'] * 100, returns_df['ETH'] * 100, alpha=0.5, s=20)\n",
        "axes[1].set_xlabel('Bitcoin Daily Return (%)')\n",
        "axes[1].set_ylabel('Ethereum Daily Return (%)')\n",
        "axes[1].set_title(f'BTC-ETH Correlation: {corr_matrix.loc[\"BTC\", \"ETH\"]:.3f}', \n",
        "                  fontsize=13, fontweight='bold')\n",
        "axes[1].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
        "axes[1].axvline(0, color='black', linewidth=0.5, alpha=0.3)\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Add regression line\n",
        "z = np.polyfit(returns_df['BTC'], returns_df['ETH'], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[1].plot(returns_df['BTC'] * 100, p(returns_df['BTC']) * 100, \n",
        "             \"r--\", alpha=0.8, linewidth=2, label=f'Regression line')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CORRELATION ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nWithin-Crypto Correlations:\")\n",
        "print(corr_matrix)\n",
        "print(\"\\nðŸ’¡ High correlations (0.5-0.8) limit diversification within cryptocurrency portfolios\")\n",
        "\n",
        "# Rolling correlation\n",
        "rolling_corr_btc_eth = returns_df['BTC'].rolling(90).corr(returns_df['ETH'])\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(rolling_corr_btc_eth.index, rolling_corr_btc_eth, linewidth=2, color='purple')\n",
        "plt.axhline(y=rolling_corr_btc_eth.mean(), color='red', linestyle='--', \n",
        "            label=f'Mean: {rolling_corr_btc_eth.mean():.3f}')\n",
        "plt.title('Rolling Correlation: Bitcoin vs Ethereum (90-day window)', fontsize=13, fontweight='bold')\n",
        "plt.ylabel('Correlation')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nRolling BTC-ETH correlation: Mean={rolling_corr_btc_eth.mean():.3f}, \"\n",
        "      f\"Std={rolling_corr_btc_eth.std():.3f}\")\n",
        "print(\"Note: Correlation increases during volatile periods (contagion effect)\")"
      ],
      "id": "73fd7b3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions (Exercise 2)\n",
        "\n",
        "Write 250-300 words addressing:\n",
        "\n",
        "1.  **Volatility Implications**: Bitcoinâ€™s 60-80% annualized volatility\n",
        "    is 3-4x higher than equities. What does this mean for: (a) using\n",
        "    Bitcoin as currency (purchasing power stability)? (b) portfolio\n",
        "    allocation (risk contribution)? (c) options pricing and risk\n",
        "    management?\n",
        "\n",
        "2.  **Fat Tails and Risk Models**: The Q-Q plot shows Bitcoin returns\n",
        "    deviate from normality with fat tails. Why do standard risk models\n",
        "    (VaR assuming normal distribution) underestimate tail risk? What\n",
        "    practical consequences does this have?\n",
        "\n",
        "3.  **Correlation Patterns**: Cryptocurrencies show high correlation\n",
        "    with each other (0.5-0.8) but time-varying correlation with\n",
        "    equities. What does this mean for diversification benefits within\n",
        "    crypto portfolios versus across asset classes?\n",
        "\n",
        "## Exercise 3: Market Efficiency Testing\n",
        "\n",
        "### Autocorrelation Analysis"
      ],
      "id": "cb916aad-138b-4a3f-aefd-a1e1fbc8e9cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test for autocorrelation (do past returns predict future returns?)\n",
        "def test_autocorrelation(returns, name, max_lag=20):\n",
        "    \"\"\"\n",
        "    Test for serial correlation in returns (market efficiency diagnostic).\n",
        "    \n",
        "    Autocorrelation measures whether past returns predict future returns. If\n",
        "    significant autocorrelation exists, markets are inefficient (predictable).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    returns : pd.Series\n",
        "        Daily returns series\n",
        "    name : str\n",
        "        Asset name for display\n",
        "    max_lag : int, default=20\n",
        "        Maximum lag to test (20 days = ~1 month)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Prints test results and displays ACF plot\n",
        "        \n",
        "    Notes\n",
        "    -----\n",
        "    **Ljung-Box Test:**\n",
        "    - Null hypothesis: No autocorrelation up to lag k\n",
        "    - p-value < 0.05 â†’ Reject H0 â†’ Significant autocorrelation (inefficiency)\n",
        "    \n",
        "    **Efficient Market Hypothesis (weak form):**\n",
        "    - If markets are efficient, past prices shouldn't predict future prices\n",
        "    - ACF should be ~0 at all lags (within 95% confidence bands)\n",
        "    - Crypto often shows significant autocorrelation (inefficient)\n",
        "    \n",
        "    **Why Crypto Markets Are Inefficient:**\n",
        "    - Fragmented liquidity across hundreds of exchanges\n",
        "    - High transaction costs (gas fees, spreads)\n",
        "    - Retail-dominated (fewer arbitrageurs)\n",
        "    - 24/7 trading â†’ slower price discovery\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> btc_returns = btc_data['price'].pct_change()\n",
        "    >>> test_autocorrelation(btc_returns, 'Bitcoin', max_lag=20)\n",
        "    Bitcoin Autocorrelation Analysis:\n",
        "      Lag-1 Autocorrelation: 0.0234\n",
        "      Ljung-Box p-value (lag 10): 0.0012  # Reject H0 â†’ Inefficient!\n",
        "    \"\"\"\n",
        "    \n",
        "    # Calculate autocorrelation function\n",
        "    acf_values = acf(returns.dropna(), nlags=max_lag, fft=False)\n",
        "    \n",
        "    # Ljung-Box test for joint significance\n",
        "    from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "    lb_test = acorr_ljungbox(returns.dropna(), lags=[5, 10, 20], return_df=True)\n",
        "    \n",
        "    print(f\"\\n{name} Autocorrelation Analysis:\")\n",
        "    print(f\"  Lag-1 Autocorrelation: {acf_values[1]:.4f}\")\n",
        "    print(f\"  Lag-5 Autocorrelation: {acf_values[5]:.4f}\")\n",
        "    print(\"\\nLjung-Box Test (joint significance):\")\n",
        "    print(lb_test)\n",
        "    \n",
        "    # Plot ACF\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    ax.stem(range(len(acf_values)), acf_values, basefmt=\" \")\n",
        "    ax.axhline(y=0, color='black', linewidth=0.5)\n",
        "    ax.axhline(y=1.96/np.sqrt(len(returns)), color='red', linestyle='--', label='95% CI')\n",
        "    ax.axhline(y=-1.96/np.sqrt(len(returns)), color='red', linestyle='--')\n",
        "    ax.set_title(f'{name} Autocorrelation Function', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Lag (days)')\n",
        "    ax.set_ylabel('Autocorrelation')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return acf_values\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MARKET EFFICIENCY: AUTOCORRELATION TESTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "btc_acf = test_autocorrelation(btc_returns, \"Bitcoin\")\n",
        "eth_acf = test_autocorrelation(eth_returns, \"Ethereum\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Interpretation: Significant autocorrelation suggests predictability (market inefficiency)\")\n",
        "print(\"   Small correlations may not be economically significant after transaction costs\")"
      ],
      "id": "6a1b1af8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Momentum Strategy Backtest"
      ],
      "id": "fbb84b70-3295-40c1-9f6e-bb009918a1d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple momentum strategy: buy if price > 50-day MA, sell otherwise\n",
        "def momentum_strategy(prices, short_window=10, long_window=50):\n",
        "    \"\"\"\n",
        "    Backtest simple moving average crossover momentum strategy.\n",
        "    \n",
        "    Classic technical analysis strategy: buy when short MA crosses above long MA,\n",
        "    sell when it crosses below. Tests whether momentum exists in crypto markets.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    prices : pd.Series\n",
        "        Daily closing prices\n",
        "    short_window : int, default=10\n",
        "        Short moving average window (days)\n",
        "    long_window : int, default=50\n",
        "        Long moving average window (days)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Columns:\n",
        "        - 'price' : original prices\n",
        "        - 'MA_short' : short-window moving average\n",
        "        - 'MA_long' : long-window moving average\n",
        "        - 'signal' : trading position (+1 = long, -1 = short, 0 = no position)\n",
        "        - 'returns' : buy-and-hold returns\n",
        "        - 'strategy_returns' : strategy returns (position Ã— market return)\n",
        "        - 'cum_returns' : cumulative buy-and-hold\n",
        "        - 'cum_strategy' : cumulative strategy performance\n",
        "        \n",
        "    Notes\n",
        "    -----\n",
        "    **Strategy Logic:**\n",
        "    - Golden Cross: Short MA > Long MA â†’ Buy signal\n",
        "    - Death Cross: Short MA < Long MA â†’ Sell signal\n",
        "    \n",
        "    **Reality Check:**\n",
        "    - This is a **naive backtest** (ignores transaction costs, slippage, fees)\n",
        "    - Crypto trading fees ~0.1-0.5% per trade â†’ eats into profits\n",
        "    - No position sizing, risk management, or stop-losses\n",
        "    - Past performance â‰  future returns (overfitting risk)\n",
        "    \n",
        "    **Academic Evidence:**\n",
        "    - Momentum works in equities (Jegadeesh & Titman 1993, JF)\n",
        "    - Crypto momentum: mixed evidence, high volatility dominates\n",
        "    - Transaction costs often exceed strategy alpha\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> btc_momentum = momentum_strategy(btc_data['price'])\n",
        "    >>> strategy_return = (btc_momentum['cum_strategy'].iloc[-1] - 1) * 100\n",
        "    >>> print(f\"Strategy return: {strategy_return:.1f}%\")\n",
        "    Strategy return: -5.2%  # Often underperforms buy-and-hold after costs\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({'price': prices})\n",
        "    \n",
        "    # Calculate moving averages\n",
        "    df['MA_short'] = df['price'].rolling(short_window).mean()\n",
        "    df['MA_long'] = df['price'].rolling(long_window).mean()\n",
        "    \n",
        "    # Generate signals\n",
        "    df['signal'] = 0\n",
        "    df.loc[df['MA_short'] > df['MA_long'], 'signal'] = 1  # Buy signal\n",
        "    df.loc[df['MA_short'] < df['MA_long'], 'signal'] = -1  # Sell signal\n",
        "    \n",
        "    # Calculate returns\n",
        "    df['returns'] = df['price'].pct_change()\n",
        "    df['strategy_returns'] = df['signal'].shift(1) * df['returns']\n",
        "    \n",
        "    # Cumulative returns\n",
        "    df['cum_returns'] = (1 + df['returns']).cumprod()\n",
        "    df['cum_strategy'] = (1 + df['strategy_returns']).cumprod()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Run momentum strategy\n",
        "btc_momentum = momentum_strategy(btc_data['price'])\n",
        "\n",
        "# Calculate performance metrics\n",
        "total_return = (btc_momentum['cum_returns'].iloc[-1] - 1) * 100\n",
        "strategy_return = (btc_momentum['cum_strategy'].iloc[-1] - 1) * 100\n",
        "excess_return = strategy_return - total_return\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MOMENTUM STRATEGY BACKTEST\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nBuy-and-Hold Return: {total_return:.2f}%\")\n",
        "print(f\"Strategy Return: {strategy_return:.2f}%\")\n",
        "print(f\"Excess Return: {excess_return:+.2f}%\")\n",
        "\n",
        "# Visualize strategy performance\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Price and moving averages\n",
        "axes[0].plot(btc_momentum.index, btc_momentum['price'], label='Bitcoin Price', color='orange', linewidth=2)\n",
        "axes[0].plot(btc_momentum.index, btc_momentum['MA_short'], label=f'{10}D MA', color='blue', linewidth=1.5)\n",
        "axes[0].plot(btc_momentum.index, btc_momentum['MA_long'], label=f'{50}D MA', color='red', linewidth=1.5)\n",
        "axes[0].set_title('Bitcoin Price with Moving Averages', fontsize=13, fontweight='bold')\n",
        "axes[0].set_ylabel('Price ($)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Cumulative returns comparison\n",
        "axes[1].plot(btc_momentum.index, btc_momentum['cum_returns'], \n",
        "             label='Buy and Hold', color='gray', linewidth=2)\n",
        "axes[1].plot(btc_momentum.index, btc_momentum['cum_strategy'], \n",
        "             label='Momentum Strategy', color='green', linewidth=2)\n",
        "axes[1].set_title('Cumulative Returns: Strategy vs Buy-and-Hold', fontsize=13, fontweight='bold')\n",
        "axes[1].set_ylabel('Cumulative Return (Base = 1)')\n",
        "axes[1].set_xlabel('Date')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâš ï¸  Note: This backtest ignores transaction costs, slippage, and taxes\")\n",
        "print(\"    Real-world implementation would have lower returns\")"
      ],
      "id": "90d49c43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mean Reversion Test"
      ],
      "id": "acfd54a5-b181-4066-a814-f2fe7035296b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Augmented Dickey-Fuller test for stationarity/mean reversion\n",
        "def test_mean_reversion(prices, name):\n",
        "    \"\"\"\n",
        "    Test for mean reversion using Augmented Dickey-Fuller (ADF) test.\n",
        "    \n",
        "    Tests whether prices follow a random walk (unit root) or revert to a mean\n",
        "    (stationary). Critical for pairs trading and mean-reversion strategies.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    prices : pd.Series\n",
        "        Daily closing prices\n",
        "    name : str\n",
        "        Asset name for display\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        ADF test results: (statistic, p-value, lags_used, nobs, critical_values, icbest)\n",
        "        \n",
        "    Notes\n",
        "    -----\n",
        "    **Augmented Dickey-Fuller Test:**\n",
        "    - Null hypothesis (H0): Series has unit root (random walk, NOT mean-reverting)\n",
        "    - Alternative (H1): Series is stationary (mean-reverting)\n",
        "    - p-value < 0.05 â†’ Reject H0 â†’ Prices are stationary (mean-reverting)\n",
        "    - p-value > 0.05 â†’ Cannot reject H0 â†’ Random walk (efficient market)\n",
        "    \n",
        "    **Implications for Trading:**\n",
        "    - **Random walk** (efficient): Momentum strategies may work, mean-reversion won't\n",
        "    - **Mean-reverting** (inefficient): Pairs trading, statistical arbitrage possible\n",
        "    \n",
        "    **Why This Matters:**\n",
        "    - Most financial time series have unit roots (Campbell, Lo, MacKinlay 1997)\n",
        "    - Crypto markets often show mixed evidence (regime-dependent)\n",
        "    - Low p-values may be spurious (structural breaks, volatility clustering)\n",
        "    \n",
        "    **Technical Details:**\n",
        "    - Test performed on log prices (handles exponential growth)\n",
        "    - Regression includes constant term ('c') but not trend\n",
        "    - AIC criterion selects optimal lag length\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> btc_adf = test_mean_reversion(btc_data['price'], 'Bitcoin')\n",
        "    Bitcoin - Augmented Dickey-Fuller Test:\n",
        "      ADF Statistic: -1.234\n",
        "      P-value: 0.658  # Cannot reject unit root â†’ Random walk\n",
        "    \"\"\"\n",
        "    \n",
        "    # ADF test on log prices\n",
        "    log_prices = np.log(prices)\n",
        "    adf_result = adfuller(log_prices.dropna(), maxlag=20, regression='c', autolag='AIC')\n",
        "    \n",
        "    print(f\"\\n{name} - Augmented Dickey-Fuller Test:\")\n",
        "    print(f\"  ADF Statistic: {adf_result[0]:.4f}\")\n",
        "    print(f\"  P-value: {adf_result[1]:.4f}\")\n",
        "    print(f\"  Critical Values:\")\n",
        "    for key, value in adf_result[4].items():\n",
        "        print(f\"    {key}: {value:.4f}\")\n",
        "    \n",
        "    if adf_result[1] < 0.05:\n",
        "        print(f\"  âœ“ Reject unit root (prices are stationary/mean-reverting)\")\n",
        "    else:\n",
        "        print(f\"  âœ— Cannot reject unit root (prices have unit root/random walk)\")\n",
        "    \n",
        "    return adf_result\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MEAN REVERSION TESTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "btc_adf = test_mean_reversion(btc_data['price'], \"Bitcoin\")\n",
        "eth_adf = test_mean_reversion(eth_data['price'], \"Ethereum\")\n",
        "\n",
        "print(\"\\nðŸ’¡ If prices follow random walk, past prices don't predict future prices\")\n",
        "print(\"   This supports weak-form market efficiency\")"
      ],
      "id": "7cd3f44d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions (Exercise 3)\n",
        "\n",
        "Write 200-250 words addressing:\n",
        "\n",
        "1.  **Efficiency Interpretation**: What do your autocorrelation and\n",
        "    momentum results suggest about Bitcoin market efficiency? Can small\n",
        "    autocorrelations or strategy profits coexist with efficient markets?\n",
        "\n",
        "2.  **Transaction Costs Matter**: The momentum strategy showed\n",
        "    \\[profit/loss\\] before transaction costs. Cryptocurrency trading\n",
        "    costs 0.1-0.5% per trade. Would your strategy be profitable after\n",
        "    accounting for costs? Show rough calculations.\n",
        "\n",
        "3.  **Limits to Arbitrage**: Even if inefficiencies exist (predictable\n",
        "    patterns), what practical barriers prevent traders from exploiting\n",
        "    them and eliminating the patterns?\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Exercise 4: GARCH Volatility Modeling & Structural Breaks\n",
        "\n",
        "**Learning Objectives:** - Apply GARCH models to cryptocurrency returns\n",
        "(Week 3, Â§3.4 theory) - Test for volatility clustering and asymmetric\n",
        "effects - Evaluate volatility forecasting accuracy (Mincer-Zarnowitz\n",
        "regression) - Detect structural breaks and regime shifts in volatility\n",
        "\n",
        "> **Connection to [Ch 03: Volatility\n",
        "> Modelling](../chapters/03_volatility_modelling.qmd) & [Ch 07:\n",
        "> Cryptocurrency](../chapters/07_cryptocurrency_digital_currency.qmd#sec-garch)**\n",
        ">\n",
        "> This exercise applies **Week 3 GARCH theory** to Bitcoin data. Youâ€™ll\n",
        "> estimate time-varying volatility, test for asymmetric effects\n",
        "> (leverage), forecast volatility, and test whether high GARCH\n",
        "> persistence is real or an artifact of regime shifts.\n",
        ">\n",
        "> **Key statistical concepts**: Volatility clustering, fat tails,\n",
        "> leverage effect, out-of-sample validation, structural breaks.\n",
        "\n",
        "### Part A: Statistical Tests for Volatility Properties\n",
        "\n",
        "**Before fitting GARCH, test for its key assumptions:**"
      ],
      "id": "9ca5626b-d499-4321-8558-24225a1cfac3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from scipy.stats import jarque_bera\n",
        "\n",
        "# Bitcoin returns (from Exercise 2)\n",
        "returns = btc_data['return'].dropna()\n",
        "\n",
        "# Test 1: Ljung-Box test on squared returns (volatility clustering)\n",
        "lb_test = acorr_ljungbox(returns**2, lags=[10], return_df=True)\n",
        "lb_stat = lb_test['lb_stat'].values[0]\n",
        "lb_pval = lb_test['lb_pvalue'].values[0]\n",
        "\n",
        "# Test 2: Jarque-Bera test (normality)\n",
        "jb_stat, jb_pval = jarque_bera(returns)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"STATISTICAL TESTS FOR GARCH ASSUMPTIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n1. Ljung-Box Test (Volatility Clustering)\")\n",
        "print(f\"   Hâ‚€: No autocorrelation in squared returns\")\n",
        "print(f\"   Statistic: {lb_stat:.2f} | p-value: {lb_pval:.4f}\")\n",
        "if lb_pval < 0.05:\n",
        "    print(f\"   âœ“ REJECT Hâ‚€ â†’ Significant volatility clustering (GARCH warranted)\")\n",
        "else:\n",
        "    print(f\"   âœ— Cannot reject Hâ‚€ â†’ No volatility clustering\")\n",
        "\n",
        "print(\"\\n2. Jarque-Bera Test (Normality)\")\n",
        "print(f\"   Hâ‚€: Returns are normally distributed\")\n",
        "print(f\"   Statistic: {jb_stat:.2f} | p-value: {jb_pval:.6f}\")\n",
        "if jb_pval < 0.05:\n",
        "    print(f\"   âœ“ REJECT Hâ‚€ â†’ Non-normal distribution (fat tails present)\")\n",
        "else:\n",
        "    print(f\"   âœ— Cannot reject Hâ‚€ â†’ Normal distribution\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Both tests should reject Hâ‚€ for cryptocurrency data\")\n",
        "print(\"   This justifies using GARCH with Student's t distribution\")"
      ],
      "id": "b7fd4f89"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretation**: Bitcoin should show p \\< 0.001 for both testsâ€”strong\n",
        "volatility clustering and fat tails.\n",
        "\n",
        "### Part B: GARCH(1,1) and GJR-GARCH Estimation\n",
        "\n",
        "**Fit symmetric GARCH(1,1) and asymmetric GJR-GARCH:**"
      ],
      "id": "7a1fa897-17e4-4167-ac0d-34135d3e5c65"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "\n",
        "# Convert returns to percentage for numerical stability\n",
        "returns_pct = returns * 100\n",
        "\n",
        "# Model 1: GARCH(1,1) with Student's t distribution (fat tails)\n",
        "model_garch = arch_model(returns_pct, vol='GARCH', p=1, q=1, dist='t')\n",
        "garch_fit = model_garch.fit(disp='off')\n",
        "\n",
        "# Model 2: GJR-GARCH (asymmetric, captures leverage effect)\n",
        "model_gjr = arch_model(returns_pct, vol='GARCH', p=1, o=1, q=1, dist='t')\n",
        "gjr_fit = model_gjr.fit(disp='off')\n",
        "\n",
        "# Extract parameters\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GARCH MODEL ESTIMATION RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n1. GARCH(1,1) with Student's t:\")\n",
        "print(f\"   Ï‰ (baseline):     {garch_fit.params['omega']:>8.4f}\")\n",
        "print(f\"   Î± (news impact):  {garch_fit.params['alpha[1]']:>8.4f}\")\n",
        "print(f\"   Î² (persistence):  {garch_fit.params['beta[1]']:>8.4f}\")\n",
        "print(f\"   Î± + Î²:            {garch_fit.params['alpha[1]'] + garch_fit.params['beta[1]']:>8.4f}\")\n",
        "print(f\"   df (tail):        {garch_fit.params['nu']:>8.2f} (normal = âˆž)\")\n",
        "print(f\"   AIC:              {garch_fit.aic:>8.2f}\")\n",
        "\n",
        "print(\"\\n2. GJR-GARCH (asymmetric):\")\n",
        "print(f\"   Ï‰ (baseline):     {gjr_fit.params['omega']:>8.4f}\")\n",
        "print(f\"   Î± (positive):     {gjr_fit.params['alpha[1]']:>8.4f}\")\n",
        "print(f\"   Î³ (asymmetry):    {gjr_fit.params['gamma[1]']:>8.4f}\")\n",
        "print(f\"   Î² (persistence):  {gjr_fit.params['beta[1]']:>8.4f}\")\n",
        "print(f\"   Î± + Î³ (negative): {gjr_fit.params['alpha[1]'] + gjr_fit.params['gamma[1]']:>8.4f}\")\n",
        "print(f\"   df (tail):        {gjr_fit.params['nu']:>8.2f}\")\n",
        "print(f\"   AIC:              {gjr_fit.aic:>8.2f}\")\n",
        "\n",
        "# Model comparison\n",
        "if gjr_fit.aic < garch_fit.aic:\n",
        "    improvement = garch_fit.aic - gjr_fit.aic\n",
        "    print(f\"\\nâœ“ GJR-GARCH preferred (AIC lower by {improvement:.2f})\")\n",
        "    print(f\"   Negative shocks increase volatility {(gjr_fit.params['alpha[1]'] + gjr_fit.params['gamma[1]']) / gjr_fit.params['alpha[1]']:.2f}Ã— more\")\n",
        "else:\n",
        "    print(f\"\\n  GARCH(1,1) preferred (symmetric effects)\")\n",
        "\n",
        "# Visualize conditional volatility\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "# Panel 1: Returns with Â±1Ïƒ GARCH bands\n",
        "conditional_vol_garch = garch_fit.conditional_volatility\n",
        "axes[0].plot(returns_pct.index, returns_pct, linewidth=0.5, alpha=0.7, label='Returns', color='blue')\n",
        "axes[0].fill_between(returns_pct.index, -conditional_vol_garch, conditional_vol_garch,\n",
        "                      alpha=0.2, color='red', label='Â±1Ïƒ (GARCH volatility)')\n",
        "axes[0].set_ylabel('Return (%)', fontsize=11)\n",
        "axes[0].set_title('Bitcoin Returns with GARCH(1,1) Conditional Volatility', fontsize=13)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Panel 2: GARCH vs GJR volatility over time\n",
        "conditional_vol_gjr = gjr_fit.conditional_volatility\n",
        "axes[1].plot(conditional_vol_garch.index, conditional_vol_garch, linewidth=1.5, \n",
        "             color='blue', label='GARCH(1,1)', alpha=0.7)\n",
        "axes[1].plot(conditional_vol_gjr.index, conditional_vol_gjr, linewidth=1.5,\n",
        "             color='red', label='GJR-GARCH', alpha=0.7)\n",
        "axes[1].set_xlabel('Date', fontsize=11)\n",
        "axes[1].set_ylabel('Conditional Volatility (%)', fontsize=11)\n",
        "axes[1].set_title('Time-Varying Volatility: GARCH vs GJR-GARCH', fontsize=13)\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ’¡ GARCH captures volatility spikes (2018 crash, 2020 COVID, 2021 bull run)\")\n",
        "print(\"   GJR-GARCH shows asymmetryâ€”bad news increases volatility more\")"
      ],
      "id": "73c5061e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Interpreting GARCH Parameters**\n",
        ">\n",
        "> **Persistence (Î± + Î²)**: - **~0.95-0.99**: High persistenceâ€”volatility\n",
        "> shocks decay slowly (typical for crypto) - **Half-life** = ln(0.5) /\n",
        "> ln(Î± + Î²). If Î±+Î²=0.98, half-life â‰ˆ 35 days\n",
        ">\n",
        "> **Asymmetry (Î³ in GJR)**: - **Î³ \\> 0**: Negative shocks (bad news)\n",
        "> increase volatility more than positive shocks - **Leverage effect**:\n",
        "> -5% drop increases vol more than +5% rally (typical for all assets)\n",
        ">\n",
        "> **Degrees of freedom (df)**: - **df \\< 10**: Very fat tails (extreme\n",
        "> events common) - **df â†’ âˆž**: Normal distribution (no fat tails)\n",
        "\n",
        "### Part C: News Impact Curves (Asymmetry Visualization)\n",
        "\n",
        "**Visualize how shocks of different sizes/signs affect volatility:**"
      ],
      "id": "764defb3-453a-45e8-96df-bb7b961a5e1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate news impact curves\n",
        "shocks = np.linspace(-10, 10, 200)  # -10% to +10% returns\n",
        "\n",
        "# GARCH(1,1) impact (symmetric)\n",
        "alpha_garch = garch_fit.params['alpha[1]']\n",
        "impact_garch = alpha_garch * shocks**2\n",
        "\n",
        "# GJR-GARCH impact (asymmetric)\n",
        "alpha_gjr = gjr_fit.params['alpha[1]']\n",
        "gamma_gjr = gjr_fit.params['gamma[1]']\n",
        "impact_gjr = alpha_gjr * shocks**2 + gamma_gjr * (shocks < 0) * shocks**2\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(shocks, impact_garch, linewidth=2.5, linestyle='--', color='blue', label='GARCH (symmetric)', alpha=0.8)\n",
        "plt.plot(shocks, impact_gjr, linewidth=2.5, color='red', label='GJR-GARCH (asymmetric)')\n",
        "\n",
        "# Highlight key points\n",
        "plt.axvline(0, color='black', linestyle=':', linewidth=1.5, alpha=0.5)\n",
        "plt.axvline(-5, color='red', linestyle=':', linewidth=1, alpha=0.5, label='Example: -5% shock')\n",
        "plt.axvline(+5, color='green', linestyle=':', linewidth=1, alpha=0.5, label='Example: +5% shock')\n",
        "\n",
        "# Annotate asymmetry\n",
        "neg5_impact = alpha_gjr * 25 + gamma_gjr * 25\n",
        "pos5_impact = alpha_gjr * 25\n",
        "plt.scatter([-5, 5], [neg5_impact, pos5_impact], s=150, c=['red', 'green'], \n",
        "            edgecolors='black', zorder=5, alpha=0.8)\n",
        "plt.text(-5, neg5_impact + 0.5, f'Impact: {neg5_impact:.2f}', ha='center', fontsize=10, fontweight='bold')\n",
        "plt.text(5, pos5_impact + 0.5, f'Impact: {pos5_impact:.2f}', ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.xlabel('News Shock (% return)', fontsize=12)\n",
        "plt.ylabel('Impact on Conditional Variance', fontsize=12)\n",
        "plt.title('News Impact Curves: How Shocks Affect Volatility', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate asymmetry ratio\n",
        "asymmetry_ratio = neg5_impact / pos5_impact\n",
        "print(f\"\\nAsymmetry Ratio:\")\n",
        "print(f\"  -5% shock impact / +5% shock impact = {asymmetry_ratio:.2f}\")\n",
        "print(f\"  â†’ Bad news increases volatility {asymmetry_ratio:.1f}Ã— more than good news\")"
      ],
      "id": "2455b56b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretation**: For Bitcoin, negative shocks typically increase\n",
        "volatility ~1.5-2Ã— more than positive shocks.\n",
        "\n",
        "### Part D: Volatility Forecasting & Out-of-Sample Validation\n",
        "\n",
        "**Test if GARCH forecasts future volatility accurately (Mincer-Zarnowitz\n",
        "regression):**"
      ],
      "id": "6a71d093-66a1-41eb-b0d4-0c8d42140d90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import linregress\n",
        "\n",
        "# Rolling-window forecast\n",
        "forecast_horizon = 22  # days (1 month ahead)\n",
        "train_size = 252 * 2   # 2 years training window\n",
        "\n",
        "forecasts_garch = []\n",
        "realized_vols = []\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ROLLING-WINDOW VOLATILITY FORECASTING\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Training window: {train_size} days | Forecast horizon: {forecast_horizon} days\")\n",
        "\n",
        "for start in range(train_size, len(returns_pct) - forecast_horizon, forecast_horizon):\n",
        "    # Train GARCH on historical data\n",
        "    train_data = returns_pct.iloc[start - train_size:start]\n",
        "    model_train = arch_model(train_data, vol='GARCH', p=1, q=1, dist='t')\n",
        "    fit_train = model_train.fit(disp='off')\n",
        "    \n",
        "    # Forecast next month's volatility\n",
        "    forecast = fit_train.forecast(horizon=forecast_horizon)\n",
        "    forecast_vol = np.sqrt(forecast.variance.values[-1, :].mean())  # Average over horizon\n",
        "    \n",
        "    # Realized volatility (actual)\n",
        "    test_data = returns_pct.iloc[start:start + forecast_horizon]\n",
        "    realized_vol = test_data.std()\n",
        "    \n",
        "    forecasts_garch.append(forecast_vol)\n",
        "    realized_vols.append(realized_vol)\n",
        "\n",
        "forecasts_garch = np.array(forecasts_garch)\n",
        "realized_vols = np.array(realized_vols)\n",
        "\n",
        "# Mincer-Zarnowitz regression: Realized = Î± + Î² Ã— Forecast + Îµ\n",
        "slope, intercept, r_value, p_value, std_err = linregress(forecasts_garch, realized_vols)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(((realized_vols - forecasts_garch)**2).mean())\n",
        "\n",
        "print(f\"\\nNumber of forecasts: {len(forecasts_garch)}\")\n",
        "print(f\"\\nMincer-Zarnowitz Regression Results:\")\n",
        "print(f\"  Intercept (Î±):  {intercept:>8.3f} (ideal = 0)\")\n",
        "print(f\"  Slope (Î²):      {slope:>8.3f} (ideal = 1)\")\n",
        "print(f\"  RÂ²:             {r_value**2:>8.3f}\")\n",
        "print(f\"  RMSE:           {rmse:>8.2f}%\")\n",
        "\n",
        "if abs(intercept) < 1 and abs(slope - 1) < 0.2:\n",
        "    print(f\"\\nâœ“ Forecast is approximately unbiased (Î±â‰ˆ0, Î²â‰ˆ1)\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸  Forecast shows bias (Î±â‰ 0 or Î²â‰ 1)\")\n",
        "\n",
        "# Visualize\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Panel 1: Mincer-Zarnowitz scatter\n",
        "ax1.scatter(forecasts_garch, realized_vols, alpha=0.6, s=80, edgecolor='black', linewidth=0.5)\n",
        "ax1.plot([forecasts_garch.min(), forecasts_garch.max()],\n",
        "         [forecasts_garch.min(), forecasts_garch.max()],\n",
        "         'r--', linewidth=2.5, label='Perfect forecast (45Â° line)')\n",
        "ax1.plot(forecasts_garch, intercept + slope * forecasts_garch,\n",
        "         'b-', linewidth=2.5, label=f'Fitted: y={intercept:.2f}+{slope:.2f}x (RÂ²={r_value**2:.2f})')\n",
        "ax1.set_xlabel('GARCH Forecast Volatility (%)', fontsize=12)\n",
        "ax1.set_ylabel('Realized Volatility (%)', fontsize=12)\n",
        "ax1.set_title('Mincer-Zarnowitz: Forecast Accuracy', fontsize=13)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Panel 2: Forecast errors over time\n",
        "errors = realized_vols - forecasts_garch\n",
        "ax2.plot(errors, linewidth=1.5, color='red', alpha=0.7)\n",
        "ax2.axhline(0, color='black', linestyle='--', linewidth=1.5)\n",
        "ax2.fill_between(range(len(errors)), 0, errors, alpha=0.3, color='red')\n",
        "ax2.set_xlabel('Forecast Period', fontsize=12)\n",
        "ax2.set_ylabel('Forecast Error (Realized - Forecast, %)', fontsize=12)\n",
        "ax2.set_title('Forecast Errors Over Time', fontsize=13)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ’¡ GARCH forecasts Bitcoin volatility reasonably (RÂ²~0.5-0.7)\")\n",
        "print(\"   But underestimates during extreme events (crashes, manias)\")"
      ],
      "id": "e366f2c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Connection to [Week 0, Â§0.6: Out-of-Sample\n",
        "> Validation](../chapters/00_foundations.qmd#sec-model-selection)**\n",
        ">\n",
        "> **Mincer-Zarnowitz regression** tests forecast unbiasedness: - **Î± =\n",
        "> 0**: No systematic over/under-prediction - **Î² = 1**: Forecast\n",
        "> correctly captures volatility scale - **High RÂ²**: Forecast explains\n",
        "> realized volatility well\n",
        ">\n",
        "> This is **honest evaluation**â€”train on past, test on future (no\n",
        "> look-ahead bias).\n",
        "\n",
        "### Part E: Structural Breaks Detection\n",
        "\n",
        "**Test if high GARCH persistence (Î±+Î² â‰ˆ 0.98) is real or artifact of\n",
        "regime shifts:**"
      ],
      "id": "8c2a67d3-13b7-47af-b2a8-38fec5fa6d14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Visual regime identification (rolling volatility)\n",
        "rolling_vol = returns_pct.rolling(window=30).std() * np.sqrt(252)\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(rolling_vol.index, rolling_vol, linewidth=1.5, color='blue', label='30-day rolling volatility')\n",
        "\n",
        "# Regime thresholds\n",
        "calm_threshold = 30\n",
        "turbulent_threshold = 60\n",
        "plt.axhline(calm_threshold, color='green', linestyle='--', linewidth=2, alpha=0.7, label=f'Calm threshold ({calm_threshold}%)')\n",
        "plt.axhline(turbulent_threshold, color='red', linestyle='--', linewidth=2, alpha=0.7, label=f'Turbulent threshold ({turbulent_threshold}%)')\n",
        "plt.fill_between(rolling_vol.index, 0, calm_threshold, alpha=0.1, color='green', label='Calm regime')\n",
        "plt.fill_between(rolling_vol.index, turbulent_threshold, rolling_vol.max(), alpha=0.1, color='red', label='Turbulent regime')\n",
        "\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Annualized Volatility (%)', fontsize=12)\n",
        "plt.title('Bitcoin Rolling Volatility: Regime Identification', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate regime statistics\n",
        "calm_pct = (rolling_vol < calm_threshold).sum() / len(rolling_vol.dropna()) * 100\n",
        "turbulent_pct = (rolling_vol > turbulent_threshold).sum() / len(rolling_vol.dropna()) * 100\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"REGIME IDENTIFICATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nRegime Statistics:\")\n",
        "print(f\"  Calm regime (<{calm_threshold}% vol):      {calm_pct:>6.1f}% of days\")\n",
        "print(f\"  Normal regime ({calm_threshold}-{turbulent_threshold}% vol):  {100 - calm_pct - turbulent_pct:>6.1f}% of days\")\n",
        "print(f\"  Turbulent regime (>{turbulent_threshold}% vol): {turbulent_pct:>6.1f}% of days\")\n",
        "\n",
        "# Step 2: Sub-period GARCH comparison\n",
        "mid_point = len(returns_pct) // 2\n",
        "returns_first = returns_pct.iloc[:mid_point]\n",
        "returns_second = returns_pct.iloc[mid_point:]\n",
        "\n",
        "# Fit GARCH to each sub-period\n",
        "model_first = arch_model(returns_first, vol='GARCH', p=1, q=1, dist='t')\n",
        "garch_first = model_first.fit(disp='off')\n",
        "persistence_first = garch_first.params['alpha[1]'] + garch_first.params['beta[1]']\n",
        "\n",
        "model_second = arch_model(returns_second, vol='GARCH', p=1, q=1, dist='t')\n",
        "garch_second = model_second.fit(disp='off')\n",
        "persistence_second = garch_second.params['alpha[1]'] + garch_second.params['beta[1]']\n",
        "\n",
        "# Full-sample persistence (from earlier)\n",
        "persistence_full = garch_fit.params['alpha[1]'] + garch_fit.params['beta[1]']\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STRUCTURAL BREAKS TEST: SUB-PERIOD GARCH PERSISTENCE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nFull sample persistence:   Î±+Î² = {persistence_full:.4f}\")\n",
        "print(f\"First half persistence:    Î±+Î² = {persistence_first:.4f}\")\n",
        "print(f\"Second half persistence:   Î±+Î² = {persistence_second:.4f}\")\n",
        "print(f\"Absolute difference:       Î”   = {abs(persistence_first - persistence_second):.4f}\")\n",
        "\n",
        "if abs(persistence_first - persistence_second) > 0.05:\n",
        "    print(f\"\\nâš ï¸  LARGE difference suggests REGIME SHIFTS, not true persistence!\")\n",
        "    print(f\"    Full-sample GARCH overestimates persistence by confusing regime changes with gradual decay.\")\n",
        "else:\n",
        "    print(f\"\\nâœ“  Similar persistence suggests GARCH model is stable across periods.\")\n",
        "\n",
        "# Model comparison (AIC)\n",
        "print(f\"\\nModel Comparison (AIC, lower = better):\")\n",
        "print(f\"  Full-sample GARCH:         {garch_fit.aic:.2f}\")\n",
        "print(f\"  Sub-periods total:         {garch_first.aic + garch_second.aic:.2f}\")\n",
        "\n",
        "if (garch_first.aic + garch_second.aic) < garch_fit.aic:\n",
        "    improvement = garch_fit.aic - (garch_first.aic + garch_second.aic)\n",
        "    print(f\"\\nâœ“ Sub-period models fit BETTER (AIC improvement: {improvement:.2f})\")\n",
        "    print(f\"  â†’ Evidence of structural breaks / regime shifts\")\n",
        "else:\n",
        "    print(f\"\\n  Full-sample model fits as well (no strong evidence of breaks)\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Key finding: If persistence differs across sub-periods,\")\n",
        "print(\"   full-sample GARCH is OVERESTIMATING true persistence!\")"
      ],
      "id": "9df33ac0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Implication: GARCH Persistence Partly Spurious**\n",
        ">\n",
        "> If sub-period persistence is significantly lower than full-sample\n",
        "> (e.g., 0.93 vs 0.98), this suggests:\n",
        ">\n",
        "> 1.  **Regime shifts exist**: Bitcoin alternates between calm and\n",
        ">     turbulent volatility states\n",
        "> 2.  **Full-sample GARCH confuses regimes with persistence**: Mistakes\n",
        ">     regime changes for gradual decay\n",
        "> 3.  **Better models needed**: Markov-switching GARCH, regime-dependent\n",
        ">     models, threshold models\n",
        ">\n",
        "> **Practical impact**: Risk models using single-regime GARCH\n",
        "> **overestimate** how long volatility shocks persist â†’ wrong hedging\n",
        "> ratios, wrong VaR forecasts.\n",
        ">\n",
        "> See [Ch 03, Â§3.5: Structural\n",
        "> Breaks](../chapters/03_volatility_modelling.qmd#sec-structural-breaks)\n",
        "\n",
        "### Reflection Questions (Exercise 4)\n",
        "\n",
        "Write 250-300 words addressing:\n",
        "\n",
        "1.  **GARCH vs GJR**: Did asymmetric GJR-GARCH fit better than symmetric\n",
        "    GARCH? What does the asymmetry parameter (Î³) tell you about\n",
        "    Bitcoinâ€™s volatility response to good vs bad news?\n",
        "\n",
        "2.  **Forecast accuracy**: How well did GARCH forecast future volatility\n",
        "    (RÂ² from Mincer-Zarnowitz)? When did forecasts fail most badly (look\n",
        "    at error plot)?\n",
        "\n",
        "3.  **Structural breaks**: Did sub-period persistence differ from\n",
        "    full-sample? If yes, what does this imply about using full-sample\n",
        "    GARCH for risk management?\n",
        "\n",
        "4.  **Practical implications**: If you were designing a crypto risk\n",
        "    model, would you use single-regime GARCH or a regime-switching\n",
        "    model? Justify your choice.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Summary and Integration\n",
        "\n",
        "### What Weâ€™ve Learned\n",
        "\n",
        "Through these exercises, youâ€™ve:\n",
        "\n",
        "1.  **Accessed real cryptocurrency market data** using public APIs,\n",
        "    experiencing data quality challenges and fragmentation\n",
        "\n",
        "2.  **Quantified extreme volatility** (60-80% annualized) that makes\n",
        "    cryptocurrency unsuitable as currency and challenging as investment\n",
        "\n",
        "3.  **Documented fat tail distributions** that violate normal\n",
        "    distribution assumptions and cause standard risk models to\n",
        "    underestimate tail risk\n",
        "\n",
        "4.  **Measured high correlations** within crypto (0.5-0.8) limiting\n",
        "    diversification benefits\n",
        "\n",
        "5.  **Tested market efficiency** finding mixed evidenceâ€”some weak\n",
        "    predictability but likely not exploitable after costs\n",
        "\n",
        "6.  **Evaluated inclusion claims** implicitly through data analysisâ€”if\n",
        "    crypto were banking the unbanked, weâ€™d see different adoption and\n",
        "    usage patterns\n",
        "\n",
        "### Connections to Course Themes\n",
        "\n",
        "-   **Week 2 (APIs)**: Cryptocurrency data is openly accessible via\n",
        "    APIs, democratizing financial data but creating standardization\n",
        "    challenges\n",
        "\n",
        "-   **Week 3 (Platforms)**: Exchanges are platforms matching\n",
        "    buyers/sellers; fragmentation creates arbitrage opportunities but\n",
        "    liquidity challenges\n",
        "\n",
        "-   **Week 6 (Financial Inclusion)**: Mobile money (M-Pesa) showed\n",
        "    rigorous welfare evidence; cryptocurrency shows speculative usage\n",
        "    among wealthy\n",
        "\n",
        "-   **Week 8 (Blockchain)**: Next week explores blockchain technology\n",
        "    and fraud detection more deeply\n",
        "\n",
        "### Critical Evaluation Framework\n",
        "\n",
        "When evaluating cryptocurrency or any FinTech innovation:\n",
        "\n",
        "1.  **Examine actual data** (adoption, usage, outcomes) versus marketing\n",
        "    claims\n",
        "2.  **Measure risks quantitatively** (volatility, correlations, tail\n",
        "    risk)\n",
        "3.  **Compare to alternatives** (mobile money, traditional finance)\n",
        "4.  **Demand welfare evidence** (does it help intended beneficiaries?)\n",
        "5.  **Account for barriers** (technical, knowledge, economic)\n",
        "\n",
        "### Assessment Preparation\n",
        "\n",
        "If your assessment involves a short research report or reflective\n",
        "analysis, this lab gives you two strong pathways:\n",
        "\n",
        "-   Empirical analysis of crypto returns (momentum, volatility,\n",
        "    correlations, tail risk)\n",
        "-   Evidence-based evaluation of â€œcrypto for inclusionâ€ claims using\n",
        "    data, mechanisms, and limitations\n",
        "\n",
        "### Further Exploration\n",
        "\n",
        "If interested in extending your analysis:\n",
        "\n",
        "-   **Cross-asset correlations**: Download S&P 500 or gold data; analyze\n",
        "    Bitcoin-equity correlation dynamics\n",
        "-   **Volatility forecasting**: Implement GARCH models to forecast\n",
        "    future volatility\n",
        "-   **Arbitrage opportunities**: Compare prices across multiple\n",
        "    exchanges in real-time\n",
        "-   **DeFi analysis**: Examine yield farming APYs, liquidity pool\n",
        "    dynamics, or stablecoin deviations from peg\n",
        "-   **On-chain metrics**: Analyze blockchain data (active addresses,\n",
        "    transaction volumes) as predictors\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "**Excellent work! Youâ€™ve completed rigorous empirical analysis of\n",
        "cryptocurrency markets, connecting data to theory and claims to\n",
        "evidence.**"
      ],
      "id": "f62d2593-67e2-49dd-afd9-b54085177d83"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "fin510",
      "display_name": "FIN510 Python",
      "language": "python",
      "path": "/Users/quinference/Library/Jupyter/kernels/fin510"
    }
  }
}