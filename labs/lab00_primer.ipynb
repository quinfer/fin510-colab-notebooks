{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Lab 0: Data Science Primer\"\n",
        "subtitle: \"Bias‚Äìvariance, uncertainty, validation\"\n",
        "format:\n",
        "  html:\n",
        "    toc: false\n",
        "    number-sections: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  message: false\n",
        "---\n",
        "\n",
        "::: callout-note\n",
        "### Expected Time\n",
        "- FIN510: Seminar hands‚Äëon ‚âà 60 min; \n",
        "- Directed learning extensions ‚âà 90‚Äì120 min\n",
        "- FIN720: Computer lab ‚âà 120 min\n",
        ":::\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab00_primer.ipynb)\n",
        "\n",
        "::: callout-note\n",
        "### How to use this lab\n",
        "- Work through the tasks in order and keep notes in your own notebook.\n",
        "- Reflection prompts are for your learning logs‚Äîthere is **no submission** for this lab.\n",
        "- Bring insights back to the seminar to connect with the Week 0 slide discussion.\n",
        ":::\n",
        "\n",
        "## Setup (Colab‚Äëonly installs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run this cell in Colab if needed\n",
        "try:\n",
        "    import numpy, pandas, matplotlib\n",
        "except Exception:\n",
        "    !pip -q install numpy pandas matplotlib scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before You Start: The Big Picture\n",
        "\n",
        "This primer lab builds foundations for rigorous financial data science. We focus on three critical concepts that prevent costly errors in production systems.\n",
        "\n",
        "::: {.callout-note}\n",
        "## The Three Foundations You'll Build\n",
        "\n",
        "**1. Bias-Variance Trade-off** ‚Üí Understanding when simpler models outperform complex ones  \n",
        "**2. Uncertainty Quantification** ‚Üí Measuring confidence in your estimates (not just point estimates)  \n",
        "**3. Time-Aware Validation** ‚Üí Preventing look-ahead bias in financial forecasting\n",
        "\n",
        "These aren't abstract theory‚Äîthey're professional standards that separate robust production systems from research toys.\n",
        ":::\n",
        "\n",
        "### What You'll Build Today\n",
        "\n",
        "By the end of this lab, you will have:\n",
        "\n",
        "- ‚úÖ Visual intuition for the bias-variance trade-off\n",
        "- ‚úÖ Working code for bootstrap confidence intervals\n",
        "- ‚úÖ Understanding of walk-forward validation for time series\n",
        "- ‚úÖ Diagnostic toolkit for financial return series\n",
        "\n",
        "**Time estimate:** 60 minutes (FIN510) | 90-120 minutes (FIN720 with extensions)\n",
        "\n",
        "::: {.callout-tip icon=false}\n",
        "## üéØ Learning Philosophy\n",
        "\n",
        "This lab emphasizes **pattern recognition over memorization**. You'll see repeating patterns:\n",
        "\n",
        "- Prepare data ‚Üí Analyze/visualize ‚Üí Validate results\n",
        "- Generate synthetic data ‚Üí Apply method ‚Üí Interpret output\n",
        "\n",
        "Master these patterns here, apply them to real financial data in later labs.\n",
        ":::\n",
        "\n",
        "## Orientation ‚Äî Notebook Basics (10 min)\n",
        "\n",
        "Let's start with a quick orientation to ensure your Python environment works correctly. This cell tests basic operations you'll use throughout the course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === Test 1: Basic output ===\n",
        "print(\"Hello, notebook!\")\n",
        "\n",
        "# === Test 2: Variables and assertions ===\n",
        "a = 2 + 2\n",
        "assert a == 4, \"Basic arithmetic check failed\"\n",
        "\n",
        "# === Test 3: Lists and slicing ===\n",
        "nums = [10, 20, 30, 40]\n",
        "assert nums[:2] == [10,20], \"List slicing check failed\"\n",
        "\n",
        "# === Test 4: Dictionaries (used heavily in financial data) ===\n",
        "info = {\"ticker\": \"AAPL\", \"price\": 185.0}\n",
        "assert \"ticker\" in info and isinstance(info[\"price\"], (int,float)), \"Dictionary check failed\"\n",
        "\n",
        "# === Test 5: Functions ===\n",
        "def add(x, y):\n",
        "    return x + y\n",
        "assert add(2,3) == 5, \"Function check failed\"\n",
        "\n",
        "print(\"‚úî All orientation checks passed - you're ready to proceed!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "## Understanding Assertions\n",
        "The `assert` statements are quality checks. If something fails, you get an immediate error message rather than silent bugs later. This is defensive programming‚Äîa professional standard.\n",
        ":::\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Visualize bias‚Äìvariance trade‚Äëoff on synthetic data\n",
        "- Compute bootstrap confidence intervals  \n",
        "- Practice time‚Äëaware validation (walk‚Äëforward schematic)\n",
        "- Diagnose stylized facts in return series\n",
        "\n",
        "## Task 1 ‚Äî Bias‚ÄìVariance Curves\n",
        "\n",
        "The bias-variance trade-off is fundamental to model selection. Simple models underfit (high bias), complex models overfit (high variance). The optimal model balances both.\n",
        "\n",
        "::: {.callout-important}\n",
        "## The Key Insight\n",
        "**Total Error = Bias¬≤ + Variance + Irreducible Noise**\n",
        "\n",
        "- **Bias¬≤**: Error from wrong assumptions (underfitting)\n",
        "- **Variance**: Error from sensitivity to training data (overfitting)\n",
        "- **Sweet spot**: Minimum MSE where bias and variance balance\n",
        ":::\n",
        "\n",
        "### Step 1: Generate the trade-off curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model complexity scale (1 = very simple, 10 = very complex)\n",
        "complexity = np.arange(1, 11)\n",
        "\n",
        "# Bias decreases with complexity (simple models underfit)\n",
        "bias2 = (1/complexity)**1.2\n",
        "\n",
        "# Variance increases with complexity (complex models overfit)\n",
        "variance = 0.03 * (complexity/10)**1.8\n",
        "\n",
        "# Total error (MSE) = Bias¬≤ + Variance\n",
        "mse = bias2 + variance\n",
        "\n",
        "# Find the optimal complexity\n",
        "optimal_idx = np.argmin(mse)\n",
        "optimal_complexity = complexity[optimal_idx]\n",
        "optimal_mse = mse[optimal_idx]\n",
        "\n",
        "print(f\"Optimal complexity: {optimal_complexity}\")\n",
        "print(f\"Minimum MSE: {optimal_mse:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Visualize the trade-off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# Plot the three curves\n",
        "plt.plot(complexity, bias2, 'o-', label='Bias¬≤ (underfitting)', linewidth=2, markersize=8)\n",
        "plt.plot(complexity, variance, 's-', label='Variance (overfitting)', linewidth=2, markersize=8)\n",
        "plt.plot(complexity, mse, '^-', label='MSE (total error)', linewidth=2, markersize=8, color='red')\n",
        "\n",
        "# Mark the optimal point\n",
        "plt.axvline(optimal_complexity, color='green', linestyle='--', alpha=0.5, \n",
        "            label=f'Optimal (complexity={optimal_complexity})')\n",
        "plt.plot(optimal_complexity, optimal_mse, 'g*', markersize=20)\n",
        "\n",
        "plt.xlabel('Model complexity (relative)', fontsize=11)\n",
        "plt.ylabel('Error', fontsize=11)\n",
        "plt.title('Bias‚ÄìVariance Trade‚Äëoff (Illustrative)', fontsize=13)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "## Reading the Chart\n",
        "- **Left side** (low complexity): Bias dominates ‚Üí model too simple\n",
        "- **Right side** (high complexity): Variance dominates ‚Üí model too flexible\n",
        "- **Green line**: The sweet spot where MSE is minimized\n",
        ":::\n",
        "\n",
        "**Checkpoint:** Where is MSE minimized? Explain why adding more complexity beyond this point **hurts** performance despite \"fitting\" the training data better.\n",
        "\n",
        "## Task 2 ‚Äî Bootstrap CI for Mean\n",
        "\n",
        "Point estimates (like \"mean return = 8%\") are incomplete‚Äîwe need **uncertainty quantification**. Bootstrap resampling lets us estimate confidence intervals without assuming distribution shape.\n",
        "\n",
        "::: {.callout-note}\n",
        "## Bootstrap Intuition\n",
        "**The Problem:** We have one sample, but want to know \"how variable is our estimate?\"  \n",
        "**The Solution:** Resample our data many times (with replacement) and see how estimates vary\n",
        "\n",
        "**Process:**\n",
        "1. Draw random sample from our data (with replacement, same size)\n",
        "2. Calculate statistic (e.g., mean)\n",
        "3. Repeat 1000-5000 times\n",
        "4. Use percentiles of bootstrap distribution as confidence interval\n",
        ":::\n",
        "\n",
        "### Step 1: Generate sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "# Simulate log-normal returns (realistic: positive skew, fat tail)\n",
        "x = np.random.lognormal(mean=0.0, sigma=0.5, size=300)\n",
        "\n",
        "print(f\"Sample size: {len(x)}\")\n",
        "print(f\"Sample mean: {np.mean(x):.4f}\")\n",
        "print(f\"Sample std: {np.std(x, ddof=1):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "## Why Lognormal?\n",
        "Financial returns often have positive skew (occasional large gains) and fat tails. Lognormal captures this better than normal distribution.\n",
        ":::\n",
        "\n",
        "### Step 2: Perform bootstrap resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Number of bootstrap iterations\n",
        "B = 2000\n",
        "\n",
        "# Store bootstrap means\n",
        "boot_means = []\n",
        "\n",
        "for i in range(B):\n",
        "    # Resample with replacement (same size as original)\n",
        "    xb = np.random.choice(x, size=len(x), replace=True)\n",
        "    \n",
        "    # Calculate mean of this bootstrap sample\n",
        "    boot_means.append(np.mean(xb))\n",
        "\n",
        "# Convert to array for analysis\n",
        "boot_means = np.array(boot_means)\n",
        "\n",
        "print(f\"Generated {B} bootstrap samples\")\n",
        "print(f\"Mean of bootstrap means: {np.mean(boot_means):.4f}\")\n",
        "print(f\"Std of bootstrap means: {np.std(boot_means):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Calculate confidence interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 95% confidence interval: use 2.5th and 97.5th percentiles\n",
        "ci_low, ci_high = np.percentile(boot_means, [2.5, 97.5])\n",
        "\n",
        "print(f\"\\n95% Bootstrap Confidence Interval:\")\n",
        "print(f\"Lower bound: {ci_low:.4f}\")\n",
        "print(f\"Point estimate: {np.mean(x):.4f}\")\n",
        "print(f\"Upper bound: {ci_high:.4f}\")\n",
        "\n",
        "# Sanity check: point estimate should be inside CI\n",
        "assert ci_low < np.mean(x) < ci_high, \"Point estimate outside CI!\"\n",
        "print(\"\\n‚úî Bootstrap CI computed successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Visualize the bootstrap distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# Histogram of bootstrap means\n",
        "plt.hist(boot_means, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "\n",
        "# Mark the confidence interval\n",
        "plt.axvline(ci_low, color='red', linestyle='--', linewidth=2, label=f'95% CI: [{ci_low:.3f}, {ci_high:.3f}]')\n",
        "plt.axvline(ci_high, color='red', linestyle='--', linewidth=2)\n",
        "plt.axvline(np.mean(x), color='green', linestyle='-', linewidth=2, label=f'Sample mean: {np.mean(x):.3f}')\n",
        "\n",
        "plt.xlabel('Bootstrap Mean Values', fontsize=11)\n",
        "plt.ylabel('Frequency', fontsize=11)\n",
        "plt.title('Bootstrap Distribution of the Mean (B=2000)', fontsize=13)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-important}\n",
        "## Interpretation\n",
        "**What the 95% CI means (frequentist):** If we repeated this process many times, 95% of the intervals would contain the true population mean.\n",
        "\n",
        "**What it does NOT mean:** There's NOT a 95% probability the true mean is in this interval. The true mean either is or isn't in there‚Äîthe probability refers to the **procedure**, not this specific interval.\n",
        "\n",
        "**Bayesian credible interval** (different concept): Given our data and prior beliefs, there's a 95% probability the parameter is in this range. Requires specifying priors.\n",
        ":::\n",
        "\n",
        "**Checkpoint:** Why does bootstrap work? Hint: think about the relationship between sample-to-population and resample-to-sample.\n",
        "\n",
        "## Task 3 ‚Äî Walk‚ÄëForward Validation Schematic\n",
        "\n",
        "Financial data has temporal structure‚Äîyou can't randomly split train/test without leaking future information into the past. **Walk-forward validation** respects time ordering.\n",
        "\n",
        "::: {.callout-important}\n",
        "## Why Random Splitting Fails in Finance\n",
        "Standard k-fold cross-validation shuffles data randomly. In finance, this creates **look-ahead bias**:\n",
        "\n",
        "- Model trained on 2023 data, tested on 2022 data ‚Üí unrealistic!\n",
        "- Information from the future leaks into the past\n",
        "- Performance estimates are optimistically biased\n",
        "\n",
        "**Solution:** Always split by time, train on past, validate on future.\n",
        ":::\n",
        "\n",
        "### Visualize walk-forward structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "\n",
        "# Define training and validation windows\n",
        "blocks = [\n",
        "    (0, 20, 'Train 1'),  \n",
        "    (20, 30, 'Valid 1'),  \n",
        "    (30, 50, 'Train 2'),  # Expands: includes Train 1 + Valid 1\n",
        "    (50, 60, 'Valid 2')\n",
        "]\n",
        "\n",
        "for start, end, label in blocks:\n",
        "    # Color training blocks blue, validation blocks orange\n",
        "    color = 'tab:blue' if 'Train' in label else 'tab:orange'\n",
        "    \n",
        "    plt.barh(0, end-start, left=start, height=0.6, color=color, edgecolor='black', linewidth=1.5)\n",
        "    plt.text((start+end)/2, 0, label, ha='center', va='center', \n",
        "             color='white', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.yticks([])\n",
        "plt.xlabel('Time index (e.g., months or days)', fontsize=11)\n",
        "plt.xlim(-2, 62)\n",
        "plt.title('Rolling/Expanding Walk‚ÄëForward Validation (Toy Example)', fontsize=13)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úî Walk‚Äëforward schematic drawn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "## Two Common Variants\n",
        "1. **Rolling Window**: Train on last N periods only (e.g., Train 2 uses days 30-50)\n",
        "   - Adapts quickly to regime changes\n",
        "   - Less data per model\n",
        "\n",
        "2. **Expanding Window**: Train on all past data (e.g., Train 2 uses days 0-50)\n",
        "   - More stable estimates\n",
        "   - Slower to adapt to structural breaks\n",
        ":::\n",
        "\n",
        "**Deliverable:** Write one short paragraph on when to prefer simple models despite recent evidence favoring complexity (@kelly2024complexity). Consider: regime shifts, parameter estimation error, interpretability requirements, regulatory constraints.\n",
        "\n",
        "## Task 4 ‚Äî Stylised-Fact Diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Synthetic returns with regime shifts to emphasise stylised facts\n",
        "regimes = np.concatenate([\n",
        "    np.random.normal(0, 0.6, size=250),\n",
        "    np.random.normal(0, 1.8, size=120),\n",
        "    np.random.normal(0, 0.9, size=200)\n",
        "]) / 100\n",
        "returns = pd.Series(regimes)\n",
        "\n",
        "kurt = stats.kurtosis(returns, fisher=False)\n",
        "acf_abs_lag1 = returns.abs().autocorr(lag=1)\n",
        "\n",
        "downside = returns[returns < 0]\n",
        "upside = returns[returns >= 0]\n",
        "semivar_down = (downside ** 2).mean()\n",
        "semivar_up = (upside ** 2).mean()\n",
        "\n",
        "roll_mean = returns.rolling(60).mean()\n",
        "roll_std = returns.rolling(60).std()\n",
        "\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10,8), sharex=True)\n",
        "returns.plot(ax=ax[0], color='tab:blue', linewidth=0.8)\n",
        "ax[0].set_title('Synthetic Returns with Regimes')\n",
        "ax[0].grid(alpha=0.3)\n",
        "\n",
        "returns.abs().plot(ax=ax[1], color='tab:orange', linewidth=0.8)\n",
        "ax[1].set_title('|Returns| Highlight Volatility Clustering')\n",
        "ax[1].grid(alpha=0.3)\n",
        "\n",
        "roll_mean.plot(ax=ax[2], color='tab:green', linewidth=1, label='Rolling mean (60)')\n",
        "roll_std.plot(ax=ax[2], color='tab:red', linewidth=1, label='Rolling std (60)')\n",
        "ax[2].set_title('Rolling Moments ‚Äî Regime Signals')\n",
        "ax[2].legend()\n",
        "ax[2].grid(alpha=0.3)\n",
        "ax[2].set_xlabel('Observation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Kurtosis (Gaussian=3): {kurt:.2f}\")\n",
        "print(f\"Autocorr |returns| lag 1: {acf_abs_lag1:.2f}\")\n",
        "print(f\"Downside semivariance: {semivar_down:.4f}\")\n",
        "print(f\"Upside semivariance:   {semivar_up:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tail risk: how does the kurtosis compare to the Gaussian benchmark (3)?\n",
        "- Volatility memory: does the |returns| autocorrelation justify extra lags in your models?\n",
        "- Asymmetry: what do the downside vs upside semivariances imply for features?\n",
        "- Regime shifts: where do rolling mean/std change and how should validation windows respond?\n",
        "\n",
        "Checkpoint: Draft a bullet list of features or diagnostics you would add before escalating model complexity.\n",
        "\n",
        "## Reflection ‚Äî Complexity Decision Flow\n",
        "\n",
        "Link your outputs back to the primer deck‚Äôs decision flow. In your notes, capture 2‚Äì3 bullet points for each step:\n",
        "\n",
        "1. Evidence of richer signal (bias‚Äìvariance + stylised facts)\n",
        "2. Baseline benchmark you would defend\n",
        "3. Validation design to test complexity honestly\n",
        "4. Governance checks before promoting Model‚ÄØB (@kelly2024complexity)\n",
        "\n",
        "::: callout-tip\n",
        "### Troubleshooting\n",
        "- If a plot is blank: check variable names and that x/y lengths match.\n",
        "- If a cell fails: run Setup, then Runtime ‚Üí Restart and run all (Colab).\n",
        "- If numbers differ: verify random seeds and parameters.\n",
        ":::\n",
        "\n",
        "## Governance & Failure Modes Checklist\n",
        "\n",
        "- Flag two potential leakage risks in your coursework dataset and note how you will test for them.\n",
        "- Assign a notional ‚Äúmodel steward‚Äù and list what they must sign off before deployment.\n",
        "- Pick one explainability technique (e.g., SHAP, PDP) and describe how it would reduce black-box anxiety for stakeholders.\n",
        "\n",
        "## Save Outputs (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.savefig('lab00_last_figure.png', dpi=150)\n",
        "\"Saved: lab00_last_figure.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exit Ticket (Optional, No Submission)\n",
        "\n",
        "- Dataset you will explore with a complex model and why it merits richer features.\n",
        "- Validation design you will implement to prove the complex model beats the baseline.\n",
        "- Governance or ethical concern you will monitor as you iterate.\n",
        "\n",
        "::: callout-note\n",
        "### Further Reading (Hilpisch 2019)\n",
        "- See our curated list: [Hilpisch Code Resources](../resources/hilpisch-code.qmd) ‚Äî Week 0 (Primer)\n",
        "- Chapter 13 notebooks (statistics, ML workflows) show squared‚Äëloss diagnostics, residual analysis, and evaluation patterns consistent with this lab.\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nlp_env",
      "language": "python",
      "display_name": "Python (nlp_env)",
      "path": "/Users/quinference/Library/Jupyter/kernels/nlp_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}