{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Lab 0: Data Science Primer\"\n",
        "subtitle: \"Bias–variance, uncertainty, validation\"\n",
        "format:\n",
        "  html:\n",
        "    toc: false\n",
        "    number-sections: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  message: false\n",
        "---\n",
        "\n",
        "::: callout-note\n",
        "### Expected Time\n",
        "- FIN510: Seminar hands‑on ≈ 60 min; \n",
        "- Directed learning extensions ≈ 90–120 min\n",
        "- FIN720: Computer lab ≈ 120 min\n",
        ":::\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab00_primer.ipynb)\n",
        "\n",
        "::: callout-note\n",
        "### How to use this lab\n",
        "- Work through the tasks in order and keep notes in your own notebook.\n",
        "- Reflection prompts are for your learning logs—there is **no submission** for this lab.\n",
        "- Bring insights back to the seminar to connect with the Week 0 slide discussion.\n",
        ":::\n",
        "\n",
        "## Setup (Colab‑only installs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run this cell in Colab if needed\n",
        "try:\n",
        "    import numpy, pandas, matplotlib\n",
        "except Exception:\n",
        "    !pip -q install numpy pandas matplotlib scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Orientation — Notebook Basics (10 min)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Running cells, variables, functions, and a tiny assert\n",
        "print(\"Hello, notebook!\")\n",
        "\n",
        "a = 2 + 2\n",
        "assert a == 4, \"Basic arithmetic check failed\"\n",
        "\n",
        "nums = [10, 20, 30, 40]\n",
        "assert nums[:2] == [10,20]\n",
        "\n",
        "info = {\"ticker\": \"AAPL\", \"price\": 185.0}\n",
        "assert \"ticker\" in info and isinstance(info[\"price\"], (int,float))\n",
        "\n",
        "def add(x, y):\n",
        "    return x + y\n",
        "assert add(2,3) == 5\n",
        "\n",
        "print(\"Orientation checks passed ✔\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives\n",
        "\n",
        "- Visualise bias–variance trade‑off on synthetic data\n",
        "- Compute bootstrap confidence intervals\n",
        "- Practise time‑aware validation (walk‑forward schematic)\n",
        "\n",
        "## Task 1 — Bias–Variance Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "complexity = np.arange(1, 11)\n",
        "bias2 = (1/complexity)**1.2\n",
        "variance = 0.03 * (complexity/10)**1.8\n",
        "mse = bias2 + variance\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(complexity, bias2, 'o-', label='Bias²')\n",
        "plt.plot(complexity, variance, 's-', label='Variance')\n",
        "plt.plot(complexity, mse, '^-', label='MSE')\n",
        "plt.xlabel('Model complexity (relative)')\n",
        "plt.ylabel('Error')\n",
        "plt.title('Bias–Variance Trade‑off (Illustrative)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(); plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkpoint: Where is MSE minimised? Explain why.\n",
        "\n",
        "## Task 2 — Bootstrap CI for Mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(3)\n",
        "x = np.random.lognormal(mean=0.0, sigma=0.5, size=300)\n",
        "B = 2000\n",
        "boot_means = []\n",
        "for _ in range(B):\n",
        "    xb = np.random.choice(x, size=len(x), replace=True)\n",
        "    boot_means.append(np.mean(xb))\n",
        "\n",
        "boot_means = np.array(boot_means)\n",
        "ci_low, ci_high = np.percentile(boot_means, [2.5, 97.5])\n",
        "ci_low, ci_high\n",
        "assert ci_low < np.mean(x) < ci_high\n",
        "print(\"Bootstrap CI computed ✔\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Discuss: CI meaning (frequentist) vs credible interval (Bayesian).\n",
        "\n",
        "## Task 3 — Walk‑Forward Validation Schematic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,2.5))\n",
        "blocks = [(0,20, 'Train 1'), (20,30,'Valid 1'), (30,50,'Train 2'), (50,60,'Valid 2')]\n",
        "for s,e,label in blocks:\n",
        "    plt.barh(0, e-s, left=s, height=0.6,\n",
        "             color='tab:blue' if 'Train' in label else 'tab:orange')\n",
        "    plt.text((s+e)/2, 0, label, ha='center', va='center', color='white', fontsize=10)\n",
        "plt.yticks([]); plt.xlabel('Time index'); plt.xlim(0,60)\n",
        "plt.title('Rolling/Expanding Walk‑Forward (Toy)'); plt.tight_layout()\n",
        "print(\"Walk‑forward schematic drawn ✔\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deliverable: One short paragraph on when to prefer simple models despite @kelly2024complexity.\n",
        "\n",
        "## Task 4 — Stylised-Fact Diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Synthetic returns with regime shifts to emphasise stylised facts\n",
        "regimes = np.concatenate([\n",
        "    np.random.normal(0, 0.6, size=250),\n",
        "    np.random.normal(0, 1.8, size=120),\n",
        "    np.random.normal(0, 0.9, size=200)\n",
        "]) / 100\n",
        "returns = pd.Series(regimes)\n",
        "\n",
        "kurt = stats.kurtosis(returns, fisher=False)\n",
        "acf_abs_lag1 = returns.abs().autocorr(lag=1)\n",
        "\n",
        "downside = returns[returns < 0]\n",
        "upside = returns[returns >= 0]\n",
        "semivar_down = (downside ** 2).mean()\n",
        "semivar_up = (upside ** 2).mean()\n",
        "\n",
        "roll_mean = returns.rolling(60).mean()\n",
        "roll_std = returns.rolling(60).std()\n",
        "\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10,8), sharex=True)\n",
        "returns.plot(ax=ax[0], color='tab:blue', linewidth=0.8)\n",
        "ax[0].set_title('Synthetic Returns with Regimes')\n",
        "ax[0].grid(alpha=0.3)\n",
        "\n",
        "returns.abs().plot(ax=ax[1], color='tab:orange', linewidth=0.8)\n",
        "ax[1].set_title('|Returns| Highlight Volatility Clustering')\n",
        "ax[1].grid(alpha=0.3)\n",
        "\n",
        "roll_mean.plot(ax=ax[2], color='tab:green', linewidth=1, label='Rolling mean (60)')\n",
        "roll_std.plot(ax=ax[2], color='tab:red', linewidth=1, label='Rolling std (60)')\n",
        "ax[2].set_title('Rolling Moments — Regime Signals')\n",
        "ax[2].legend()\n",
        "ax[2].grid(alpha=0.3)\n",
        "ax[2].set_xlabel('Observation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Kurtosis (Gaussian=3): {kurt:.2f}\")\n",
        "print(f\"Autocorr |returns| lag 1: {acf_abs_lag1:.2f}\")\n",
        "print(f\"Downside semivariance: {semivar_down:.4f}\")\n",
        "print(f\"Upside semivariance:   {semivar_up:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tail risk: how does the kurtosis compare to the Gaussian benchmark (3)?\n",
        "- Volatility memory: does the |returns| autocorrelation justify extra lags in your models?\n",
        "- Asymmetry: what do the downside vs upside semivariances imply for features?\n",
        "- Regime shifts: where do rolling mean/std change and how should validation windows respond?\n",
        "\n",
        "Checkpoint: Draft a bullet list of features or diagnostics you would add before escalating model complexity.\n",
        "\n",
        "## Reflection — Complexity Decision Flow\n",
        "\n",
        "Link your outputs back to the primer deck’s decision flow. In your notes, capture 2–3 bullet points for each step:\n",
        "\n",
        "1. Evidence of richer signal (bias–variance + stylised facts)\n",
        "2. Baseline benchmark you would defend\n",
        "3. Validation design to test complexity honestly\n",
        "4. Governance checks before promoting Model B (@kelly2024complexity)\n",
        "\n",
        "::: callout-tip\n",
        "### Troubleshooting\n",
        "- If a plot is blank: check variable names and that x/y lengths match.\n",
        "- If a cell fails: run Setup, then Runtime → Restart and run all (Colab).\n",
        "- If numbers differ: verify random seeds and parameters.\n",
        ":::\n",
        "\n",
        "## Governance & Failure Modes Checklist\n",
        "\n",
        "- Flag two potential leakage risks in your coursework dataset and note how you will test for them.\n",
        "- Assign a notional “model steward” and list what they must sign off before deployment.\n",
        "- Pick one explainability technique (e.g., SHAP, PDP) and describe how it would reduce black-box anxiety for stakeholders.\n",
        "\n",
        "## Save Outputs (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.savefig('lab00_last_figure.png', dpi=150)\n",
        "\"Saved: lab00_last_figure.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exit Ticket (Optional, No Submission)\n",
        "\n",
        "- Dataset you will explore with a complex model and why it merits richer features.\n",
        "- Validation design you will implement to prove the complex model beats the baseline.\n",
        "- Governance or ethical concern you will monitor as you iterate.\n",
        "\n",
        "::: callout-note\n",
        "### Further Reading (Hilpisch 2019)\n",
        "- See our curated list: [Hilpisch Code Resources](../resources/hilpisch-code.qmd) — Week 0 (Primer)\n",
        "- Chapter 13 notebooks (statistics, ML workflows) show squared‑loss diagnostics, residual analysis, and evaluation patterns consistent with this lab.\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nlp_env",
      "language": "python",
      "display_name": "Python (nlp_env)",
      "path": "/Users/quinference/Library/Jupyter/kernels/nlp_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}