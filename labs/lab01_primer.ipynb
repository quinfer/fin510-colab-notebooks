{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: Data Science Primer\n",
        "\n",
        "Bias‚Äìvariance, uncertainty, validation\n",
        "\n",
        "> **Expected Time**\n",
        ">\n",
        "> -   Core lab: ‚âà 60 minutes\n",
        "> -   Directed learning extensions: +30‚Äì60 minutes\n",
        "\n",
        "<figure>\n",
        "<a\n",
        "href=\"https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab01_primer.ipynb\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "<figcaption>Open in Colab</figcaption>\n",
        "</figure>\n",
        "\n",
        "> **How to use this lab**\n",
        ">\n",
        "> -   Work through the tasks in order and keep notes in your own\n",
        ">     notebook.\n",
        "> -   Reflection prompts are for your learning logs‚Äîthere is **no\n",
        ">     submission** for this lab.\n",
        "> -   Bring insights back to the seminar to connect with the Week 1\n",
        ">     slide discussion.\n",
        "\n",
        "## Setup (Colab‚Äëonly installs)"
      ],
      "id": "6ecaab95-a20f-476e-8959-329c8ed0300f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this cell in Colab if needed\n",
        "try:\n",
        "    import numpy, pandas, matplotlib\n",
        "except Exception:\n",
        "    !pip -q install numpy pandas matplotlib scipy"
      ],
      "id": "74fac5d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before You Start: The Big Picture\n",
        "\n",
        "This primer lab builds foundations for rigorous financial data science.\n",
        "We focus on three critical concepts that prevent costly errors in\n",
        "production systems.\n",
        "\n",
        "> **The Three Foundations You‚Äôll Build**\n",
        ">\n",
        "> **1. Bias-Variance Trade-off** ‚Üí Understanding when simpler models\n",
        "> outperform complex ones  \n",
        "> **2. Uncertainty Quantification** ‚Üí Measuring confidence in your\n",
        "> estimates (not just point estimates)  \n",
        "> **3. Time-Aware Validation** ‚Üí Preventing look-ahead bias in financial\n",
        "> forecasting\n",
        ">\n",
        "> These aren‚Äôt abstract theory‚Äîthey‚Äôre professional standards that\n",
        "> separate robust production systems from research toys.\n",
        "\n",
        "### What You‚Äôll Build Today\n",
        "\n",
        "By the end of this lab, you will have:\n",
        "\n",
        "-   ‚úÖ Visual intuition for the bias-variance trade-off\n",
        "-   ‚úÖ Working code for bootstrap confidence intervals\n",
        "-   ‚úÖ Understanding of walk-forward validation for time series\n",
        "-   ‚úÖ Diagnostic toolkit for financial return series\n",
        "\n",
        "**Time estimate:** ‚âà 60 minutes (plus optional extensions)\n",
        "\n",
        "> **üéØ Learning Philosophy**\n",
        ">\n",
        "> This lab emphasizes **pattern recognition over memorization**. You‚Äôll\n",
        "> see repeating patterns:\n",
        ">\n",
        "> -   Prepare data ‚Üí Analyze/visualize ‚Üí Validate results\n",
        "> -   Generate synthetic data ‚Üí Apply method ‚Üí Interpret output\n",
        ">\n",
        "> Master these patterns here, apply them to real financial data in later\n",
        "> labs.\n",
        "\n",
        "## Orientation ‚Äî Notebook Basics (10 min)\n",
        "\n",
        "Let‚Äôs start with a quick orientation to ensure your Python environment\n",
        "works correctly. This cell tests basic operations you‚Äôll use throughout\n",
        "the course."
      ],
      "id": "a10018a8-f311-46b9-a34c-faf4bfb23521"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Test 1: Basic output ===\n",
        "print(\"Hello, notebook!\")\n",
        "\n",
        "# === Test 2: Variables and assertions ===\n",
        "a = 2 + 2\n",
        "assert a == 4, \"Basic arithmetic check failed\"\n",
        "\n",
        "# === Test 3: Lists and slicing ===\n",
        "nums = [10, 20, 30, 40]\n",
        "assert nums[:2] == [10,20], \"List slicing check failed\"\n",
        "\n",
        "# === Test 4: Dictionaries (used heavily in financial data) ===\n",
        "info = {\"ticker\": \"AAPL\", \"price\": 185.0}\n",
        "assert \"ticker\" in info and isinstance(info[\"price\"], (int,float)), \"Dictionary check failed\"\n",
        "\n",
        "# === Test 5: Functions ===\n",
        "def add(x, y):\n",
        "    return x + y\n",
        "assert add(2,3) == 5, \"Function check failed\"\n",
        "\n",
        "print(\"‚úî All orientation checks passed - you're ready to proceed!\")"
      ],
      "id": "5f2776d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Understanding Assertions**\n",
        ">\n",
        "> The `assert` statements are quality checks. If something fails, you\n",
        "> get an immediate error message rather than silent bugs later. This is\n",
        "> defensive programming‚Äîa professional standard.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "-   Visualize bias‚Äìvariance trade‚Äëoff on synthetic data\n",
        "-   Compute bootstrap confidence intervals  \n",
        "-   Practice time‚Äëaware validation (walk‚Äëforward schematic)\n",
        "-   Diagnose stylized facts in return series\n",
        "\n",
        "## Task 1 ‚Äî Bias‚ÄìVariance Curves\n",
        "\n",
        "The bias-variance trade-off is fundamental to model selection. Simple\n",
        "models underfit (high bias), complex models overfit (high variance). The\n",
        "optimal model balances both.\n",
        "\n",
        "> **The Key Insight**\n",
        ">\n",
        "> **Total Error = Bias¬≤ + Variance + Irreducible Noise**\n",
        ">\n",
        "> -   **Bias¬≤**: Error from wrong assumptions (underfitting)\n",
        "> -   **Variance**: Error from sensitivity to training data\n",
        ">     (overfitting)\n",
        "> -   **Sweet spot**: Minimum MSE where bias and variance balance\n",
        "\n",
        "### Step 1: Generate the trade-off curves"
      ],
      "id": "471d4bff-e4aa-42ab-8a26-7ac9766d14e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model complexity scale (1 = very simple, 10 = very complex)\n",
        "complexity = np.arange(1, 11)\n",
        "\n",
        "# Bias decreases with complexity (simple models underfit)\n",
        "bias2 = (1/complexity)**1.2\n",
        "\n",
        "# Variance increases with complexity (complex models overfit)\n",
        "variance = 0.03 * (complexity/10)**1.8\n",
        "\n",
        "# Total error (MSE) = Bias¬≤ + Variance\n",
        "mse = bias2 + variance\n",
        "\n",
        "# Find the optimal complexity\n",
        "optimal_idx = np.argmin(mse)\n",
        "optimal_complexity = complexity[optimal_idx]\n",
        "optimal_mse = mse[optimal_idx]\n",
        "\n",
        "print(f\"Optimal complexity: {optimal_complexity}\")\n",
        "print(f\"Minimum MSE: {optimal_mse:.4f}\")"
      ],
      "id": "f24c9845"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Visualize the trade-off"
      ],
      "id": "8c792b51-4c40-4a13-a759-04fcd83afc03"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reuse optimal from Step 1 (or recompute so this step is self-contained)\n",
        "optimal_idx = np.argmin(mse)\n",
        "optimal_complexity = complexity[optimal_idx]\n",
        "optimal_mse = mse[optimal_idx]\n",
        "print(f\"MSE is minimized at complexity = {optimal_complexity} (minimum MSE = {optimal_mse:.4f})\")\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# Plot the three curves\n",
        "plt.plot(complexity, bias2, 'o-', label='Bias¬≤ (underfitting)', linewidth=2, markersize=8)\n",
        "plt.plot(complexity, variance, 's-', label='Variance (overfitting)', linewidth=2, markersize=8)\n",
        "plt.plot(complexity, mse, '^-', label='MSE (total error)', linewidth=2, markersize=8, color='red')\n",
        "\n",
        "# Mark the optimal point\n",
        "plt.axvline(optimal_complexity, color='green', linestyle='--', alpha=0.5, \n",
        "            label=f'Optimal (complexity={optimal_complexity})')\n",
        "plt.plot(optimal_complexity, optimal_mse, 'g*', markersize=20)\n",
        "\n",
        "plt.xlabel('Model complexity (relative)', fontsize=11)\n",
        "plt.ylabel('Error', fontsize=11)\n",
        "plt.title('Bias‚ÄìVariance Trade‚Äëoff (Illustrative)', fontsize=13)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "7d1e3f39"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reading the Chart**\n",
        ">\n",
        "> -   **Left side** (low complexity): Bias dominates ‚Üí model too simple\n",
        "> -   **Right side** (high complexity): Variance dominates ‚Üí model too\n",
        ">     flexible\n",
        "> -   **Green line**: The sweet spot where MSE is minimized\n",
        "\n",
        "**Checkpoint:** Where is MSE minimized? Explain why adding more\n",
        "complexity beyond this point **hurts** performance despite ‚Äúfitting‚Äù the\n",
        "training data better.\n",
        "\n",
        "## Task 2 ‚Äî Bootstrap CI for Mean\n",
        "\n",
        "Point estimates (like ‚Äúmean return = 8%‚Äù) are incomplete‚Äîwe need\n",
        "**uncertainty quantification**. Bootstrap resampling lets us estimate\n",
        "confidence intervals without assuming distribution shape.\n",
        "\n",
        "> **Bootstrap Intuition**\n",
        ">\n",
        "> **The Problem:** We have one sample, but want to know ‚Äúhow variable is\n",
        "> our estimate?‚Äù  \n",
        "> **The Solution:** Resample our data many times (with replacement) and\n",
        "> see how estimates vary\n",
        ">\n",
        "> **Process:** 1. Draw random sample from our data (with replacement,\n",
        "> same size) 2. Calculate statistic (e.g., mean) 3. Repeat 1000-5000\n",
        "> times 4. Use percentiles of bootstrap distribution as confidence\n",
        "> interval\n",
        "\n",
        "### Step 1: Generate sample data"
      ],
      "id": "61f7083e-3eac-4709-9e45-942199f8ab99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "# Simulate log-normal returns (realistic: positive skew, fat tail)\n",
        "x = np.random.lognormal(mean=0.0, sigma=0.5, size=300)\n",
        "\n",
        "print(f\"Sample size: {len(x)}\")\n",
        "print(f\"Sample mean: {np.mean(x):.4f}\")\n",
        "print(f\"Sample std: {np.std(x, ddof=1):.4f}\")"
      ],
      "id": "701e9a6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Why Lognormal?**\n",
        ">\n",
        "> Financial returns often have positive skew (occasional large gains)\n",
        "> and fat tails. Lognormal captures this better than normal\n",
        "> distribution.\n",
        "\n",
        "### Step 2: Perform bootstrap resampling"
      ],
      "id": "6ee43174-a1a2-484c-8bd0-73da12e6ea45"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of bootstrap iterations\n",
        "B = 2000\n",
        "\n",
        "# Store bootstrap means\n",
        "boot_means = []\n",
        "\n",
        "for i in range(B):\n",
        "    # Resample with replacement (same size as original)\n",
        "    xb = np.random.choice(x, size=len(x), replace=True)\n",
        "    \n",
        "    # Calculate mean of this bootstrap sample\n",
        "    boot_means.append(np.mean(xb))\n",
        "\n",
        "# Convert to array for analysis\n",
        "boot_means = np.array(boot_means)\n",
        "\n",
        "print(f\"Generated {B} bootstrap samples\")\n",
        "print(f\"Mean of bootstrap means: {np.mean(boot_means):.4f}\")\n",
        "print(f\"Std of bootstrap means: {np.std(boot_means):.4f}\")"
      ],
      "id": "5875057c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Calculate confidence interval"
      ],
      "id": "3b3563f4-e374-46fd-b4f6-0a426397e8c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 95% confidence interval: use 2.5th and 97.5th percentiles\n",
        "ci_low, ci_high = np.percentile(boot_means, [2.5, 97.5])\n",
        "\n",
        "print(f\"\\n95% Bootstrap Confidence Interval:\")\n",
        "print(f\"Lower bound: {ci_low:.4f}\")\n",
        "print(f\"Point estimate: {np.mean(x):.4f}\")\n",
        "print(f\"Upper bound: {ci_high:.4f}\")\n",
        "\n",
        "# Sanity check: point estimate should be inside CI\n",
        "assert ci_low < np.mean(x) < ci_high, \"Point estimate outside CI!\"\n",
        "print(\"\\n‚úî Bootstrap CI computed successfully\")"
      ],
      "id": "329296b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Visualize the bootstrap distribution"
      ],
      "id": "bb8317bc-6b9d-4ae1-9a85-8cec369e690a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# Histogram of bootstrap means\n",
        "plt.hist(boot_means, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "\n",
        "# Mark the confidence interval\n",
        "plt.axvline(ci_low, color='red', linestyle='--', linewidth=2, label=f'95% CI: [{ci_low:.3f}, {ci_high:.3f}]')\n",
        "plt.axvline(ci_high, color='red', linestyle='--', linewidth=2)\n",
        "plt.axvline(np.mean(x), color='green', linestyle='-', linewidth=2, label=f'Sample mean: {np.mean(x):.3f}')\n",
        "\n",
        "plt.xlabel('Bootstrap Mean Values', fontsize=11)\n",
        "plt.ylabel('Frequency', fontsize=11)\n",
        "plt.title('Bootstrap Distribution of the Mean (B=2000)', fontsize=13)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "28ae76f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Interpretation**\n",
        ">\n",
        "> **What the 95% CI means (frequentist):** If we repeated this process\n",
        "> many times, 95% of the intervals would contain the true population\n",
        "> mean.\n",
        ">\n",
        "> **What it does NOT mean:** There‚Äôs NOT a 95% probability the true mean\n",
        "> is in this interval. The true mean either is or isn‚Äôt in there‚Äîthe\n",
        "> probability refers to the **procedure**, not this specific interval.\n",
        ">\n",
        "> **Bayesian credible interval** (different concept): Given our data and\n",
        "> prior beliefs, there‚Äôs a 95% probability the parameter is in this\n",
        "> range. Requires specifying priors.\n",
        "\n",
        "**Checkpoint:** Why does bootstrap work? Hint: think about the\n",
        "relationship between sample-to-population and resample-to-sample.\n",
        "\n",
        "## Task 3 ‚Äî Walk‚ÄëForward Validation Schematic\n",
        "\n",
        "Financial data has temporal structure‚Äîyou can‚Äôt randomly split\n",
        "train/test without leaking future information into the past.\n",
        "**Walk-forward validation** respects time ordering.\n",
        "\n",
        "> **Why Random Splitting Fails in Finance**\n",
        ">\n",
        "> Standard k-fold cross-validation shuffles data randomly. In finance,\n",
        "> this creates **look-ahead bias**:\n",
        ">\n",
        "> -   Model trained on 2023 data, tested on 2022 data ‚Üí unrealistic!\n",
        "> -   Information from the future leaks into the past\n",
        "> -   Performance estimates are optimistically biased\n",
        ">\n",
        "> **Solution:** Always split by time, train on past, validate on future.\n",
        "\n",
        "### Visualize walk-forward structure"
      ],
      "id": "3ce3cdd5-8e74-44e0-a2b4-23375c61ab6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "\n",
        "# Define training and validation windows\n",
        "blocks = [\n",
        "    (0, 20, 'Train 1'),  \n",
        "    (20, 30, 'Valid 1'),  \n",
        "    (30, 50, 'Train 2'),  # Expands: includes Train 1 + Valid 1\n",
        "    (50, 60, 'Valid 2')\n",
        "]\n",
        "\n",
        "for start, end, label in blocks:\n",
        "    # Color training blocks blue, validation blocks orange\n",
        "    color = 'tab:blue' if 'Train' in label else 'tab:orange'\n",
        "    \n",
        "    plt.barh(0, end-start, left=start, height=0.6, color=color, edgecolor='black', linewidth=1.5)\n",
        "    plt.text((start+end)/2, 0, label, ha='center', va='center', \n",
        "             color='white', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.yticks([])\n",
        "plt.xlabel('Time index (e.g., months or days)', fontsize=11)\n",
        "plt.xlim(-2, 62)\n",
        "plt.title('Rolling/Expanding Walk‚ÄëForward Validation (Toy Example)', fontsize=13)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úî Walk‚Äëforward schematic drawn\")"
      ],
      "id": "309a0a86"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Two Common Variants**\n",
        ">\n",
        "> 1.  **Rolling Window**: Train on last N periods only (e.g., Train 2\n",
        ">     uses days 30-50)\n",
        ">     -   Adapts quickly to regime changes\n",
        ">     -   Less data per model\n",
        "> 2.  **Expanding Window**: Train on all past data (e.g., Train 2 uses\n",
        ">     days 0-50)\n",
        ">     -   More stable estimates\n",
        ">     -   Slower to adapt to structural breaks\n",
        "\n",
        "**Deliverable:** Write one short paragraph on when to prefer simple\n",
        "models despite recent evidence favoring complexity (Kelly, Malamud, and\n",
        "Zhou (2024)). Consider: regime shifts, parameter estimation error,\n",
        "interpretability requirements, regulatory constraints.\n",
        "\n",
        "## Task 4 ‚Äî Stylised-Fact Diagnostics"
      ],
      "id": "a7951f04-74e0-412b-9d1a-7d1e1c780996"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Synthetic returns with regime shifts to emphasise stylised facts\n",
        "regimes = np.concatenate([\n",
        "    np.random.normal(0, 0.6, size=250),\n",
        "    np.random.normal(0, 1.8, size=120),\n",
        "    np.random.normal(0, 0.9, size=200)\n",
        "]) / 100\n",
        "returns = pd.Series(regimes)\n",
        "\n",
        "kurt = stats.kurtosis(returns, fisher=False)\n",
        "acf_abs_lag1 = returns.abs().autocorr(lag=1)\n",
        "\n",
        "downside = returns[returns < 0]\n",
        "upside = returns[returns >= 0]\n",
        "semivar_down = (downside ** 2).mean()\n",
        "semivar_up = (upside ** 2).mean()\n",
        "\n",
        "roll_mean = returns.rolling(60).mean()\n",
        "roll_std = returns.rolling(60).std()\n",
        "\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10,8), sharex=True)\n",
        "returns.plot(ax=ax[0], color='tab:blue', linewidth=0.8)\n",
        "ax[0].set_title('Synthetic Returns with Regimes')\n",
        "ax[0].grid(alpha=0.3)\n",
        "\n",
        "returns.abs().plot(ax=ax[1], color='tab:orange', linewidth=0.8)\n",
        "ax[1].set_title('|Returns| Highlight Volatility Clustering')\n",
        "ax[1].grid(alpha=0.3)\n",
        "\n",
        "roll_mean.plot(ax=ax[2], color='tab:green', linewidth=1, label='Rolling mean (60)')\n",
        "roll_std.plot(ax=ax[2], color='tab:red', linewidth=1, label='Rolling std (60)')\n",
        "ax[2].set_title('Rolling Moments ‚Äî Regime Signals')\n",
        "ax[2].legend()\n",
        "ax[2].grid(alpha=0.3)\n",
        "ax[2].set_xlabel('Observation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Kurtosis (Gaussian=3): {kurt:.2f}\")\n",
        "print(f\"Autocorr |returns| lag 1: {acf_abs_lag1:.2f}\")\n",
        "print(f\"Downside semivariance: {semivar_down:.4f}\")\n",
        "print(f\"Upside semivariance:   {semivar_up:.4f}\")"
      ],
      "id": "1360f90d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Tail risk: how does the kurtosis compare to the Gaussian benchmark\n",
        "    (3)?\n",
        "-   Volatility memory: does the \\|returns\\| autocorrelation justify\n",
        "    extra lags in your models?\n",
        "-   Asymmetry: what do the downside vs upside semivariances imply for\n",
        "    features?\n",
        "-   Regime shifts: where do rolling mean/std change and how should\n",
        "    validation windows respond?\n",
        "\n",
        "Checkpoint: Draft a bullet list of features or diagnostics you would add\n",
        "before escalating model complexity.\n",
        "\n",
        "## Reflection ‚Äî Complexity Decision Flow\n",
        "\n",
        "Link your outputs back to the primer deck‚Äôs decision flow. In your\n",
        "notes, capture 2‚Äì3 bullet points for each step:\n",
        "\n",
        "1.  Evidence of richer signal (bias‚Äìvariance + stylised facts)\n",
        "2.  Baseline benchmark you would defend\n",
        "3.  Validation design to test complexity honestly\n",
        "4.  Governance checks before promoting Model‚ÄØB (Kelly, Malamud, and Zhou\n",
        "    (2024))\n",
        "\n",
        "> **Troubleshooting**\n",
        ">\n",
        "> -   If a plot is blank: check variable names and that x/y lengths\n",
        ">     match.\n",
        "> -   If a cell fails: run Setup, then Runtime ‚Üí Restart and run all\n",
        ">     (Colab).\n",
        "> -   If numbers differ: verify random seeds and parameters.\n",
        "\n",
        "## Governance & Failure Modes Checklist\n",
        "\n",
        "-   Flag two potential leakage risks in your coursework dataset and note\n",
        "    how you will test for them.\n",
        "-   Assign a notional ‚Äúmodel steward‚Äù and list what they must sign off\n",
        "    before deployment.\n",
        "-   Pick one explainability technique (e.g., SHAP, PDP) and describe how\n",
        "    it would reduce black-box anxiety for stakeholders.\n",
        "\n",
        "## Exercise: Bayesian Bootstrap for Signal-to-Noise\n",
        "\n",
        "How much of return variance is predictable? A rigorous way to measure\n",
        "**signal** is the R¬≤ from an AR(1) model: what fraction of today‚Äôs\n",
        "return is predictable from yesterday‚Äôs? The Bayesian bootstrap gives us\n",
        "a posterior distribution‚Äînot just a point estimate‚Äîcapturing uncertainty\n",
        "about predictability."
      ],
      "id": "fdb9bcd9-b6bc-49e1-a416-2d6088177bec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def bayesian_bootstrap_ar1(returns, n_samples=2000, seed=42):\n",
        "    \"\"\"\n",
        "    Bayesian bootstrap for AR(1) R¬≤ = œÅ¬≤ (squared autocorrelation).\n",
        "    \n",
        "    Returns posterior samples of R¬≤ capturing uncertainty.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = len(returns) - 1\n",
        "    x, y = returns[:-1], returns[1:]  # Paired observations\n",
        "    \n",
        "    r2_samples = []\n",
        "    for _ in range(n_samples):\n",
        "        # Dirichlet weights (Bayesian bootstrap)\n",
        "        w = rng.dirichlet(np.ones(n))\n",
        "        \n",
        "        # Weighted correlation\n",
        "        wx, wy = np.sum(w * x), np.sum(w * y)\n",
        "        cov_xy = np.sum(w * (x - wx) * (y - wy))\n",
        "        var_x = np.sum(w * (x - wx) ** 2)\n",
        "        var_y = np.sum(w * (y - wy) ** 2)\n",
        "        rho = cov_xy / np.sqrt(var_x * var_y + 1e-10)\n",
        "        r2_samples.append(rho ** 2)\n",
        "    \n",
        "    return np.array(r2_samples)\n",
        "\n",
        "# Simulate returns (or use your own data)\n",
        "np.random.seed(123)\n",
        "returns = np.random.normal(0.0005, 0.02, size=500)  # 500 days, ~0.05% mean, 2% vol\n",
        "\n",
        "# Compute posterior\n",
        "r2_posterior = bayesian_bootstrap_ar1(returns, n_samples=2000)\n",
        "\n",
        "# Summarise\n",
        "median_r2 = np.median(r2_posterior) * 100\n",
        "ci_lo, ci_hi = np.percentile(r2_posterior * 100, [2.5, 97.5])\n",
        "\n",
        "print(f\"Posterior R¬≤ (predictable variance):\")\n",
        "print(f\"  Median: {median_r2:.2f}%\")\n",
        "print(f\"  95% CI: [{ci_lo:.2f}%, {ci_hi:.2f}%]\")\n",
        "print(f\"  Noise fraction (at median): {100 - median_r2:.2f}%\")\n",
        "\n",
        "# Plot posterior\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.hist(r2_posterior * 100, bins=50, density=True, alpha=0.7, color='steelblue', edgecolor='white')\n",
        "ax.axvline(median_r2, color='coral', linestyle='--', linewidth=2, label=f'Median: {median_r2:.2f}%')\n",
        "ax.axvline(ci_lo, color='gray', linestyle=':', linewidth=1)\n",
        "ax.axvline(ci_hi, color='gray', linestyle=':', linewidth=1, label=f'95% CI: [{ci_lo:.1f}%, {ci_hi:.1f}%]')\n",
        "ax.set_xlabel('Predictable variance R¬≤ (%)')\n",
        "ax.set_ylabel('Posterior density')\n",
        "ax.set_title('Bayesian Bootstrap: How Much Variance is Predictable?')\n",
        "ax.legend()\n",
        "ax.set_xlim(0, max(15, ci_hi * 1.5))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fd839740"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Reflection questions:**\n",
        "\n",
        "1.  **Interpret the width**: Why is the 95% credible interval so wide\n",
        "    relative to the median? What does this tell you about measuring\n",
        "    predictability?\n",
        "\n",
        "2.  **Upper bound matters**: Even at the optimistic upper bound of the\n",
        "    interval, what fraction of variance remains unpredictable noise?\n",
        "\n",
        "3.  **Wide intervals are informative**: A point estimate (R¬≤ = X%) hides\n",
        "    uncertainty. How does the posterior distribution change your\n",
        "    interpretation compared to a single number?\n",
        "\n",
        "4.  **Try real data**: If you have access to Bloomberg data or another\n",
        "    source, replace the simulated returns with actual daily returns for\n",
        "    SPY, AAPL, or another asset. How do the results compare?\n",
        "\n",
        "> **Connection to Course Themes**\n",
        ">\n",
        "> This exercise connects to Fischer Black‚Äôs insight that ‚Äúwe are forced\n",
        "> to act largely in the dark.‚Äù The posterior distribution quantifies\n",
        "> exactly how dark: even with hundreds of observations, we cannot\n",
        "> precisely measure how little predictability exists. This is the\n",
        "> fundamental challenge of financial inference that motivates everything\n",
        "> in this course.\n",
        "\n",
        "## Save Outputs (optional)"
      ],
      "id": "b8431c7e-de72-443b-a761-8cd895a99fbe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.savefig('lab01_last_figure.png', dpi=150)\n",
        "\"Saved: lab01_last_figure.png\""
      ],
      "id": "097d9aec"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exit Ticket (Optional, No Submission)\n",
        "\n",
        "Before you leave, note one or two of the following (no submission):\n",
        "\n",
        "-   **Variation and uncertainty**: A setting where you care about\n",
        "    *variation* (what you model) and *uncertainty* (what you\n",
        "    quantify)‚Äîand how this lab‚Äôs tools (bootstrap, bias‚Äìvariance,\n",
        "    walk‚Äëforward) would apply.\n",
        "-   **Validation**: How you would design a time‚Äëaware validation\n",
        "    (e.g.¬†walk‚Äëforward) to compare a more complex model to a baseline\n",
        "    without look‚Äëahead bias.\n",
        "-   **Governance**: One governance or ethical concern you would monitor\n",
        "    when taking a model from this lab‚Äôs style of analysis toward a\n",
        "    production or high‚Äëstakes setting.\n",
        "\n",
        "> **Further Reading (optional)**\n",
        ">\n",
        "> -   Kelly, Malamud, and Zhou (2024) on when complexity helps return\n",
        ">     prediction‚Äîconnects to the bias‚Äìvariance and validation themes in\n",
        ">     this lab.\n",
        "> -   For additional code and statistics/ML workflows aligned with this\n",
        ">     lab, see the [Reading\n",
        ">     List](https://quinfer.github.io/financial-data-science/resources/reading.qmd)\n",
        ">     and resources linked from the course website. The handbook and\n",
        ">     module page are the source of truth for *required* reading.\n",
        "\n",
        "Kelly, Bryan T., Semyon Malamud, and Kangying Zhou. 2024. ‚ÄúThe Virtue of\n",
        "Complexity in Return Prediction.‚Äù *Journal of Finance* 79 (1): 459‚Äì503.\n",
        "<https://doi.org/10.1111/jofi.13298>."
      ],
      "id": "65652344-1ae4-43eb-a32c-e1a74165ce57"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "fin510",
      "display_name": "FIN510 Python",
      "language": "python",
      "path": "/Users/quinference/Library/Jupyter/kernels/fin510"
    }
  }
}