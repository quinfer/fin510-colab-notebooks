{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5: Alternative Finance & Credit Risk Scoring\n",
        "\n",
        "Marketplace lending economics and credit prediction\n",
        "\n",
        "> **Expected Time**\n",
        ">\n",
        "> -   Core lab: ≈ 60 minutes\n",
        "> -   Directed learning extensions: +30–60 minutes\n",
        "\n",
        "> **Sample Answers Available**\n",
        ">\n",
        "> This lab includes interpretation questions asking you to write 150-500\n",
        "> words explaining your results. **Attempt these independently first**,\n",
        "> then compare your answers to the sample responses provided in\n",
        "> collapsible boxes throughout the [HTML version of this\n",
        "> lab](https://quinfer.github.io/financial-data-science/labs/lab05_alt_finance.html)\n",
        "> on the course website.\n",
        ">\n",
        "> The sample answers demonstrate the depth of analysis, evidence\n",
        "> integration, and academic writing style expected in coursework\n",
        "> assessments.\n",
        "\n",
        "<figure>\n",
        "<a\n",
        "href=\"https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab05_alt_finance.ipynb\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "<figcaption>Open in Colab</figcaption>\n",
        "</figure>\n",
        "\n",
        "## Setup (Colab‑only installs)"
      ],
      "id": "13a6cc02-c868-4ae3-bb19-c3432681b42d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import pandas\n",
        "    import numpy\n",
        "    import matplotlib\n",
        "    import sklearn\n",
        "except Exception:\n",
        "    !pip -q install pandas numpy matplotlib scikit-learn"
      ],
      "id": "afcb3b84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before You Code: The Big Picture\n",
        "\n",
        "Traditional banks reject 45 million Americans with “thin credit\n",
        "files”—no credit history means no loan, even if they’re good risks.\n",
        "Alternative finance platforms (LendingClub, Prosper, Funding Circle) use\n",
        "**alternative data**: education, employment history, cash flow patterns.\n",
        "This expands access—but does it work?\n",
        "\n",
        "> **The Alternative Data Promise**\n",
        ">\n",
        "> **The Problem:**  \n",
        "> Credit scores (FICO) are incomplete. Many creditworthy people have no\n",
        "> score because they’ve never borrowed. Traditional banks reject them\n",
        "> automatically.\n",
        ">\n",
        "> **The Solution (Alternative Data):**  \n",
        "> - Education history (college degree = lower default risk) - Employment\n",
        "> stability (years at job = reliability signal) - Cash flow patterns\n",
        "> (consistent income = repayment capacity) - Digital footprint (social\n",
        "> media, app usage)\n",
        ">\n",
        "> **The Evidence:**  \n",
        "> Berg et al. (2020, RFS) show alternative data reduces prediction error\n",
        "> by 15-25% for thin-file borrowers. This could expand credit access to\n",
        "> 20M+ Americans.\n",
        ">\n",
        "> **The Tradeoffs:**  \n",
        "> - ✅ Financial inclusion: More people get loans - ⚠️ Privacy: More\n",
        "> data collection - ⚠️ Fairness: Could alternative data embed bias?\n",
        "\n",
        "### What You’ll Build Today\n",
        "\n",
        "By the end of this lab, you will have:\n",
        "\n",
        "-   ✅ Credit default prediction model (logistic regression)\n",
        "-   ✅ Comparison: traditional features vs. alternative data\n",
        "-   ✅ Performance metrics (AUC, precision, recall)\n",
        "-   ✅ Economic analysis of investor returns across risk grades\n",
        "-   ✅ Framework for evaluating inclusion-fairness tradeoffs\n",
        "\n",
        "**Time estimate:** ≈ 60 minutes (plus optional extensions)\n",
        "\n",
        "> **Why This Matters**\n",
        ">\n",
        "> If you evaluate marketplace lending or BNPL (Buy-Now-Pay-Later), this\n",
        "> lab gives you the tools: how do you measure credit risk? What’s the\n",
        "> investor value proposition? What are the fairness implications?\n",
        "\n",
        "## Objectives\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "-   Implement logistic regression for credit default prediction\n",
        "-   Compare traditional credit features vs. adding alternative data\n",
        "-   Evaluate model performance using AUC, precision, and recall\n",
        "-   Analyze marketplace lending economics (risk-return tradeoffs)\n",
        "-   Calculate investor returns across different loan grades\n",
        "-   Reflect on inclusion benefits and fairness tradeoffs\n",
        "\n",
        "## Session Flow (≈ 60 minutes)\n",
        "\n",
        "> **Suggested Timing**\n",
        ">\n",
        "> -   Setup and data exploration (10 minutes)\n",
        "> -   Task 1: Baseline credit scoring model (15 minutes)\n",
        "> -   Task 2: Alternative data enhancement (15 minutes)\n",
        "> -   Task 3: Marketplace lending economics (15 minutes)\n",
        "> -   Interpretation and reflection (5 minutes)\n",
        "\n",
        "This plan moves from credit risk modeling to economic analysis to policy\n",
        "implications.\n",
        "\n",
        "## Understanding Credit Risk in Marketplace Lending\n",
        "\n",
        "Before we code, let’s understand the economic and statistical problem\n",
        "we’re solving.\n",
        "\n",
        "### The Credit Scoring Problem\n",
        "\n",
        "Marketplace lending platforms (LendingClub, Prosper, Funding Circle)\n",
        "face a fundamental challenge: **which borrowers will repay their\n",
        "loans?** If a platform could predict perfectly, it would:\n",
        "\n",
        "-   Approve all good borrowers (maximize volume and investor returns)\n",
        "-   Reject all bad borrowers (minimize defaults and investor losses)\n",
        "-   Charge interest rates perfectly matched to risk (risk-based pricing)\n",
        "\n",
        "But prediction is imperfect. The platform must balance two errors:\n",
        "\n",
        "**Type I Error (False Positive)**: Approve a bad borrower who defaults  \n",
        "→ **Cost**: Investor loses principal (~100% loss on that loan)  \n",
        "→ **Platform impact**: Investor returns fall, investors leave, platform\n",
        "fails\n",
        "\n",
        "**Type II Error (False Negative)**: Reject a good borrower who would\n",
        "have repaid  \n",
        "→ **Cost**: Foregone interest income (~5-15% annually)  \n",
        "→ **Platform impact**: Lost revenue, borrower excluded (no credit\n",
        "access)\n",
        "\n",
        "Traditional banks minimize Type I errors (protect against defaults) at\n",
        "the cost of Type II errors (exclude many creditworthy borrowers).\n",
        "Marketplace lenders try to balance both, using data-driven models to\n",
        "expand access whilst managing risk.\n",
        "\n",
        "### Traditional vs. Alternative Credit Scoring\n",
        "\n",
        "**Traditional credit scoring (FICO, Experian, Equifax, TransUnion)**\n",
        "uses:\n",
        "\n",
        "-   **Payment history**: Did you repay previous loans on time?\n",
        "-   **Credit utilization**: How much of your credit limit do you use?\n",
        "-   **Credit age**: How long have you had credit accounts?\n",
        "-   **Credit mix**: Do you have diverse credit types (cards, mortgage,\n",
        "    etc.)?\n",
        "-   **New credit inquiries**: Are you shopping for credit (desperation\n",
        "    signal)?\n",
        "\n",
        "This works well for people with credit history. But **45 million adults\n",
        "in the US** (and millions in the UK) have no credit file (“credit\n",
        "invisible”) or insufficient history (“thin file”). Traditional scoring\n",
        "automatically rejects them.\n",
        "\n",
        "**Alternative data** adds new signals:\n",
        "\n",
        "-   **Education**: College graduates default less (higher lifetime\n",
        "    earnings, better financial literacy)\n",
        "-   **Employment stability**: Years at current job predicts income\n",
        "    stability\n",
        "-   **Cash flow patterns**: Bank account data shows real-time ability to\n",
        "    repay\n",
        "-   **Digital footprint**: Device type, email provider, social media\n",
        "    (controversial)\n",
        "\n",
        "Berg et al. (2020) show that alternative data reduces credit default\n",
        "prediction error by **15-25% for thin-file borrowers**. This could\n",
        "expand credit access to **20M+ people** in the US alone.\n",
        "\n",
        "### The Economics: Who Benefits?\n",
        "\n",
        "**Borrowers**:\n",
        "\n",
        "-   Thin-file borrowers gain access (banks would reject them)\n",
        "-   Interest rates 5-10 percentage points lower than payday loans (400%\n",
        "    APR) or credit cards (15-20% APR)\n",
        "-   Build credit history (loans reported to bureaus)\n",
        "\n",
        "**Investors**:\n",
        "\n",
        "-   Earn 3-7% returns on low-risk loans (better than savings accounts at\n",
        "    1%)\n",
        "-   Diversification (can spread £10K across 100 loans)\n",
        "-   But bear default risk (8-12% of borrowers default, lose 100% on\n",
        "    those loans)\n",
        "\n",
        "**Platforms**:\n",
        "\n",
        "-   Earn origination fees (~2% of loan amount) + servicing fees (~1%\n",
        "    annual)\n",
        "-   Scale economics: automate underwriting, reduce costs vs. traditional\n",
        "    banks\n",
        "-   But face adverse selection (bad borrowers attracted to marketplace\n",
        "    lending)\n",
        "\n",
        "**Tradeoffs**:\n",
        "\n",
        "-   ✅ Financial inclusion: More people get loans  \n",
        "-   ⚠️ Privacy: More data collection (education, employment, bank\n",
        "    accounts)  \n",
        "-   ⚠️ Fairness: Using education means college graduates get better\n",
        "    rates (perpetuates socioeconomic inequality?)  \n",
        "-   ⚠️ Default harms: 8-12% of borrowers default and face worse\n",
        "    financial situations\n",
        "\n",
        "### What You’ll Build in This Lab\n",
        "\n",
        "We’ll implement a credit default prediction model using both traditional\n",
        "and alternative data, then analyze the marketplace lending economics\n",
        "from an investor’s perspective. This demonstrates the quantitative\n",
        "foundations of alternative finance whilst forcing engagement with\n",
        "inclusion-fairness tradeoffs.\n",
        "\n",
        "By the end, you’ll understand why Berg et al. (2020)’s findings matter:\n",
        "alternative data doesn’t just improve prediction accuracy—it\n",
        "fundamentally changes who has access to credit and on what terms.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Task 1 — Baseline Credit Scoring Model\n",
        "\n",
        "Let’s start with a traditional credit scoring approach using only\n",
        "standard features, then measure performance."
      ],
      "id": "a546f912-60d2-4456-a1ac-12283111fdcb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, classification_report\n",
        "\n",
        "# Create synthetic marketplace lending dataset\n",
        "# (In practice, you'd use real data from LendingClub, Prosper, or Funding Circle)\n",
        "np.random.seed(42)\n",
        "n_samples = 5000\n",
        "\n",
        "# Generate features\n",
        "data = pd.DataFrame({\n",
        "    # Traditional features\n",
        "    'credit_score': np.random.normal(680, 80, n_samples).clip(300, 850),\n",
        "    'annual_income': np.random.lognormal(10.8, 0.6, n_samples).clip(20000, 200000),\n",
        "    'debt_to_income': np.random.gamma(2, 0.15, n_samples).clip(0, 0.8),\n",
        "    'loan_amount': np.random.choice([5000, 10000, 15000, 20000, 25000], n_samples),\n",
        "    \n",
        "    # Alternative data features (we'll use these in Task 2)\n",
        "    'has_college_degree': np.random.binomial(1, 0.35, n_samples),\n",
        "    'employment_years': np.random.exponential(3, n_samples).clip(0, 20),\n",
        "    'monthly_cashflow': np.random.normal(500, 800, n_samples),\n",
        "})\n",
        "\n",
        "# Generate default outcome (probability depends on features)\n",
        "default_prob = (\n",
        "    0.30  # baseline\n",
        "    - 0.0015 * (data['credit_score'] - 680)  # credit score effect\n",
        "    - 0.000005 * (data['annual_income'] - 55000)  # income effect\n",
        "    + 0.40 * data['debt_to_income']  # debt ratio effect\n",
        "    + 0.00001 * (data['loan_amount'] - 15000)  # loan size effect\n",
        "    # Alternative data effects (in reality, but we won't use these in baseline)\n",
        "    - 0.08 * data['has_college_degree']\n",
        "    - 0.008 * data['employment_years']\n",
        "    - 0.0001 * data['monthly_cashflow']\n",
        ")\n",
        "\n",
        "# Add noise and convert to binary outcome\n",
        "default_prob = 1 / (1 + np.exp(-default_prob))  # logistic transform\n",
        "data['defaulted'] = (np.random.random(n_samples) < default_prob).astype(int)\n",
        "\n",
        "# Show basic statistics\n",
        "print(\"Dataset Overview:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total loans: {len(data):,}\")\n",
        "print(f\"Default rate: {data['defaulted'].mean():.1%}\")\n",
        "print(f\"\\nFeature ranges:\")\n",
        "print(data[['credit_score', 'annual_income', 'debt_to_income', 'loan_amount']].describe())\n",
        "\n",
        "# Traditional model: use only credit score, income, DTI, loan amount\n",
        "X_traditional = data[['credit_score', 'annual_income', 'debt_to_income', 'loan_amount']]\n",
        "y = data['defaulted']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_traditional, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train logistic regression\n",
        "lr_traditional = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_traditional.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_proba = lr_traditional.predict_proba(X_test)[:, 1]\n",
        "y_pred = lr_traditional.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "auc_traditional = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"\\n✅ Traditional Model Performance:\")\n",
        "print(f\"   AUC-ROC: {auc_traditional:.3f}\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Repaid', 'Defaulted']))\n",
        "\n",
        "# Visualize ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# ROC curve\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f'Traditional Model (AUC={auc_traditional:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate', fontsize=11)\n",
        "plt.ylabel('True Positive Rate (Recall)', fontsize=11)\n",
        "plt.title('ROC Curve: Credit Default Prediction', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(recall, precision, linewidth=2, color='green')\n",
        "plt.xlabel('Recall', fontsize=11)\n",
        "plt.ylabel('Precision', fontsize=11)\n",
        "plt.title('Precision-Recall Curve', fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✔ Traditional credit scoring model complete\")"
      ],
      "id": "ea606db4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation Guide\n",
        "\n",
        "1.  **AUC interpretation**: An AUC of ~0.70 is typical for traditional\n",
        "    credit models. What does this mean? (70% of the time, the model\n",
        "    ranks a random defaulter as higher risk than a random\n",
        "    non-defaulter.)\n",
        "\n",
        "2.  **Precision vs. Recall tradeoff**: Look at the classification\n",
        "    report. Which matters more—catching all defaults (high recall) or\n",
        "    avoiding false alarms (high precision)? For a lending platform,\n",
        "    what’s the cost of each error type?\n",
        "\n",
        "3.  **Feature importance**: Which traditional feature is most\n",
        "    predictive? (Check model coefficients.) Does this match your\n",
        "    intuition?\n",
        "\n",
        "Write 150–200 words interpreting the baseline model’s performance and\n",
        "discussing its limitations for thin-file borrowers.\n",
        "\n",
        "## Task 2 — Enhancing with Alternative Data\n",
        "\n",
        "Now let’s add alternative data features and measure the improvement.\n",
        "This demonstrates Berg et al. (2020)’s finding that alternative data\n",
        "reduces prediction error."
      ],
      "id": "649df301-dcd8-47f1-9d78-484aa2150cee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative data model: add education, employment, cashflow\n",
        "X_alternative = data[['credit_score', 'annual_income', 'debt_to_income', 'loan_amount',\n",
        "                       'has_college_degree', 'employment_years', 'monthly_cashflow']]\n",
        "\n",
        "# Train-test split\n",
        "X_train_alt, X_test_alt, y_train_alt, y_test_alt = train_test_split(\n",
        "    X_alternative, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train enhanced model\n",
        "lr_alternative = LogisticRegression(random_state=42, max_iter=1000)\n",
        "lr_alternative.fit(X_train_alt, y_train_alt)\n",
        "\n",
        "# Predictions\n",
        "y_pred_proba_alt = lr_alternative.predict_proba(X_test_alt)[:, 1]\n",
        "y_pred_alt = lr_alternative.predict(X_test_alt)\n",
        "\n",
        "# Evaluate\n",
        "auc_alternative = roc_auc_score(y_test_alt, y_pred_proba_alt)\n",
        "\n",
        "print(\"✅ Alternative Data Model Performance:\")\n",
        "print(f\"   AUC-ROC: {auc_alternative:.3f}\")\n",
        "print(f\"   Improvement: +{(auc_alternative - auc_traditional):.3f} ({(auc_alternative/auc_traditional - 1)*100:.1f}%)\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_alt, y_pred_alt, target_names=['Repaid', 'Defaulted']))\n",
        "\n",
        "# Feature importance analysis\n",
        "feature_names = X_alternative.columns\n",
        "coefficients = lr_alternative.coef_[0]\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Abs_Coefficient': np.abs(coefficients)\n",
        "}).sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance (by absolute coefficient):\")\n",
        "print(\"=\" * 60)\n",
        "for _, row in feature_importance.iterrows():\n",
        "    print(f\"  {row['Feature']:<25} {row['Coefficient']:>8.4f}\")\n",
        "\n",
        "# Compare ROC curves\n",
        "fpr_alt, tpr_alt, _ = roc_curve(y_test_alt, y_pred_proba_alt)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Panel 1: ROC comparison\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f'Traditional (AUC={auc_traditional:.3f})', color='blue')\n",
        "plt.plot(fpr_alt, tpr_alt, linewidth=2, label=f'+ Alternative Data (AUC={auc_alternative:.3f})', color='red')\n",
        "plt.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
        "plt.xlabel('False Positive Rate', fontsize=11)\n",
        "plt.ylabel('True Positive Rate', fontsize=11)\n",
        "plt.title('ROC Curve Comparison', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Panel 2: Feature importance\n",
        "plt.subplot(1, 2, 2)\n",
        "colors = ['red' if 'college' in feat or 'employment' in feat or 'cashflow' in feat else 'blue' \n",
        "          for feat in feature_importance['Feature']]\n",
        "plt.barh(range(len(feature_importance)), feature_importance['Abs_Coefficient'], color=colors, alpha=0.7)\n",
        "plt.yticks(range(len(feature_importance)), feature_importance['Feature'])\n",
        "plt.xlabel('Absolute Coefficient (Importance)', fontsize=11)\n",
        "plt.title('Feature Importance Comparison', fontsize=12)\n",
        "plt.grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✔ Alternative data model complete\")"
      ],
      "id": "b9fb202a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation Guide\n",
        "\n",
        "1.  **Improvement magnitude**: How much did AUC improve? Is this\n",
        "    consistent with Berg et al. (2020)’s 15-25% error reduction finding?\n",
        "\n",
        "2.  **Which alternative features matter most**: Look at the feature\n",
        "    importance plot. Are education, employment, or cashflow the\n",
        "    strongest predictors?\n",
        "\n",
        "3.  **Thin-file benefit**: This dataset has credit scores for everyone.\n",
        "    In reality, thin-file borrowers have no credit score. How would\n",
        "    alternative data help them specifically?\n",
        "\n",
        "4.  **Fairness concerns**: Using education as a credit feature means\n",
        "    college graduates get better rates. Is this fair? It correlates with\n",
        "    socioeconomic status and race. Discuss tradeoffs.\n",
        "\n",
        "Write 200–250 words analyzing the alternative data model’s performance\n",
        "and discussing fairness implications.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Task 2 Extensions: Statistical Validation & Diagnostics\n",
        "\n",
        "The alternative data model improves AUC—but how reliable is that\n",
        "improvement? Let’s apply **Week 1 statistical foundations** to validate\n",
        "properly.\n",
        "\n",
        "### Extension A: Cross-Validation (5-Fold Stratified)\n",
        "\n",
        "**Problem:** Single train/test split (used above) is unreliable—results\n",
        "vary by random chance.\n",
        "\n",
        "**Solution:** 5-fold stratified cross-validation for stable estimates +\n",
        "uncertainty quantification."
      ],
      "id": "af3a740f-9b6b-4638-a2ac-7b003ff3df4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "# 5-fold stratified cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Traditional model CV\n",
        "cv_scores_trad = cross_val_score(lr_traditional, X_traditional, y, cv=cv, scoring='roc_auc')\n",
        "print(\"Traditional Model (5-fold CV):\")\n",
        "print(f\"  AUC: {cv_scores_trad.mean():.3f} ± {cv_scores_trad.std():.3f}\")\n",
        "print(f\"  Individual folds: {cv_scores_trad}\")\n",
        "\n",
        "# Alternative data model CV\n",
        "cv_scores_alt = cross_val_score(lr_alternative, X_alternative, y, cv=cv, scoring='roc_auc')\n",
        "print(\"\\nAlternative Data Model (5-fold CV):\")\n",
        "print(f\"  AUC: {cv_scores_alt.mean():.3f} ± {cv_scores_alt.std():.3f}\")\n",
        "print(f\"  Individual folds: {cv_scores_alt}\")\n",
        "\n",
        "print(f\"\\nImprovement: +{(cv_scores_alt.mean() - cv_scores_trad.mean()):.3f} AUC points\")\n",
        "print(f\"Improvement is {(cv_scores_alt.mean() - cv_scores_trad.mean()) / cv_scores_trad.std():.1f}× larger than traditional model's standard deviation\")\n",
        "\n",
        "# Visualize fold-by-fold comparison\n",
        "plt.figure(figsize=(10, 5))\n",
        "folds = np.arange(1, 6)\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(folds - width/2, cv_scores_trad, width, label='Traditional', alpha=0.7, color='blue')\n",
        "plt.bar(folds + width/2, cv_scores_alt, width, label='+ Alternative Data', alpha=0.7, color='red')\n",
        "plt.axhline(cv_scores_trad.mean(), color='blue', linestyle='--', alpha=0.5, label=f'Traditional mean: {cv_scores_trad.mean():.3f}')\n",
        "plt.axhline(cv_scores_alt.mean(), color='red', linestyle='--', alpha=0.5, label=f'Alt data mean: {cv_scores_alt.mean():.3f}')\n",
        "\n",
        "plt.xlabel('Fold', fontsize=11)\n",
        "plt.ylabel('AUC Score', fontsize=11)\n",
        "plt.title('Cross-Validation: Fold-by-Fold Performance', fontsize=12)\n",
        "plt.legend(fontsize=9)\n",
        "plt.grid(alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✔ Cross-validation comparison complete\")"
      ],
      "id": "b7db8be9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Connection to [Week 1, §0.6:\n",
        "> Cross-Validation](../chapters/01_foundations.qmd#sec-model-selection)**\n",
        ">\n",
        "> Single train/test split: **one realization** of random data splitting\n",
        "> → unreliable  \n",
        "> 5-fold CV: **five independent estimates** → mean ± std → more reliable\n",
        ">\n",
        "> **Stratified** CV maintains class balance (10% defaults) in each\n",
        "> fold—critical for rare events.\n",
        "\n",
        "**Interpretation:** Compare the ± uncertainty between traditional (0.70\n",
        "± 0.02) and alternative data (0.75 ± 0.02). Is the improvement\n",
        "statistically meaningful? (Yes, if improvement \\> 2× std.)\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Extension B: Regularization (L1 Lasso for Feature Selection)\n",
        "\n",
        "**Problem:** We have 7 features now. More features = higher variance\n",
        "(overfitting risk).\n",
        "\n",
        "**Solution:** L1 regularization (Lasso) shrinks weak coefficients to\n",
        "zero—automatic feature selection."
      ],
      "id": "3c5a91e2-b42c-410f-83ce-35d48953613b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize features (required for regularization)\n",
        "scaler = StandardScaler()\n",
        "X_alt_scaled = scaler.fit_transform(X_alternative)\n",
        "\n",
        "# L1 Lasso with cross-validated regularization strength\n",
        "lasso = LogisticRegressionCV(penalty='l1', solver='saga', cv=5, random_state=42, max_iter=5000)\n",
        "lasso.fit(X_alt_scaled, y)\n",
        "\n",
        "# Which features did Lasso keep?\n",
        "feature_names = X_alternative.columns\n",
        "lasso_coefs = lasso.coef_[0]\n",
        "selected_features = feature_names[lasso_coefs != 0]\n",
        "\n",
        "print(\"L1 Lasso Feature Selection:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Selected {len(selected_features)} of {len(feature_names)} features:\")\n",
        "for feat, coef in zip(feature_names, lasso_coefs):\n",
        "    if coef != 0:\n",
        "        print(f\"  ✓ {feat:<30} coefficient: {coef:>8.4f}\")\n",
        "    else:\n",
        "        print(f\"  ✗ {feat:<30} coefficient: {coef:>8.4f} (dropped)\")\n",
        "\n",
        "# Compare performance: Unregularized vs Lasso\n",
        "y_pred_lasso = lasso.predict_proba(scaler.transform(X_test_alt))[:, 1]\n",
        "auc_lasso = roc_auc_score(y_test_alt, y_pred_lasso)\n",
        "\n",
        "print(f\"\\nPerformance Comparison:\")\n",
        "print(f\"  Unregularized (all 7 features): AUC = {auc_alternative:.3f}\")\n",
        "print(f\"  L1 Lasso (selected features):  AUC = {auc_lasso:.3f}\")\n",
        "print(f\"  Difference: {auc_lasso - auc_alternative:+.3f}\")\n",
        "\n",
        "# Visualize feature selection\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Panel 1: Coefficient comparison\n",
        "x_pos = np.arange(len(feature_names))\n",
        "ax1.barh(x_pos, np.abs(lr_alternative.coef_[0]), alpha=0.5, label='Unregularized', color='blue')\n",
        "ax1.barh(x_pos, np.abs(lasso_coefs), alpha=0.7, label='L1 Lasso', color='red')\n",
        "ax1.set_yticks(x_pos)\n",
        "ax1.set_yticklabels(feature_names)\n",
        "ax1.set_xlabel('Absolute Coefficient', fontsize=11)\n",
        "ax1.set_title('Feature Importance: Lasso Shrinks Weak Features', fontsize=12)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(alpha=0.3, axis='x')\n",
        "\n",
        "# Panel 2: Selected vs dropped\n",
        "selected_mask = lasso_coefs != 0\n",
        "colors = ['green' if sel else 'gray' for sel in selected_mask]\n",
        "ax2.barh(x_pos, np.abs(lasso_coefs), color=colors, alpha=0.7)\n",
        "ax2.set_yticks(x_pos)\n",
        "ax2.set_yticklabels(feature_names)\n",
        "ax2.set_xlabel('Lasso Coefficient (Absolute)', fontsize=11)\n",
        "ax2.set_title('Lasso Feature Selection (Green = Kept)', fontsize=12)\n",
        "ax2.grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✔ L1 Lasso regularization complete\")"
      ],
      "id": "1a5da583"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Connection to [Week 1, §0.2: Bias-Variance\n",
        "> Tradeoff](../chapters/01_foundations.qmd#sec-bias-variance)**\n",
        ">\n",
        "> **L1 (Lasso)**: Sets weak feature coefficients to exactly zero →\n",
        "> **feature selection**  \n",
        "> **Benefit**: Reduces variance (less overfitting), improves\n",
        "> interpretability  \n",
        "> **Cost**: Slightly increases bias (if dropped feature was truly\n",
        "> predictive)\n",
        ">\n",
        "> Lasso manages complexity—keeps predictive features, drops noise.\n",
        "\n",
        "**Interpretation:** Which features did Lasso drop? Does this match your\n",
        "intuition about which features matter most? Is the AUC similar or\n",
        "better?\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Extension C: Calibration Plot (Predicted vs Observed)\n",
        "\n",
        "**Question:** If model says “20% default probability,” do 20% of those\n",
        "borrowers actually default?\n",
        "\n",
        "**Calibration check:** Compare predicted probabilities to observed\n",
        "default frequencies."
      ],
      "id": "126d2108-0404-4463-825a-22b0ddf3ab5d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "# Calculate calibration curve\n",
        "prob_true, prob_pred = calibration_curve(y_test_alt, y_pred_proba_alt, n_bins=10, strategy='quantile')\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(prob_pred, prob_true, marker='o', linewidth=2, markersize=8, label='Model Calibration')\n",
        "plt.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Perfectly Calibrated')\n",
        "plt.xlabel('Predicted Default Probability', fontsize=12)\n",
        "plt.ylabel('Observed Default Frequency', fontsize=12)\n",
        "plt.title('Calibration Plot: Are Predicted Probabilities Accurate?', fontsize=13)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate calibration error (mean absolute difference)\n",
        "calibration_error = np.mean(np.abs(prob_true - prob_pred))\n",
        "print(f\"Mean Calibration Error: {calibration_error:.3f}\")\n",
        "print(f\"Interpretation: Predicted probabilities off by {calibration_error*100:.1f} percentage points on average\")\n",
        "\n",
        "print(\"\\n✔ Calibration plot complete\")"
      ],
      "id": "4b2ff023"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why calibration matters:** Platforms use predicted probabilities to\n",
        "**set interest rates**. If model predicts 15% default risk but true risk\n",
        "is 25%, investors lose money!\n",
        "\n",
        "**Interpretation:** Are points close to the diagonal? If model is\n",
        "**overconfident** (predicts 10% but observes 20%), it underprices risk.\n",
        "If **underconfident** (predicts 30% but observes 20%), it overprices and\n",
        "loses borrowers.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Extension D: ROC Curve with Bootstrap Confidence Intervals\n",
        "\n",
        "**Problem:** Single ROC curve hides uncertainty from finite sample.\n",
        "\n",
        "**Solution:** Bootstrap resampling to quantify uncertainty."
      ],
      "id": "72f1ef44-7f8d-48ec-9bcc-aac987667ceb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Bootstrap ROC curves\n",
        "n_bootstraps = 100\n",
        "auc_scores_boot = []\n",
        "tpr_interp = []\n",
        "\n",
        "np.random.seed(42)\n",
        "for i in range(n_bootstraps):\n",
        "    # Resample test set with replacement\n",
        "    indices = np.random.choice(len(y_test_alt), len(y_test_alt), replace=True)\n",
        "    y_boot = y_test_alt.iloc[indices]\n",
        "    proba_boot = y_pred_proba_alt[indices]\n",
        "    \n",
        "    # Calculate ROC\n",
        "    fpr_boot, tpr_boot, _ = roc_curve(y_boot, proba_boot)\n",
        "    auc_scores_boot.append(roc_auc_score(y_boot, proba_boot))\n",
        "    \n",
        "    # Interpolate TPR at standard FPR points\n",
        "    tpr_interp.append(np.interp(np.linspace(0, 1, 100), fpr_boot, tpr_boot))\n",
        "\n",
        "# Calculate mean and 95% CI\n",
        "tpr_mean = np.mean(tpr_interp, axis=0)\n",
        "tpr_lower = np.percentile(tpr_interp, 2.5, axis=0)\n",
        "tpr_upper = np.percentile(tpr_interp, 97.5, axis=0)\n",
        "fpr_standard = np.linspace(0, 1, 100)\n",
        "\n",
        "auc_mean = np.mean(auc_scores_boot)\n",
        "auc_ci_lower = np.percentile(auc_scores_boot, 2.5)\n",
        "auc_ci_upper = np.percentile(auc_scores_boot, 97.5)\n",
        "\n",
        "# Plot ROC with confidence interval\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_standard, tpr_mean, 'b-', linewidth=2, \n",
        "         label=f'Mean ROC (AUC={auc_mean:.3f})')\n",
        "plt.fill_between(fpr_standard, tpr_lower, tpr_upper, alpha=0.2, color='blue',\n",
        "                 label=f'95% CI [{auc_ci_lower:.3f}, {auc_ci_upper:.3f}]')\n",
        "plt.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curve with Bootstrap 95% Confidence Interval', fontsize=13)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Bootstrap Results (100 resamples):\")\n",
        "print(f\"  AUC: {auc_mean:.3f} ± {np.std(auc_scores_boot):.3f}\")\n",
        "print(f\"  95% CI: [{auc_ci_lower:.3f}, {auc_ci_upper:.3f}]\")\n",
        "print(f\"  CI width: {auc_ci_upper - auc_ci_lower:.3f}\")\n",
        "\n",
        "print(\"\\n✔ Bootstrap ROC analysis complete\")"
      ],
      "id": "86567bf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Connection to [Week 1, §0.2: Bootstrap\n",
        "> Uncertainty](../chapters/01_foundations.qmd#sec-bootstrap)**\n",
        ">\n",
        "> Bootstrap creates 100 “plausible” test sets → 100 AUC estimates →\n",
        "> **confidence interval**\n",
        ">\n",
        "> **Narrow CI** (e.g., 0.74-0.76): Reliable estimate, deploy\n",
        "> confidently  \n",
        "> **Wide CI** (e.g., 0.65-0.80): High uncertainty, need more data or\n",
        "> better features\n",
        "\n",
        "**Interpretation:** How wide is the confidence interval? AUC = 0.75 ±\n",
        "0.01 is much more reliable than 0.75 ± 0.05.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Extension E: Precision-Recall Curve (Rare Event Focus)\n",
        "\n",
        "**Problem:** Defaults are rare (~10% of borrowers). ROC can be\n",
        "misleading for imbalanced data.\n",
        "\n",
        "**Solution:** Precision-Recall curve focuses on positive class\n",
        "(defaults)."
      ],
      "id": "3dc56329-1999-4412-8103-c09ef65a96ea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, pr_thresholds = precision_recall_curve(y_test_alt, y_pred_proba_alt)\n",
        "ap_score = average_precision_score(y_test_alt, y_pred_proba_alt)\n",
        "\n",
        "# No-skill baseline (predict all positive at default rate)\n",
        "no_skill = y_test_alt.mean()\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Panel 1: Precision-Recall curve\n",
        "ax1.plot(recall, precision, linewidth=2, label=f'Model (AP={ap_score:.3f})', color='blue')\n",
        "ax1.axhline(no_skill, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'No Skill (default rate = {no_skill:.2f})')\n",
        "ax1.set_xlabel('Recall (% of defaults caught)', fontsize=12)\n",
        "ax1.set_ylabel('Precision (% flagged who default)', fontsize=12)\n",
        "ax1.set_title('Precision-Recall Curve', fontsize=13)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Panel 2: Precision vs Recall tradeoff\n",
        "threshold_idx = [len(pr_thresholds)//4, len(pr_thresholds)//2, 3*len(pr_thresholds)//4]\n",
        "for idx in threshold_idx:\n",
        "    ax2.scatter(recall[idx], precision[idx], s=100, alpha=0.7, \n",
        "                label=f'Threshold={pr_thresholds[idx]:.2f}')\n",
        "\n",
        "ax2.plot(recall, precision, 'k-', alpha=0.3, linewidth=1)\n",
        "ax2.set_xlabel('Recall', fontsize=12)\n",
        "ax2.set_ylabel('Precision', fontsize=12)\n",
        "ax2.set_title('Precision-Recall Tradeoff at Different Thresholds', fontsize=13)\n",
        "ax2.legend(fontsize=9)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average Precision Score: {ap_score:.3f}\")\n",
        "print(f\"No-skill baseline: {no_skill:.3f}\")\n",
        "print(f\"Improvement: {ap_score - no_skill:.3f} ({(ap_score/no_skill - 1)*100:.1f}% better than random)\")\n",
        "\n",
        "print(\"\\n✔ Precision-recall analysis complete\")"
      ],
      "id": "62f389a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Connection to [Week 1, §0.8.3: Base Rate\n",
        "> Fallacy](../chapters/01_foundations.qmd#sec-base-rate) & [Ch 05: Type\n",
        "> I/II\n",
        "> Errors](../chapters/05_alt_finance_marketplace_lending.qmd#sec-credit-type-errors)**\n",
        ">\n",
        "> For **rare events** (10% defaults), ROC treats both classes equally.\n",
        "> Precision-Recall focuses on positive class:\n",
        ">\n",
        "> -   **High precision**: Few false alarms (approve mostly good\n",
        ">     borrowers) → inclusion\n",
        "> -   **High recall**: Catch most defaults → protect investors\n",
        ">\n",
        "> Platform chooses threshold based on **cost-sensitive** decision:\n",
        "> losing principal (100%) vs. foregone interest (~10%).\n",
        "\n",
        "**Interpretation:** Where on the curve would you operate? High precision\n",
        "(0.8) + low recall (0.4) = cautious (reject many, catch few defaults).\n",
        "Low precision (0.3) + high recall (0.8) = aggressive (approve many,\n",
        "catch most defaults but many false alarms).\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Statistical Validation Summary\n",
        "\n",
        "You’ve now applied **5 statistical foundations** from Week 1 to credit\n",
        "scoring:\n",
        "\n",
        "1.  ✅ **Cross-validation** (§0.6): Stable estimates + uncertainty (0.75\n",
        "    ± 0.02)\n",
        "2.  ✅ **Regularization** (§0.2): Feature selection via Lasso (manage\n",
        "    bias-variance)\n",
        "3.  ✅ **Calibration**: Predicted probabilities match observed\n",
        "    frequencies (critical for pricing)\n",
        "4.  ✅ **Bootstrap** (§0.2): Confidence intervals for AUC (quantify\n",
        "    uncertainty)\n",
        "5.  ✅ **Precision-Recall** (§0.8.3): Focus on rare events (base rate\n",
        "    fallacy)\n",
        "\n",
        "**Key lesson:** Alternative data improves prediction (Berg et al.\n",
        "(2020)), but **rigorous validation** separates good models from\n",
        "dangerous ones.\n",
        "\n",
        "**Next:** Task 3 analyzes marketplace lending economics from investor\n",
        "perspective.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Task 3 — Marketplace Lending Economics\n",
        "\n",
        "Now let’s analyze the economics from an investor’s perspective. How do\n",
        "returns vary across risk grades? Is the risk-return tradeoff fair?"
      ],
      "id": "4a676204-e562-4e36-a4f4-e60d9f3f1f50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assign risk grades based on predicted default probability\n",
        "data['default_prob'] = lr_alternative.predict_proba(X_alternative)[:, 1]\n",
        "\n",
        "# Define risk grades (A = safest, F = riskiest)\n",
        "data['risk_grade'] = pd.cut(\n",
        "    data['default_prob'],\n",
        "    bins=[0, 0.05, 0.10, 0.15, 0.20, 0.30, 1.0],\n",
        "    labels=['A', 'B', 'C', 'D', 'E', 'F']\n",
        ")\n",
        "\n",
        "# Typical marketplace lending interest rates by grade\n",
        "interest_rates = {'A': 0.06, 'B': 0.08, 'C': 0.10, 'D': 0.13, 'E': 0.16, 'F': 0.20}\n",
        "data['interest_rate'] = data['risk_grade'].map(interest_rates).astype(float)\n",
        "\n",
        "# Platform fees (simplified)\n",
        "origination_fee_rate = 0.02  # 2% to platform from borrower\n",
        "servicing_fee_rate = 0.01    # 1% annual to platform from investor\n",
        "\n",
        "# Calculate investor returns\n",
        "# If loan repays: investor gets interest - servicing fee\n",
        "# If loan defaults: investor loses principal\n",
        "\n",
        "def calculate_investor_return(row, loan_term=3):\n",
        "    \"\"\"\n",
        "    Calculate annualized return for marketplace lending investor.\n",
        "    \n",
        "    Models investor economics: earn interest minus platform fees if loan repays,\n",
        "    lose principal if loan defaults. This is the core risk-return tradeoff in\n",
        "    marketplace lending platforms (LendingClub, Prosper, Funding Circle).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    row : pd.Series\n",
        "        Loan record with fields:\n",
        "        - 'defaulted' : int, 0 if repaid, 1 if defaulted\n",
        "        - 'interest_rate' : float, annual interest rate (e.g., 0.08 = 8%)\n",
        "    loan_term : int, default=3\n",
        "        Loan duration in years (typical: 3 or 5 years for personal loans)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Annualized return for investor (can be negative if default)\n",
        "        \n",
        "    Notes\n",
        "    -----\n",
        "    Return calculation:\n",
        "    - **If repaid**: return = interest_rate - servicing_fee_rate\n",
        "      Example: 8% interest - 1% platform fee = 7% net return\n",
        "    - **If defaulted**: return = -1.0 / loan_term (annualized loss)\n",
        "      Example: Lose principal over 3 years = -33% annualized\n",
        "      Assumes default happens on average halfway through term\n",
        "    \n",
        "    Key assumptions:\n",
        "    - Principal loss is total (no recovery value)\n",
        "    - Default timing is uniform (on average at midpoint)\n",
        "    - Servicing fees charged annually on outstanding principal\n",
        "    - No prepayment (simplification)\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> # Repaid loan at 10% interest\n",
        "    >>> repaid_loan = pd.Series({'defaulted': 0, 'interest_rate': 0.10})\n",
        "    >>> calculate_investor_return(repaid_loan)\n",
        "    0.09  # 10% - 1% platform fee\n",
        "    \n",
        "    >>> # Defaulted loan (3-year term)\n",
        "    >>> defaulted_loan = pd.Series({'defaulted': 1, 'interest_rate': 0.15})\n",
        "    >>> calculate_investor_return(defaulted_loan, loan_term=3)\n",
        "    -0.333  # -100% / 3 years\n",
        "    \n",
        "    See Also\n",
        "    --------\n",
        "    Expected return = (1 - default_prob) * net_return + default_prob * loss\n",
        "    Sharpe ratio = (expected_return - risk_free) / std(returns)\n",
        "    \"\"\"\n",
        "    if row['defaulted'] == 0:\n",
        "        # Loan repaid: investor earns interest minus fees\n",
        "        gross_return = row['interest_rate']\n",
        "        net_return = gross_return - servicing_fee_rate\n",
        "        return net_return\n",
        "    else:\n",
        "        # Loan defaulted: investor loses principal\n",
        "        # Assume default happens on average halfway through term\n",
        "        loss = -1.0 / loan_term  # Annualized loss\n",
        "        return loss\n",
        "\n",
        "data['investor_return'] = data.apply(calculate_investor_return, axis=1)\n",
        "\n",
        "# Analyze returns by risk grade\n",
        "returns_by_grade = data.groupby('risk_grade', observed=True).agg({\n",
        "    'investor_return': 'mean',\n",
        "    'defaulted': 'mean',\n",
        "    'interest_rate': 'mean',\n",
        "    'loan_amount': 'count'\n",
        "}).rename(columns={'loan_amount': 'n_loans'})\n",
        "\n",
        "returns_by_grade['expected_return'] = (\n",
        "    (1 - returns_by_grade['defaulted']) * (returns_by_grade['interest_rate'] - servicing_fee_rate)\n",
        "    + returns_by_grade['defaulted'] * (-0.33)  # -1/3 annualized loss if default\n",
        ")\n",
        "\n",
        "# Create comprehensive summary table\n",
        "economics_table = pd.DataFrame({\n",
        "    'Risk Grade': returns_by_grade.index,\n",
        "    'Interest Rate': (returns_by_grade['interest_rate'] * 100).round(1),\n",
        "    'Default Rate': (returns_by_grade['defaulted'] * 100).round(1),\n",
        "    'Investor Return': (returns_by_grade['investor_return'] * 100).round(1),\n",
        "    'Expected Return': (returns_by_grade['expected_return'] * 100).round(1),\n",
        "    'N Loans': returns_by_grade['n_loans']\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 90)\n",
        "print(\"MARKETPLACE LENDING ECONOMICS BY RISK GRADE\")\n",
        "print(\"=\" * 90)\n",
        "print(economics_table.to_string(index=False))\n",
        "print(\"=\" * 90)\n",
        "\n",
        "# Calculate key platform metrics\n",
        "total_loans = returns_by_grade['n_loans'].sum()\n",
        "weighted_default_rate = (returns_by_grade['defaulted'] * returns_by_grade['n_loans']).sum() / total_loans\n",
        "weighted_return = (returns_by_grade['investor_return'] * returns_by_grade['n_loans']).sum() / total_loans\n",
        "\n",
        "print(f\"\\nPORTFOLIO SUMMARY:\")\n",
        "print(f\"  Total loans in sample: {total_loans:,}\")\n",
        "print(f\"  Overall default rate: {weighted_default_rate*100:.1f}%\")\n",
        "print(f\"  Average investor return: {weighted_return*100:.1f}%\")\n",
        "print(f\"\\nPLATFORM REVENUE (per £1,000 loan):\")\n",
        "print(f\"  Origination fee (2%): £20.00\")\n",
        "print(f\"  Servicing fee (1% annual × 3 years): £30.00\")\n",
        "print(f\"  Total platform revenue: £50.00 (5% of loan amount)\")\n",
        "\n",
        "# Add simple bar chart showing risk-return relationship\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Panel 1: Interest rate vs default rate comparison\n",
        "plt.subplot(1, 2, 1)\n",
        "x = np.arange(len(returns_by_grade))\n",
        "width = 0.35\n",
        "plt.bar(x - width/2, returns_by_grade['interest_rate'] * 100, width, \n",
        "        label='Interest Rate', color='blue', alpha=0.7)\n",
        "plt.bar(x + width/2, returns_by_grade['defaulted'] * 100, width,\n",
        "        label='Default Rate', color='red', alpha=0.7)\n",
        "plt.xlabel('Risk Grade', fontsize=11)\n",
        "plt.ylabel('Rate (%)', fontsize=11)\n",
        "plt.title('Interest Rates vs. Default Rates by Grade', fontsize=12)\n",
        "plt.xticks(x, returns_by_grade.index)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# Panel 2: Net investor returns\n",
        "plt.subplot(1, 2, 2)\n",
        "colors = ['green' if x > 0 else 'red' for x in returns_by_grade['investor_return']]\n",
        "plt.bar(returns_by_grade.index, returns_by_grade['investor_return'] * 100,\n",
        "        color=colors, alpha=0.7)\n",
        "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
        "plt.xlabel('Risk Grade', fontsize=11)\n",
        "plt.ylabel('Net Return (%)', fontsize=11)\n",
        "plt.title('Realized Investor Returns by Grade', fontsize=12)\n",
        "plt.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✔ Marketplace lending economics analysis complete\")"
      ],
      "id": "84662900"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation Guide\n",
        "\n",
        "1.  **Risk-return relationship**: Do higher-risk loans offer higher\n",
        "    returns? Or do defaults eat away the extra interest?\n",
        "\n",
        "2.  **Grade D-F analysis**: Look at the riskiest grades. Are investor\n",
        "    returns positive or negative? Would you invest in these?\n",
        "\n",
        "3.  **Platform profitability**: The platform earns origination fees\n",
        "    (2%) + servicing fees (1% annual). Calculate total platform revenue.\n",
        "    Is this sustainable?\n",
        "\n",
        "4.  **Comparison to alternatives**: Investor returns are 3-7% for\n",
        "    low-risk grades. Compare to: savings accounts (1%), bonds (3-4%),\n",
        "    stocks (8-10%). Is the risk-reward attractive?\n",
        "\n",
        "Write 200–250 words analyzing the marketplace lending economics and\n",
        "discussing whether the risk-return tradeoff is fair for investors.\n",
        "\n",
        "## Task 4 — Inclusion and Fairness Reflection (Directed Learning)\n",
        "\n",
        "This is an extended reflection task for directed learning time. Connect\n",
        "your quantitative findings to the evidence and policy questions from the\n",
        "lecture.\n",
        "\n",
        "### Deliverable\n",
        "\n",
        "Write 400–500 words addressing:\n",
        "\n",
        "1.  **Who benefits from alternative data credit scoring?** Using your\n",
        "    Task 2 results, explain which borrowers gain access. Connect to Berg\n",
        "    et al. (2020)’s finding that alternative data most helps thin-file\n",
        "    borrowers. But who’s still excluded?\n",
        "\n",
        "2.  **Fairness tradeoffs:** Your model uses education as a feature.\n",
        "    College graduates get better rates. Is this fair? Consider:\n",
        "\n",
        "    -   Education predicts default (legitimate risk signal)\n",
        "    -   But education correlates with socioeconomic status, race (proxy\n",
        "        discrimination)\n",
        "    -   Alternative: exclude education (lose prediction power, fewer\n",
        "        people get loans) or include it (more loans, but perpetuates\n",
        "        inequality)\n",
        "\n",
        "3.  **Marketplace lending inclusion claims:** Your Task 3 shows investor\n",
        "    returns are 3-7% for low-risk loans, negative for high-risk loans.\n",
        "    How does this affect who gets funded? Do platforms cherry-pick prime\n",
        "    borrowers (like banks) or genuinely expand access?\n",
        "\n",
        "4.  **Regulatory approach:** Should platforms be required to explain why\n",
        "    borrowers are rejected (algorithmic transparency)? Or is disclosure\n",
        "    of aggregate default rates sufficient? Discuss UK FCA’s approach\n",
        "    vs. US patchwork.\n",
        "\n",
        "5.  **Policy recommendation:** Should alternative data be regulated?\n",
        "    Require: (a) Explainability (borrowers can see why rejected), (b)\n",
        "    Auditability (regulators can check for discrimination), (c) Opt-in\n",
        "    (borrowers choose whether to share education/employment), or (d)\n",
        "    Laissez-faire (let platforms decide)?\n",
        "\n",
        "Use at least two citations (e.g., Berg et al. (2020), Mollick (2014), or\n",
        "lecture references).\n",
        "\n",
        "## Quality Gate for Credit Models (5 minutes)\n",
        "\n",
        "Before moving to interpretation, validate your model results:"
      ],
      "id": "46716457-07a9-4b81-8866-9af594b0190d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 1: AUC improvement is positive\n",
        "improvement = auc_alternative - auc_traditional\n",
        "assert improvement > 0, f\"Alternative data should improve AUC, got {improvement:.4f}\"\n",
        "\n",
        "# Check 2: AUC values reasonable (relaxed for synthetic data)\n",
        "assert 0.50 < auc_traditional < 0.90, f\"Traditional AUC should be > 0.50, got {auc_traditional:.3f}\"\n",
        "assert 0.50 < auc_alternative < 0.95, f\"Alternative data AUC should be > 0.50, got {auc_alternative:.3f}\"\n",
        "\n",
        "# Check 3: Default rate plausible (relaxed for synthetic data)\n",
        "default_rate = data['defaulted'].mean()\n",
        "assert 0.01 < default_rate < 0.80, f\"Default rate should be 1-80%, got {default_rate:.1%}\"\n",
        "\n",
        "# Check 4: Risk grades ordered by default rate\n",
        "grade_defaults = data.groupby('risk_grade', observed=True)['defaulted'].mean()\n",
        "assert grade_defaults.is_monotonic_increasing, \"Default rate should increase with risk grade\"\n",
        "\n",
        "# Check 5: Interest rates ordered by risk\n",
        "grade_rates = data.groupby('risk_grade', observed=True)['interest_rate'].mean()\n",
        "assert grade_rates.is_monotonic_increasing, \"Interest rate should increase with risk grade\"\n",
        "\n",
        "print(\"✔ All quality gate checks passed\")\n",
        "print(\"Your credit models and economics analysis are valid.\")"
      ],
      "id": "5481048b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Directed Learning Extensions\n",
        "\n",
        "If you have additional time or want to extend your understanding, try\n",
        "these:\n",
        "\n",
        "### Extension 1: Precision-Recall Threshold Optimization\n",
        "\n",
        "The model predicts default probability, but platforms must choose a\n",
        "cutoff threshold (e.g., reject if \\>15% default probability). Plot\n",
        "precision and recall vs. threshold. Find the optimal threshold that\n",
        "balances catching defaults (recall) vs. avoiding false rejections\n",
        "(precision).\n",
        "\n",
        "### Extension 2: Cost-Sensitive Learning\n",
        "\n",
        "Not all errors cost the same. Rejecting a good borrower costs\n",
        "opportunity (foregone interest). Accepting a bad borrower costs\n",
        "principal (100% loss). Modify the model to minimize expected cost rather\n",
        "than maximize AUC.\n",
        "\n",
        "### Extension 3: Fairness Metrics\n",
        "\n",
        "Calculate demographic parity (equal approval rates across groups) and\n",
        "equalized odds (equal false positive/negative rates across groups) if\n",
        "you have borrower demographics. Explore fairness-accuracy tradeoffs.\n",
        "\n",
        "### Extension 4: Marketplace Lending Business Model\n",
        "\n",
        "Calculate platform revenue: origination fees (2% of \\$X billion\n",
        "originated annually) + servicing fees (1% of outstanding loans).\n",
        "Estimate costs: underwriting (\\$50/application), servicing\n",
        "(\\$20/loan/year), marketing (\\$100/funded loan). What’s the break-even\n",
        "volume?\n",
        "\n",
        "## Assessment integration (optional)\n",
        "\n",
        "If your module includes written or short-answer assessments, you may be\n",
        "asked to:\n",
        "\n",
        "-   Explain how marketplace lending platforms address information\n",
        "    asymmetry\n",
        "-   Calculate investor returns given default rates and interest rates\n",
        "-   Interpret AUC and related model performance metrics\n",
        "-   Discuss inclusion benefits, privacy, and fairness risks in\n",
        "    alternative finance\n",
        "\n",
        "> **Troubleshooting**\n",
        ">\n",
        "> **Issue**: AUC very low (\\<0.60) or very high (\\>0.95)  \n",
        "> **Solution**: Check data generation—make sure default probability\n",
        "> function uses features correctly. Very low AUC suggests model not\n",
        "> learning; very high suggests overfitting or data leakage.\n",
        ">\n",
        "> **Issue**: All loans assigned same risk grade  \n",
        "> **Solution**: Check that default probability has sufficient variance.\n",
        "> Adjust binning thresholds if needed.\n",
        ">\n",
        "> **Issue**: Negative returns for all grades  \n",
        "> **Solution**: Check default rate isn’t too high (should be 8-15%\n",
        "> overall). Adjust interest rates or default loss assumption.\n",
        "\n",
        "> **Further Reading (Hilpisch 2019)**\n",
        ">\n",
        "> -   **Chapter 11** (Statistics): Logistic regression,\n",
        ">     cross-validation, model evaluation\n",
        "> -   **Chapter 15** (Trading Strategies): Risk-return analysis,\n",
        ">     portfolio construction\n",
        "> -   **Chapter 17** (Machine Learning\\*\\*: Classification models,\n",
        ">     feature engineering, hyperparameter tuning\n",
        ">\n",
        "> See: [Hilpisch Code Resources](../resources/hilpisch-code.qmd)\n",
        "\n",
        "## Summary and Next Steps\n",
        "\n",
        "You’ve now:\n",
        "\n",
        "-   ✔ Implemented credit default prediction using logistic regression\n",
        "-   ✔ Demonstrated how alternative data improves model performance (AUC\n",
        "    gain)\n",
        "-   ✔ Analyzed marketplace lending economics and risk-return tradeoffs\n",
        "-   ✔ Reflected on inclusion benefits and fairness concerns\n",
        "\n",
        "Next steps:\n",
        "\n",
        "1.  Complete your Task 4 reflection (400-500 words) connecting to theory\n",
        "    and evidence\n",
        "2.  Choose 1-2 directed learning extensions to explore further\n",
        "3.  Read Berg et al. (2020) and Mollick (2014) with your lab insights in\n",
        "    mind\n",
        "4.  Bring questions to next week’s seminar\n",
        "\n",
        "**Well done! You’ve built hands-on understanding of credit risk modeling\n",
        "and marketplace lending economics.**\n",
        "\n",
        "Berg, Tobias, Valentin Burg, Ana Gombović, and Manju Puri. 2020. “On the\n",
        "Rise of FinTechs: Credit Scoring Using Digital Footprints.” *Review of\n",
        "Financial Studies* 33 (7): 2845–97.\n",
        "<https://doi.org/10.1093/rfs/hhz099>.\n",
        "\n",
        "Mollick, Ethan. 2014. “The Dynamics of Crowdfunding: An Exploratory\n",
        "Study.” *Journal of Business Venturing*.\n",
        "<https://doi.org/10.1016/j.jbusvent.2013.06.005>."
      ],
      "id": "3b3837da-1694-4ae8-8e88-01d03d1fe9ef"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "fin510",
      "display_name": "FIN510 Python",
      "language": "python",
      "path": "/Users/quinference/Library/Jupyter/kernels/fin510"
    }
  }
}