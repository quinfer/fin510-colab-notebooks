{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Lab 2: Data Acquisition & APIs\"\n",
        "subtitle: \"Build a minimal, reliable pipeline\"\n",
        "format:\n",
        "  html:\n",
        "    toc: false\n",
        "    number-sections: true\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  message: false\n",
        "---\n",
        "\n",
        "::: callout-note\n",
        "### Expected Time\n",
        "- FIN510: Seminar hands‑on ≈ 60 min; \n",
        "- Directed learning extensions ≈ 90–120 min\n",
        "- FIN720: Computer lab ≈ 120 min\n",
        ":::\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quinfer/fin510-colab-notebooks/blob/main/labs/lab02_apis.ipynb)\n",
        "\n",
        "## Setup (Colab‑only installs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import yfinance, pandas, pandas_datareader\n",
        "except Exception:\n",
        "    !pip -q install yfinance pandas pandas-datareader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives\n",
        "\n",
        "- Pull assets with yfinance; validate and log\n",
        "- Handle missing values and out‑of‑range returns\n",
        "\n",
        "## Task 1 — Download and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, time, random\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "symbols = ['AAPL','MSFT','SPY']\n",
        "\n",
        "def get_close_from_yf(symbols, period='2y', tries=3):\n",
        "    last_err = None\n",
        "    for i in range(tries):\n",
        "        try:\n",
        "            df = yf.download(symbols, period=period, auto_adjust=True, progress=False, group_by='ticker', threads=True)\n",
        "            # yfinance returns MultiIndex cols when multiple symbols\n",
        "            if isinstance(df.columns, pd.MultiIndex):\n",
        "                closes = pd.concat({sym: df[sym]['Close'] for sym in symbols if sym in df.columns.levels[0]}, axis=1)\n",
        "                closes.columns = [c if isinstance(c, str) else c[0] for c in closes.columns]\n",
        "            else:\n",
        "                # single symbol\n",
        "                closes = df['Close'].to_frame(symbols[0])\n",
        "            if closes.dropna(how='all').shape[0] > 0:\n",
        "                return closes\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "        # Backoff on rate limit\n",
        "        time.sleep(2*(i+1) + random.random())\n",
        "    raise RuntimeError(f\"yfinance download failed after {tries} tries: {last_err}\")\n",
        "\n",
        "def get_close_from_stooq(symbols, years=2):\n",
        "    from datetime import datetime, timedelta\n",
        "    from pandas_datareader import data as web\n",
        "    end = datetime.today()\n",
        "    start = end - timedelta(days=365*years + 14)\n",
        "    series = []\n",
        "    for sym in symbols:\n",
        "        try:\n",
        "            s = web.DataReader(sym, 'stooq', start, end)['Close'].sort_index()\n",
        "            s.name = sym\n",
        "            series.append(s)\n",
        "            time.sleep(0.4)\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not series:\n",
        "        raise RuntimeError(\"stooq fallback returned no data\")\n",
        "    return pd.concat(series, axis=1)\n",
        "\n",
        "def synthetic_prices(symbols, periods=252, mu=0.0004, sigma=0.012):\n",
        "    rng = np.random.default_rng(42)\n",
        "    dates = pd.bdate_range(end=pd.Timestamp.today().normalize(), periods=periods)\n",
        "    shocks = rng.normal(mu, sigma, size=(len(dates), len(symbols)))\n",
        "    levels = 100*np.exp(np.cumsum(shocks, axis=0))\n",
        "    return pd.DataFrame(levels, index=dates, columns=symbols)\n",
        "\n",
        "# Try yfinance → stooq → synthetic\n",
        "try:\n",
        "    prices = get_close_from_yf(symbols)\n",
        "    source = 'yfinance'\n",
        "except Exception as e1:\n",
        "    try:\n",
        "        prices = get_close_from_stooq(symbols)\n",
        "        source = 'stooq (pandas-datareader)'\n",
        "    except Exception as e2:\n",
        "        prices = synthetic_prices(symbols)\n",
        "        source = f'synthetic (fallback due to: {e1!r}; {e2!r})'\n",
        "\n",
        "log = {}\n",
        "log['source'] = source\n",
        "log['missing_prices'] = int(prices.isna().sum().sum())\n",
        "rets = prices.pct_change()\n",
        "log['missing_returns'] = int(rets.isna().sum().sum())\n",
        "log['out_of_range'] = int((rets.abs()>0.2).sum().sum())\n",
        "log\n",
        "if prices.dropna(how='all').shape[0] > 0:\n",
        "    print(f\"Data source: {source}. Download and validation checks passed ✔\")\n",
        "else:\n",
        "    print(f\"Warning: no data returned from any source. Proceeding with empty frame.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2 — Clean and Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clean = rets.dropna().clip(lower=-0.2, upper=0.2)\n",
        "clean.tail()\n",
        "clean.to_csv('returns_clean.csv')\n",
        "\"Saved returns_clean.csv\"\n",
        "assert 'returns_clean.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deliverable: Short note describing issues found (missing, out‑of‑range) and how you handled them.\n",
        "\n",
        "::: callout-tip\n",
        "### Troubleshooting\n",
        "- API download empty: try fewer symbols or shorter period.\n",
        "- Many outliers: inspect corporate actions/adjustments; consider `auto_adjust=True`.\n",
        "- CSV not found: ensure current working directory permissions in Colab.\n",
        ":::\n",
        "\n",
        "::: callout-note\n",
        "### Further Reading (Hilpisch 2019)\n",
        "- See: [Hilpisch Code Resources](../resources/hilpisch-code.qmd) — Week 2\n",
        "- Chapter 13 (ML pipelines) shows end‑to‑end workflows (features → pipeline → evaluation) you can mirror with time‑aware splits.\n",
        ":::\n",
        "\n",
        "## Mini‑Task — JKP Sample (Primer for Coursework 2)\n",
        "\n",
        "This short exercise previews the JKP factor dataset used in Coursework 2. Load a small sample CSV, compute quick stats, and (optionally) run a one‑line CAPM alpha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# JKP sample (course mirror) — small monthly slice with MKT, SMB, HML, MOM\n",
        "import pandas as pd, os\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Prefer local file during site build; fall back to raw GitHub if needed\n",
        "local_path = os.path.join('..','resources','jkp-sample.csv')\n",
        "if os.path.exists(local_path):\n",
        "    jkp = pd.read_csv(local_path, parse_dates=['date']).set_index('date').sort_index()\n",
        "else:\n",
        "    url = \"https://raw.githubusercontent.com/quinfer/financial-data-science/main/resources/jkp-sample.csv\"\n",
        "    jkp = pd.read_csv(url, parse_dates=['date']).set_index('date').sort_index()\n",
        "\n",
        "# Summary stats and quick cumulative return for MOM\n",
        "summary = jkp[['MKT','SMB','HML','MOM']].describe().round(3)\n",
        "cum = (1 + jkp['MOM']).cumprod() - 1\n",
        "summary.tail(3), cum.tail()\n",
        "\n",
        "# Optional: CAPM alpha (no HAC here — use HAC in the assessment)\n",
        "ls = jkp['MOM'].dropna()\n",
        "mkt = jkp['MKT'].reindex(ls.index)\n",
        "capm = sm.OLS(ls, sm.add_constant(mkt)).fit()\n",
        "float(capm.params['const']), float(capm.tvalues['const'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notes\n",
        "- In the assessment you will use a larger CSV downloaded from the JKP portal and apply HAC standard errors.\n",
        "- Keep scope tight (few factors, limited window) and focus on quality of evidence.\n",
        "\n",
        "## Quick Leakage Check (Practice)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure prediction tasks shift the target correctly\n",
        "import pandas as pd\n",
        "\n",
        "# Intentionally wrong design (no shift) for demonstration\n",
        "X_wrong = jkp[['MKT','SMB','HML','MOM']].dropna()\n",
        "y_next   = jkp['MOM'].shift(-1)               # next-month target\n",
        "\n",
        "# Overlap of indices indicates potential leakage if you don't drop/shift properly\n",
        "overlap = X_wrong.index.intersection(y_next.dropna().index)\n",
        "print(\"Potential leakage rows with wrong design:\", len(overlap))\n",
        "\n",
        "# Correct design: predictors at t, target at t+1 → align and drop NA\n",
        "X = jkp[['MKT','SMB','HML']].shift(0)\n",
        "y = jkp['MOM'].shift(-1)\n",
        "df = pd.concat([X, y.rename('y')], axis=1).dropna()\n",
        "print(\"Rows after proper shift/drop:\", len(df))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nlp_env",
      "language": "python",
      "display_name": "Python (nlp_env)",
      "path": "/Users/quinference/Library/Jupyter/kernels/nlp_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}